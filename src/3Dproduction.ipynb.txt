{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 908
        },
        "id": "3bhD25UQgUlp",
        "outputId": "9fde9892-f829-4ed6-f507-311024013c1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:6 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 36 not upgraded.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/intel-isl_MiDaS_master\n",
            "/usr/local/lib/python3.11/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LOG] Transformation utilisÃ©e : Compose(\n",
            "    <function transforms.<locals>.<lambda> at 0x7af1bcec9d00>\n",
            "    <midas.transforms.Resize object at 0x7af1a0a38150>\n",
            "    <midas.transforms.NormalizeImage object at 0x7af1a0a384d0>\n",
            "    <midas.transforms.PrepareForNet object at 0x7af1a0a3bdd0>\n",
            "    <function transforms.<locals>.<lambda> at 0x7af1bcec9da0>\n",
            ")\n",
            "â¬†ï¸ TÃ©lÃ©versez votre image (PNG, JPG, etc.)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/intel-isl_MiDaS_master\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e56dc1f7-384a-4e0c-b6c8-38ae2b9da3b1\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e56dc1f7-384a-4e0c-b6c8-38ae2b9da3b1\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving IMG-20250226-WA0015.jpg to IMG-20250226-WA0015.jpg\n",
            "[LOG] Image - Dimensions : (765, 1020, 3), Type : uint8\n",
            "[LOG] Image brute sauvegardÃ©e : output_frames/raw_image.png\n",
            "[LOG] Dimensions tenseur : torch.Size([1, 3, 384, 512]), Type : torch.float32, Valeurs min/max : -1.09/1.04\n",
            "[LOG] Forme avant infÃ©rence : torch.Size([1, 3, 384, 512])\n",
            "[LOG] Stats profondeur : min=9.87, max=35.34, mean=21.46\n",
            "[LOG] Carte de profondeur sauvegardÃ©e : output_frames/depth_image.png\n",
            "[LOG] 12288 points ajoutÃ©s\n",
            "[LOG] Forme des points : (12288, 3), Forme des couleurs : (12288, 3)\n",
            "[LOG] Affichage du nuage de points...\n",
            "\u001b[1;33m[Open3D WARNING] GLFW Error: Failed to detect any supported platform\u001b[0;m\n",
            "\u001b[1;33m[Open3D WARNING] GLFW initialized for headless rendering.\u001b[0;m\n",
            "\u001b[1;33m[Open3D WARNING] GLFW Error: OSMesa: Library not found\u001b[0;m\n",
            "\u001b[1;33m[Open3D WARNING] Failed to create window\u001b[0;m\n",
            "\u001b[1;33m[Open3D WARNING] [DrawGeometries] Failed creating OpenGL window.\u001b[0;m\n",
            "[LOG] âœ… Nuage de points exportÃ© vers 'scene3d.ply'\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_fa3acc9c-76e2-41ee-80e5-fca19e902f89\", \"scene3d.ply\", 331984)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LOG] âœ… Processus terminÃ©\n"
          ]
        }
      ],
      "source": [
        "# INSTALLATION\n",
        "!pip install -q opencv-python matplotlib timm torch torchvision open3d\n",
        "!apt-get update && apt-get install -y ffmpeg\n",
        "\n",
        "# IMPORTS\n",
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "import open3d as o3d\n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Fixer les graines pour la reproductibilitÃ©\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# CHARGEMENT DU MODÃˆLE MiDaS\n",
        "model_type = \"DPT_Large\"  # Options : DPT_Large, DPT_Hybrid, MiDaS_small\n",
        "try:\n",
        "    midas = torch.hub.load(\"intel-isl/MiDaS\", model_type, trust_repo=True)\n",
        "    midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\", trust_repo=True)\n",
        "except Exception as e:\n",
        "    raise RuntimeError(f\"Ã‰chec du chargement du modÃ¨le MiDaS : {e}\")\n",
        "\n",
        "# Configurer le dispositif\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "midas.to(device)\n",
        "midas.eval()\n",
        "\n",
        "# SÃ©lectionner la transformation appropriÃ©e\n",
        "transform = midas_transforms.dpt_transform if model_type.startswith(\"DPT\") else midas_transforms.small_transform\n",
        "print(f\"[LOG] Transformation utilisÃ©e : {transform}\")\n",
        "\n",
        "# CrÃ©er le dossier de sortie\n",
        "os.makedirs(\"output_frames\", exist_ok=True)\n",
        "\n",
        "# TÃ©lÃ©verser l'image\n",
        "print(\"â¬†ï¸ TÃ©lÃ©versez votre image (PNG, JPG, etc.)\")\n",
        "try:\n",
        "    uploaded = files.upload()\n",
        "    image_path = next(iter(uploaded))\n",
        "except Exception as e:\n",
        "    raise RuntimeError(f\"Ã‰chec du tÃ©lÃ©versement de l'image : {e}\")\n",
        "\n",
        "# Charger et convertir l'image en RGB\n",
        "img_rgb = cv2.imread(image_path)\n",
        "if img_rgb is None:\n",
        "    raise RuntimeError(f\"Impossible de charger l'image : {image_path}\")\n",
        "img_rgb = cv2.cvtColor(img_rgb, cv2.COLOR_BGR2RGB)\n",
        "print(f\"[LOG] Image - Dimensions : {img_rgb.shape}, Type : {img_rgb.dtype}\")\n",
        "\n",
        "# VÃ©rifier les canaux\n",
        "if img_rgb.shape[2] != 3:\n",
        "    raise ValueError(f\"L'image doit avoir 3 canaux (RGB), {img_rgb.shape[2]} dÃ©tectÃ©s\")\n",
        "\n",
        "# Sauvegarder l'image brute pour inspection\n",
        "plt.imsave(\"output_frames/raw_image.png\", img_rgb)\n",
        "print(f\"[LOG] Image brute sauvegardÃ©e : output_frames/raw_image.png\")\n",
        "\n",
        "# Appliquer la transformation MiDaS\n",
        "try:\n",
        "    input_tensor = transform(img_rgb).to(device)\n",
        "    print(f\"[LOG] Dimensions tenseur : {input_tensor.shape}, Type : {input_tensor.dtype}, Valeurs min/max : {input_tensor.min():.2f}/{input_tensor.max():.2f}\")\n",
        "    if input_tensor.shape[1] != 3:  # VÃ©rifier la dimension des canaux\n",
        "        raise ValueError(f\"Le tenseur d'entrÃ©e doit avoir 3 canaux, {input_tensor.shape[1]} dÃ©tectÃ©s\")\n",
        "except Exception as e:\n",
        "    raise RuntimeError(f\"Erreur lors de la transformation : {e}\")\n",
        "\n",
        "# VÃ©rifier la forme avant infÃ©rence\n",
        "print(f\"[LOG] Forme avant infÃ©rence : {input_tensor.shape}\")\n",
        "\n",
        "# PrÃ©dire la profondeur\n",
        "with torch.no_grad():\n",
        "    prediction = midas(input_tensor)\n",
        "    prediction = torch.nn.functional.interpolate(\n",
        "        prediction.unsqueeze(1),\n",
        "        size=img_rgb.shape[:2],\n",
        "        mode=\"bicubic\",\n",
        "        align_corners=False,\n",
        "    ).squeeze()\n",
        "\n",
        "depth = prediction.cpu().numpy()\n",
        "print(f\"[LOG] Stats profondeur : min={depth.min():.2f}, max={depth.max():.2f}, mean={depth.mean():.2f}\")\n",
        "\n",
        "# Sauvegarder la carte de profondeur\n",
        "plt.imsave(\"output_frames/depth_image.png\", depth, cmap='inferno')\n",
        "print(f\"[LOG] Carte de profondeur sauvegardÃ©e : output_frames/depth_image.png\")\n",
        "\n",
        "# ParamÃ¨tres de la camÃ©ra\n",
        "fx, fy = 500, 500  # Longueurs focales\n",
        "h, w = depth.shape\n",
        "cx, cy = w / 2, h / 2\n",
        "\n",
        "# Normaliser la profondeur\n",
        "depth = np.clip(depth, 0.1, 100)\n",
        "\n",
        "# GÃ©nÃ©rer le nuage de points\n",
        "all_points = []\n",
        "all_colors = []\n",
        "stride = 8\n",
        "points_count = 0\n",
        "for y in range(0, h, stride):\n",
        "    for x in range(0, w, stride):\n",
        "        z = depth[y, x]\n",
        "        if np.isnan(z) or np.isinf(z):\n",
        "            continue\n",
        "        X = (x - cx) * z / fx\n",
        "        Y = (y - cy) * z / fy\n",
        "        if np.any(np.isnan([X, Y, z])) or np.any(np.isinf([X, Y, z])):\n",
        "            continue\n",
        "        all_points.append([X, -Y, -z])\n",
        "        all_colors.append(img_rgb[y, x] / 255.0)\n",
        "        points_count += 1\n",
        "print(f\"[LOG] {points_count} points ajoutÃ©s\")\n",
        "\n",
        "# VÃ©rifier si des points ont Ã©tÃ© gÃ©nÃ©rÃ©s\n",
        "if not all_points:\n",
        "    print(\"[LOG] Erreur : Aucun point valide gÃ©nÃ©rÃ©. VÃ©rifiez l'image brute et la carte de profondeur dans 'output_frames/'\")\n",
        "    raise RuntimeError(\"Aucun point valide gÃ©nÃ©rÃ© pour le nuage de points.\")\n",
        "\n",
        "# CrÃ©er le nuage de points Open3D\n",
        "try:\n",
        "    pcd = o3d.geometry.PointCloud()\n",
        "    points_array = np.array(all_points, dtype=np.float64)\n",
        "    colors_array = np.array(all_colors, dtype=np.float64)\n",
        "    print(f\"[LOG] Forme des points : {points_array.shape}, Forme des couleurs : {colors_array.shape}\")\n",
        "    if points_array.shape[1] != 3 or colors_array.shape[1] != 3:\n",
        "        raise ValueError(f\"Forme incorrecte : points {points_array.shape}, couleurs {colors_array.shape}\")\n",
        "    pcd.points = o3d.utility.Vector3dVector(points_array)\n",
        "    pcd.colors = o3d.utility.Vector3dVector(colors_array)\n",
        "except Exception as e:\n",
        "    print(f\"[LOG] Erreur lors de la crÃ©ation du nuage de points : {e}\")\n",
        "    raise RuntimeError(f\"Ã‰chec de la crÃ©ation du nuage de points : {e}\")\n",
        "\n",
        "# Visualiser le nuage de points\n",
        "print(\"[LOG] Affichage du nuage de points...\")\n",
        "try:\n",
        "    o3d.visualization.draw_geometries([pcd])\n",
        "except Exception as e:\n",
        "    print(f\"[LOG] Avertissement : Ã‰chec de la visualisation : {e}\")\n",
        "\n",
        "# Exporter le nuage de points\n",
        "output_path = \"scene3d.ply\"\n",
        "try:\n",
        "    o3d.io.write_point_cloud(output_path, pcd)\n",
        "    print(f\"[LOG] âœ… Nuage de points exportÃ© vers '{output_path}'\")\n",
        "except Exception as e:\n",
        "    print(f\"[LOG] Erreur lors de l'exportation : {e}\")\n",
        "    raise RuntimeError(f\"Ã‰chec de l'exportation du nuage de points : {e}\")\n",
        "\n",
        "# TÃ©lÃ©charger le fichier\n",
        "try:\n",
        "    files.download(output_path)\n",
        "except Exception as e:\n",
        "    print(f\"[LOG] Avertissement : Ã‰chec du tÃ©lÃ©chargement : {e}\")\n",
        "\n",
        "# Nettoyage\n",
        "del midas\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "print(\"[LOG] âœ… Processus terminÃ©\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2QyNaxedrGdo"
      },
      "outputs": [],
      "source": [
        "# ğŸ“¦ INSTALLATION\n",
        "!pip install -q opencv-python matplotlib timm torch torchvision open3d\n",
        "!apt-get update && apt-get install -y ffmpeg\n",
        "\n",
        "# ğŸ“š IMPORTS\n",
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "import open3d as o3d\n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# âš™ï¸ SETUP\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_type = \"DPT_Large\"\n",
        "\n",
        "# ğŸ§  CHARGEMENT MODÃˆLE\n",
        "midas = torch.hub.load(\"intel-isl/MiDaS\", model_type, trust_repo=True)\n",
        "midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\", trust_repo=True)\n",
        "midas.to(device).eval()\n",
        "transform = midas_transforms.dpt_transform if model_type.startswith(\"DPT\") else midas_transforms.small_transform\n",
        "\n",
        "# ğŸ“ OUTPUT\n",
        "os.makedirs(\"output_frames\", exist_ok=True)\n",
        "\n",
        "# ğŸ“¤ CHOIX IMAGE OU VIDÃ‰O\n",
        "print(\"â¬†ï¸ TÃ©lÃ©versez une image OU une vidÃ©o (.jpg, .png, .mp4)\")\n",
        "uploaded = files.upload()\n",
        "file_path = next(iter(uploaded))\n",
        "is_video = file_path.lower().endswith(\".mp4\")\n",
        "\n",
        "def estimate_depth(img_rgb):\n",
        "    input_tensor = transform(img_rgb).to(device)\n",
        "    with torch.no_grad():\n",
        "        prediction = midas(input_tensor)\n",
        "        prediction = torch.nn.functional.interpolate(\n",
        "            prediction.unsqueeze(1),\n",
        "            size=img_rgb.shape[:2],\n",
        "            mode=\"bicubic\",\n",
        "            align_corners=False,\n",
        "        ).squeeze()\n",
        "    return prediction.cpu().numpy()\n",
        "\n",
        "# ğŸ¯ FONCTION NUAGE DE POINTS\n",
        "def image_to_pointcloud(img_rgb, depth, fx=500, fy=500, stride=8):\n",
        "    h, w = depth.shape\n",
        "    cx, cy = w / 2, h / 2\n",
        "    depth = np.clip(depth, 0.1, 100)\n",
        "    all_points, all_colors = [], []\n",
        "    for y in range(0, h, stride):\n",
        "        for x in range(0, w, stride):\n",
        "            z = depth[y, x]\n",
        "            if np.isnan(z) or np.isinf(z): continue\n",
        "            X = (x - cx) * z / fx\n",
        "            Y = (y - cy) * z / fy\n",
        "            if np.any(np.isnan([X, Y, z])): continue\n",
        "            all_points.append([X, -Y, -z])\n",
        "            all_colors.append(img_rgb[y, x] / 255.0)\n",
        "    return np.array(all_points), np.array(all_colors)\n",
        "\n",
        "# ğŸ“¸ TRAITEMENT IMAGE UNIQUE\n",
        "if not is_video:\n",
        "    img = cv2.imread(file_path)\n",
        "    if img is None: raise RuntimeError(\"Erreur de chargement de l'image\")\n",
        "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    depth = estimate_depth(img_rgb)\n",
        "    pts, colors = image_to_pointcloud(img_rgb, depth)\n",
        "    print(f\"[LOG] Image : {pts.shape[0]} points gÃ©nÃ©rÃ©s\")\n",
        "else:\n",
        "    # ğŸï¸ TRAITEMENT VIDÃ‰O\n",
        "    cap = cv2.VideoCapture(file_path)\n",
        "    stride, skip = 8, 10\n",
        "    fx = fy = 500\n",
        "    all_points, all_colors = [], []\n",
        "    frame_idx, processed = 0, 0\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret: break\n",
        "        if frame_idx % skip != 0:\n",
        "            frame_idx += 1\n",
        "            continue\n",
        "        img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        depth = estimate_depth(img_rgb)\n",
        "        pts, colors = image_to_pointcloud(img_rgb, depth, fx, fy, stride)\n",
        "        all_points.append(pts)\n",
        "        all_colors.append(colors)\n",
        "        print(f\"[LOG] Frame {frame_idx} â†’ {pts.shape[0]} points\")\n",
        "        frame_idx += 1\n",
        "        processed += 1\n",
        "    cap.release()\n",
        "    if not all_points:\n",
        "        raise RuntimeError(\"Aucun point gÃ©nÃ©rÃ© Ã  partir de la vidÃ©o.\")\n",
        "    pts = np.concatenate(all_points, axis=0)\n",
        "    colors = np.concatenate(all_colors, axis=0)\n",
        "    print(f\"[LOG] VidÃ©o : {pts.shape[0]} points cumulÃ©s depuis {processed} frames\")\n",
        "\n",
        "# ğŸ’¾ CRÃ‰ATION NUAGE DE POINTS\n",
        "pcd = o3d.geometry.PointCloud()\n",
        "pcd.points = o3d.utility.Vector3dVector(pts)\n",
        "pcd.colors = o3d.utility.Vector3dVector(colors)\n",
        "\n",
        "# ğŸ‘ï¸ AFFICHAGE\n",
        "try:\n",
        "    o3d.visualization.draw_geometries([pcd])\n",
        "except Exception as e:\n",
        "    print(f\"[LOG] Avertissement : visualisation non supportÃ©e ici : {e}\")\n",
        "\n",
        "# ğŸ’½ EXPORT\n",
        "output_path = \"scene3d.ply\"\n",
        "o3d.io.write_point_cloud(output_path, pcd)\n",
        "print(f\"[LOG] âœ… Fichier exportÃ© : {output_path}\")\n",
        "\n",
        "# ğŸ“¥ TÃ‰LÃ‰CHARGEMENT\n",
        "try:\n",
        "    files.download(output_path)\n",
        "except Exception as e:\n",
        "    print(f\"[LOG] âš ï¸ Ã‰chec du tÃ©lÃ©chargement : {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oadgw2zVNp0T",
        "outputId": "ff47fc29-6a82-41ef-9c60-1a674ee48815"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m76.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m858.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m447.7/447.7 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m78.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m65.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fr-core-news-md==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_md-3.8.0/fr_core_news_md-3.8.0-py3-none-any.whl (45.8 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m45.8/45.8 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fr-core-news-md\n",
            "Successfully installed fr-core-news-md-3.8.0\n",
            "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('fr_core_news_md')\n",
            "\u001b[38;5;3mâš  Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:3 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,840 kB]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:10 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,764 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:13 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,124 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,461 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,148 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [5,139 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,572 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [4,932 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,267 kB]\n",
            "Fetched 33.6 MB in 4s (8,263 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "zip is already the newest version (3.0-12build2).\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 36 not upgraded.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/intel-isl/MiDaS/zipball/master\" to /root/.cache/torch/hub/master.zip\n",
            "/usr/local/lib/python3.11/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
            "Downloading: \"https://github.com/isl-org/MiDaS/releases/download/v3/dpt_large_384.pt\" to /root/.cache/torch/hub/checkpoints/dpt_large_384.pt\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.28G/1.28G [00:20<00:00, 65.6MB/s]\n",
            "Using cache found in /root/.cache/torch/hub/intel-isl_MiDaS_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "â¬†ï¸ TÃ©lÃ©versez une image (.jpg/.png) ou une vidÃ©o (.mp4)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8c0b4eaf-5a7c-4b95-af4d-2f8838229643\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8c0b4eaf-5a7c-4b95-af4d-2f8838229643\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving output_62079.mp4 to output_62079.mp4\n",
            "[LOG] Frame 0 : 5632 points â†’ video_frames_3d/frame_0000.ply\n",
            "[Analyse NLP] â†’ usÃ©\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 128202 (\\N{BAR CHART}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 600x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LOG] Frame 10 : 5632 points â†’ video_frames_3d/frame_0010.ply\n",
            "[Analyse NLP] â†’ usÃ©\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 600x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LOG] Frame 20 : 5632 points â†’ video_frames_3d/frame_0020.ply\n",
            "[Analyse NLP] â†’ usÃ©\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 600x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LOG] Frame 30 : 5632 points â†’ video_frames_3d/frame_0030.ply\n",
            "[Analyse NLP] â†’ usÃ©\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 600x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LOG] Frame 40 : 5632 points â†’ video_frames_3d/frame_0040.ply\n",
            "[Analyse NLP] â†’ usÃ©\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 600x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LOG] Frame 50 : 5632 points â†’ video_frames_3d/frame_0050.ply\n",
            "[Analyse NLP] â†’ usÃ©\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 600x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LOG] âœ… 6 frames traitÃ©es et analysÃ©es\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_ff4b9986-51be-46c4-be1e-46b3b63670d2\", \"video_frames_3d.zip\", 914464)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# ğŸ“¦ INSTALLATION\n",
        "!pip install -q opencv-python matplotlib timm torch torchvision open3d spacy\n",
        "!python -m spacy download fr_core_news_md\n",
        "!apt-get update && apt-get install -y ffmpeg zip\n",
        "\n",
        "# ğŸ“š IMPORTS\n",
        "import os\n",
        "import cv2\n",
        "import zipfile\n",
        "import torch\n",
        "import numpy as np\n",
        "import open3d as o3d\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "import spacy\n",
        "import random\n",
        "\n",
        "# âš™ï¸ SETUP\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_type = \"DPT_Large\"\n",
        "\n",
        "# ğŸ§  CHARGEMENT MODÃˆLE DE PROFONDEUR\n",
        "midas = torch.hub.load(\"intel-isl/MiDaS\", model_type, trust_repo=True)\n",
        "midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\", trust_repo=True)\n",
        "midas.to(device).eval()\n",
        "transform = midas_transforms.dpt_transform if model_type.startswith(\"DPT\") else midas_transforms.small_transform\n",
        "\n",
        "# ğŸ§  CHARGEMENT SPAcY POUR ANALYSE\n",
        "nlp = spacy.load(\"fr_core_news_md\")\n",
        "\n",
        "# ğŸ“¤ TÃ‰LÃ‰VERSEMENT\n",
        "print(\"â¬†ï¸ TÃ©lÃ©versez une image (.jpg/.png) ou une vidÃ©o (.mp4)\")\n",
        "uploaded = files.upload()\n",
        "file_path = next(iter(uploaded))\n",
        "is_video = file_path.lower().endswith(\".mp4\")\n",
        "\n",
        "# ğŸ“ DOSSIERS OUTPUT\n",
        "os.makedirs(\"output_frames\", exist_ok=True)\n",
        "os.makedirs(\"video_frames_3d\", exist_ok=True)\n",
        "os.makedirs(\"depth_maps\", exist_ok=True)\n",
        "\n",
        "# ğŸ§  ESTIMATION DE PROFONDEUR\n",
        "def estimate_depth(img_rgb):\n",
        "    input_tensor = transform(img_rgb).to(device)\n",
        "    with torch.no_grad():\n",
        "        prediction = midas(input_tensor)\n",
        "        prediction = torch.nn.functional.interpolate(\n",
        "            prediction.unsqueeze(1),\n",
        "            size=img_rgb.shape[:2],\n",
        "            mode=\"bicubic\",\n",
        "            align_corners=False,\n",
        "        ).squeeze()\n",
        "    return prediction.cpu().numpy()\n",
        "\n",
        "# ğŸ¯ CONVERSION EN NUAGE DE POINTS\n",
        "def image_to_pointcloud(img_rgb, depth, fx=500, fy=500, stride=8):\n",
        "    h, w = depth.shape\n",
        "    cx, cy = w / 2, h / 2\n",
        "    depth = np.clip(depth, 0.1, 100)\n",
        "    all_points, all_colors = [], []\n",
        "    for y in range(0, h, stride):\n",
        "        for x in range(0, w, stride):\n",
        "            z = depth[y, x]\n",
        "            if np.isnan(z) or np.isinf(z): continue\n",
        "            X = (x - cx) * z / fx\n",
        "            Y = (y - cy) * z / fy\n",
        "            if np.any(np.isnan([X, Y, z])): continue\n",
        "            all_points.append([X, -Y, -z])\n",
        "            all_colors.append(img_rgb[y, x] / 255.0)\n",
        "    return np.array(all_points), np.array(all_colors)\n",
        "\n",
        "# ğŸ§  ANALYSE PAR spaCy + ModÃ¨le ML fictif\n",
        "def analyze_pointcloud_stats(pts):\n",
        "    mean_height = np.mean(pts[:, 1])\n",
        "    max_depth = np.max(pts[:, 2])\n",
        "    spread = np.std(pts[:, 0])\n",
        "    keywords = []\n",
        "\n",
        "    # PrÃ©dictions simulÃ©es (Ã  remplacer par vrai modÃ¨le ML si dispo)\n",
        "    if max_depth > 10: keywords.append(\"dangereux\")\n",
        "    if mean_height < -1: keywords.append(\"abÃ®mÃ©\")\n",
        "    if spread > 5: keywords.append(\"usÃ©\")\n",
        "    if len(keywords) == 0: keywords.append(\"neuf\")\n",
        "\n",
        "    # NLP spaCy enrichi\n",
        "    doc = nlp(\" \".join(keywords))\n",
        "    print(f\"[Analyse NLP] â†’ {' | '.join([ent.text for ent in doc])}\")\n",
        "\n",
        "    # Visualisation simple\n",
        "    plt.figure(figsize=(6, 3))\n",
        "    plt.bar([\"Hauteur\", \"Profondeur\", \"Dispersion\"], [abs(mean_height), abs(max_depth), spread], color='skyblue')\n",
        "    plt.title(\"ğŸ“Š Analyse structurelle\")\n",
        "    plt.show()\n",
        "\n",
        "    return keywords\n",
        "\n",
        "# ğŸï¸ TRAITEMENT VIDÃ‰O OU IMAGE\n",
        "if is_video:\n",
        "    cap = cv2.VideoCapture(file_path)\n",
        "    stride, skip = 8, 10\n",
        "    fx = fy = 500\n",
        "    frame_idx, processed = 0, 0\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        if frame_idx % skip != 0:\n",
        "            frame_idx += 1\n",
        "            continue\n",
        "\n",
        "        img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        depth = estimate_depth(img_rgb)\n",
        "\n",
        "        # Sauvegarde de la carte de profondeur\n",
        "        plt.imsave(f\"depth_maps/depth_{frame_idx:04d}.png\", depth, cmap=\"inferno\")\n",
        "\n",
        "        pts, colors = image_to_pointcloud(img_rgb, depth, fx, fy, stride)\n",
        "        if pts.shape[0] == 0:\n",
        "            frame_idx += 1\n",
        "            continue\n",
        "\n",
        "        pcd = o3d.geometry.PointCloud()\n",
        "        pcd.points = o3d.utility.Vector3dVector(pts)\n",
        "        pcd.colors = o3d.utility.Vector3dVector(colors)\n",
        "\n",
        "        path = f\"video_frames_3d/frame_{frame_idx:04d}.ply\"\n",
        "        o3d.io.write_point_cloud(path, pcd)\n",
        "        print(f\"[LOG] Frame {frame_idx} : {pts.shape[0]} points â†’ {path}\")\n",
        "\n",
        "        analyze_pointcloud_stats(pts)\n",
        "        frame_idx += 1\n",
        "        processed += 1\n",
        "\n",
        "    cap.release()\n",
        "    print(f\"[LOG] âœ… {processed} frames traitÃ©es et analysÃ©es\")\n",
        "\n",
        "    # CrÃ©ation dâ€™un ZIP\n",
        "    zip_name = \"video_frames_3d.zip\"\n",
        "    with zipfile.ZipFile(zip_name, 'w') as zipf:\n",
        "        for root, _, files_ in os.walk(\"video_frames_3d\"):\n",
        "            for file in files_:\n",
        "                zipf.write(os.path.join(root, file))\n",
        "    files.download(zip_name)\n",
        "\n",
        "else:\n",
        "    # ğŸ“¸ TRAITEMENT IMAGE UNIQUE\n",
        "    img = cv2.imread(file_path)\n",
        "    if img is None:\n",
        "        raise RuntimeError(\"Erreur de chargement de l'image\")\n",
        "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    depth = estimate_depth(img_rgb)\n",
        "    plt.imsave(\"depth_maps/depth_image.png\", depth, cmap=\"inferno\")\n",
        "\n",
        "    pts, colors = image_to_pointcloud(img_rgb, depth)\n",
        "    pcd = o3d.geometry.PointCloud()\n",
        "    pcd.points = o3d.utility.Vector3dVector(pts)\n",
        "    pcd.colors = o3d.utility.Vector3dVector(colors)\n",
        "\n",
        "    output_path = \"output_frames/scene3d.ply\"\n",
        "    o3d.io.write_point_cloud(output_path, pcd)\n",
        "    print(f\"[LOG] âœ… Image â†’ {pts.shape[0]} points exportÃ©s\")\n",
        "\n",
        "    analyze_pointcloud_stats(pts)\n",
        "    files.download(output_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Wylvp5S3qm45",
        "outputId": "9c7a8049-9b8e-4a83-d7ac-d1f063c62991"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting open3d\n",
            "  Downloading open3d-0.19.0-cp311-cp311-manylinux_2_31_x86_64.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.31.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.11/dist-packages (from open3d) (2.0.2)\n",
            "Collecting dash>=2.6.0 (from open3d)\n",
            "  Downloading dash-3.1.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: werkzeug>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from open3d) (3.1.3)\n",
            "Requirement already satisfied: flask>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from open3d) (3.1.1)\n",
            "Requirement already satisfied: nbformat>=5.7.0 in /usr/local/lib/python3.11/dist-packages (from open3d) (5.10.4)\n",
            "Collecting configargparse (from open3d)\n",
            "  Downloading configargparse-1.7.1-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting ipywidgets>=8.0.4 (from open3d)\n",
            "  Downloading ipywidgets-8.1.7-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting addict (from open3d)\n",
            "  Downloading addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: pillow>=9.3.0 in /usr/local/lib/python3.11/dist-packages (from open3d) (11.2.1)\n",
            "Requirement already satisfied: matplotlib>=3 in /usr/local/lib/python3.11/dist-packages (from open3d) (3.10.0)\n",
            "Requirement already satisfied: pyyaml>=5.4.1 in /usr/local/lib/python3.11/dist-packages (from open3d) (6.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from open3d) (4.67.1)\n",
            "Collecting pyquaternion (from open3d)\n",
            "  Downloading pyquaternion-0.9.9-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.116.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.6.0)\n",
            "Requirement already satisfied: gradio-client==1.10.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.10.1)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.33.4)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.11.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.7)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.12.3)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.47.1)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.14.1)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.35.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (15.0.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.73.1)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: plotly>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from dash>=2.6.0->open3d) (5.24.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from dash>=2.6.0->open3d) (8.7.0)\n",
            "Collecting retrying (from dash>=2.6.0->open3d)\n",
            "  Downloading retrying-1.4.1-py3-none-any.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from dash>=2.6.0->open3d) (1.6.0)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from flask>=3.0.0->open3d) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask>=3.0.0->open3d) (8.2.1)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from flask>=3.0.0->open3d) (2.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (1.1.5)\n",
            "Collecting comm>=0.1.3 (from ipywidgets>=8.0.4->open3d)\n",
            "  Downloading comm-0.2.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.0.4->open3d) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.0.4->open3d) (5.7.1)\n",
            "Collecting widgetsnbextension~=4.0.14 (from ipywidgets>=8.0.4->open3d)\n",
            "  Downloading widgetsnbextension-4.0.14-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.0.4->open3d) (3.0.15)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3->open3d) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3->open3d) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3->open3d) (4.58.5)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3->open3d) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3->open3d) (3.2.3)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.7.0->open3d) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.7.0->open3d) (4.24.0)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.7.0->open3d) (5.8.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Collecting jedi>=0.16 (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (3.0.51)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (4.9.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (0.26.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core!=5.0.*,>=4.12->nbformat>=5.7.0->open3d) (4.3.8)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly>=5.0.0->dash>=2.6.0->open3d) (8.5.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->dash>=2.6.0->open3d) (3.23.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.8.4)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.13)\n",
            "Downloading open3d-0.19.0-cp311-cp311-manylinux_2_31_x86_64.whl (447.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m447.7/447.7 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dash-3.1.1-py3-none-any.whl (7.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ipywidgets-8.1.7-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Downloading configargparse-1.7.1-py3-none-any.whl (25 kB)\n",
            "Downloading pyquaternion-0.9.9-py3-none-any.whl (14 kB)\n",
            "Downloading comm-0.2.2-py3-none-any.whl (7.2 kB)\n",
            "Downloading widgetsnbextension-4.0.14-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading retrying-1.4.1-py3-none-any.whl (12 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: addict, widgetsnbextension, retrying, pyquaternion, jedi, configargparse, comm, ipywidgets, dash, open3d\n",
            "  Attempting uninstall: widgetsnbextension\n",
            "    Found existing installation: widgetsnbextension 3.6.10\n",
            "    Uninstalling widgetsnbextension-3.6.10:\n",
            "      Successfully uninstalled widgetsnbextension-3.6.10\n",
            "  Attempting uninstall: ipywidgets\n",
            "    Found existing installation: ipywidgets 7.7.1\n",
            "    Uninstalling ipywidgets-7.7.1:\n",
            "      Successfully uninstalled ipywidgets-7.7.1\n",
            "Successfully installed addict-2.4.0 comm-0.2.2 configargparse-1.7.1 dash-3.1.1 ipywidgets-8.1.7 jedi-0.19.2 open3d-0.19.0 pyquaternion-0.9.9 retrying-1.4.1 widgetsnbextension-4.0.14\n",
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://3a0394de9eaa733e19.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://3a0394de9eaa733e19.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ğŸ“Œ NOM : topo_ai_trainer.ipynb\n",
        "# Utilise TensorFlow + open3d + Gradio pour IA topographique\n",
        "\n",
        "!pip install open3d gradio tensorflow scikit-learn pandas\n",
        "\n",
        "import open3d as o3d\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import gradio as gr\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# ğŸ“¥ Chargement d'un nuage de points\n",
        "def load_point_cloud(file):\n",
        "    pcd = o3d.io.read_point_cloud(file.name)\n",
        "    return np.asarray(pcd.points)\n",
        "\n",
        "# ğŸ§  CrÃ©ation d'un modÃ¨le simple pour classifier le terrain\n",
        "def create_model(input_dim):\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(64, activation='relu', input_shape=(input_dim,)),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(4, activation='softmax')  # 4 classes: plat, pente, sommet, cuvette\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# ğŸ“Š Exemple de gÃ©nÃ©ration de donnÃ©es topographiques fictives\n",
        "def generate_fake_data(points):\n",
        "    X = points[:, :3]  # x, y, z\n",
        "    y = []\n",
        "    for pt in X:\n",
        "        if pt[2] < 0.2:\n",
        "            y.append([1,0,0,0])  # plat\n",
        "        elif pt[2] < 0.5:\n",
        "            y.append([0,1,0,0])  # pente\n",
        "        elif pt[2] < 0.8:\n",
        "            y.append([0,0,1,0])  # sommet\n",
        "        else:\n",
        "            y.append([0,0,0,1])  # cuvette\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# ğŸ” EntraÃ®nement\n",
        "def train_model(file):\n",
        "    points = load_point_cloud(file)\n",
        "    X, y = generate_fake_data(points)\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2)\n",
        "    model = create_model(X_train.shape[1])\n",
        "    model.fit(X_train, y_train, epochs=10, batch_size=16)\n",
        "    acc = model.evaluate(X_test, y_test)[1]\n",
        "    return f\"ModÃ¨le entraÃ®nÃ© avec {acc*100:.2f}% de prÃ©cision.\"\n",
        "\n",
        "# ğŸ§ª Interface Gradio\n",
        "iface = gr.Interface(\n",
        "    fn=train_model,\n",
        "    inputs=gr.File(label=\"Charger un fichier .ply\"),\n",
        "    outputs=\"text\",\n",
        "    title=\"EntraÃ®nement IA Topographique\"\n",
        ")\n",
        "\n",
        "iface.launch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nPVfYE2QO7Te",
        "outputId": "1ad88aff-db83-44de-ca86-e3a9eb0f76fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m75.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m447.7/447.7 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,840 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:12 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,128 kB]\n",
            "Get:13 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,267 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,572 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [4,932 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,461 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,148 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [5,139 kB]\n",
            "Get:19 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,764 kB]\n",
            "Fetched 33.6 MB in 4s (9,554 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 36 not upgraded.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/intel-isl/MiDaS/zipball/master\" to /root/.cache/torch/hub/master.zip\n",
            "/usr/local/lib/python3.11/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
            "Downloading: \"https://github.com/isl-org/MiDaS/releases/download/v3/dpt_large_384.pt\" to /root/.cache/torch/hub/checkpoints/dpt_large_384.pt\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.28G/1.28G [00:25<00:00, 53.5MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "â¬†ï¸ TÃ©lÃ©versez une image...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/intel-isl_MiDaS_master\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-542b6ca8-3915-4196-ad21-b629b11090c9\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-542b6ca8-3915-4196-ad21-b629b11090c9\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving IMG-20250226-WA0017.jpg to IMG-20250226-WA0017.jpg\n",
            "[LOG] NettetÃ© OK (Laplacian: 8412.02)\n",
            "\u001b[1;33m[Open3D WARNING] GLFW Error: Failed to detect any supported platform\u001b[0;m\n",
            "\u001b[1;33m[Open3D WARNING] GLFW initialized for headless rendering.\u001b[0;m\n",
            "\u001b[1;33m[Open3D WARNING] GLFW Error: OSMesa: Library not found\u001b[0;m\n",
            "\u001b[1;33m[Open3D WARNING] Failed to create window\u001b[0;m\n",
            "\u001b[1;33m[Open3D WARNING] [DrawGeometries] Failed creating OpenGL window.\u001b[0;m\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_901da362-0e5d-4259-b83e-40f2d1008aa4\", \"scene3d_corrected.ply\", 83151)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[âœ… FIN] Rendu 3D avec amÃ©liorations complÃ¨tes et export rÃ©ussi.\n"
          ]
        }
      ],
      "source": [
        "# ğŸ“¦ INSTALLATION (exÃ©cuter une seule fois)\n",
        "!pip install -q opencv-python-headless pillow imageio matplotlib timm torch torchvision open3d\n",
        "!apt-get update && apt-get install -y ffmpeg\n",
        "\n",
        "# ğŸ“š IMPORTS\n",
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "import open3d as o3d\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ExifTags, ImageEnhance, ImageFilter\n",
        "from google.colab import files\n",
        "import torchvision.transforms as T\n",
        "\n",
        "# ğŸ”„ SETUP\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "os.makedirs(\"output_frames\", exist_ok=True)\n",
        "\n",
        "# ğŸ” CHARGEMENT MiDaS\n",
        "model_type = \"DPT_Large\"\n",
        "midas = torch.hub.load(\"intel-isl/MiDaS\", model_type, trust_repo=True).to(device).eval()\n",
        "midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\", trust_repo=True)\n",
        "transform = midas_transforms.dpt_transform if model_type.startswith(\"DPT\") else midas_transforms.small_transform\n",
        "\n",
        "# ğŸ§¼ PRÃ‰TRAITEMENT AVANCÃ‰\n",
        "def enhance_image(image: Image.Image) -> Image.Image:\n",
        "    enhancer = ImageEnhance.Contrast(image)\n",
        "    image = enhancer.enhance(1.8)\n",
        "\n",
        "    enhancer = ImageEnhance.Sharpness(image)\n",
        "    image = enhancer.enhance(2.0)\n",
        "\n",
        "    image = image.filter(ImageFilter.EDGE_ENHANCE_MORE)\n",
        "    return image\n",
        "\n",
        "def correct_orientation(image: Image.Image) -> Image.Image:\n",
        "    try:\n",
        "        for orientation in ExifTags.TAGS.keys():\n",
        "            if ExifTags.TAGS[orientation] == 'Orientation':\n",
        "                break\n",
        "        exif = dict(image._getexif().items())\n",
        "        if exif.get(orientation) == 3:\n",
        "            image = image.rotate(180, expand=True)\n",
        "        elif exif.get(orientation) == 6:\n",
        "            image = image.rotate(270, expand=True)\n",
        "        elif exif.get(orientation) == 8:\n",
        "            image = image.rotate(90, expand=True)\n",
        "    except:\n",
        "        pass\n",
        "    return image\n",
        "\n",
        "def load_and_prepare_image(image_path, target_max_size=512):\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    image = correct_orientation(image)\n",
        "\n",
        "    max_dim = max(image.size)\n",
        "    if max_dim > target_max_size:\n",
        "        scale = target_max_size / max_dim\n",
        "        image = image.resize((int(image.size[0]*scale), int(image.size[1]*scale)), Image.LANCZOS)\n",
        "\n",
        "    image = enhance_image(image)\n",
        "    return np.array(image)\n",
        "\n",
        "# ğŸ” DÃ‰TECTION Dâ€™ANOMALIES\n",
        "def check_image_quality(img):\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "    lap_var = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
        "    if lap_var < 50:\n",
        "        print(f\"[ALERTE] Image floue (Laplacian: {lap_var:.2f})\")\n",
        "    else:\n",
        "        print(f\"[LOG] NettetÃ© OK (Laplacian: {lap_var:.2f})\")\n",
        "\n",
        "    if img.std() < 10:\n",
        "        raise ValueError(\"Image trop plate (faible contraste)\")\n",
        "    if img.mean() < 10:\n",
        "        raise ValueError(\"Image trop sombre\")\n",
        "\n",
        "# ğŸ§  INPAINTING POUR COMPLÃ‰TION AUTOMATIQUE (zones noires ou plates)\n",
        "def auto_inpaint(img):\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "    _, mask = cv2.threshold(gray, 5, 255, cv2.THRESH_BINARY_INV)\n",
        "    inpainted = cv2.inpaint(img, mask, 3, cv2.INPAINT_TELEA)\n",
        "    return inpainted\n",
        "\n",
        "# ğŸ“¤ UPLOAD IMAGE\n",
        "print(\"â¬†ï¸ TÃ©lÃ©versez une image...\")\n",
        "uploaded = files.upload()\n",
        "image_path = next(iter(uploaded))\n",
        "\n",
        "# ğŸ§½ TRAITEMENT\n",
        "img_rgb = load_and_prepare_image(image_path)\n",
        "check_image_quality(img_rgb)\n",
        "\n",
        "# Sauvegarde prÃ©visualisation\n",
        "plt.imsave(\"output_frames/corrected_input.png\", img_rgb)\n",
        "\n",
        "# Inpainting zones sombres\n",
        "img_rgb = auto_inpaint(img_rgb)\n",
        "\n",
        "# ğŸ” MIDAS - PRÃ‰DICTION\n",
        "input_tensor = transform(img_rgb).to(device)\n",
        "with torch.no_grad():\n",
        "    prediction = midas(input_tensor)\n",
        "    prediction = torch.nn.functional.interpolate(\n",
        "        prediction.unsqueeze(1),\n",
        "        size=img_rgb.shape[:2],\n",
        "        mode=\"bicubic\",\n",
        "        align_corners=False,\n",
        "    ).squeeze()\n",
        "\n",
        "depth = prediction.cpu().numpy()\n",
        "plt.imsave(\"output_frames/depth_map.png\", depth, cmap=\"inferno\")\n",
        "\n",
        "# ğŸ“Œ PARAMÃˆTRES 3D\n",
        "fx, fy = 500, 500\n",
        "h, w = depth.shape\n",
        "cx, cy = w / 2, h / 2\n",
        "depth = np.clip(depth, 0.1, 100)\n",
        "\n",
        "# ğŸ“ GÃ‰NÃ‰RATION DU NUAGE DE POINTS\n",
        "all_points, all_colors = [], []\n",
        "for y in range(0, h, 8):\n",
        "    for x in range(0, w, 8):\n",
        "        z = depth[y, x]\n",
        "        if np.isnan(z) or np.isinf(z): continue\n",
        "        X = (x - cx) * z / fx\n",
        "        Y = (y - cy) * z / fy\n",
        "        all_points.append([X, -Y, -z])\n",
        "        all_colors.append(img_rgb[y, x] / 255.0)\n",
        "\n",
        "if not all_points:\n",
        "    raise RuntimeError(\"âŒ Aucun point 3D dÃ©tectÃ© !\")\n",
        "\n",
        "pcd = o3d.geometry.PointCloud()\n",
        "pcd.points = o3d.utility.Vector3dVector(np.array(all_points))\n",
        "pcd.colors = o3d.utility.Vector3dVector(np.array(all_colors))\n",
        "\n",
        "# ğŸŒ VISUALISATION ET EXPORT\n",
        "try:\n",
        "    o3d.visualization.draw_geometries([pcd])\n",
        "except:\n",
        "    print(\"[LOG] Visualisation dÃ©sactivÃ©e (Colab)\")\n",
        "\n",
        "output_file = \"scene3d_corrected.ply\"\n",
        "o3d.io.write_point_cloud(output_file, pcd)\n",
        "files.download(output_file)\n",
        "\n",
        "print(\"[âœ… FIN] Rendu 3D avec amÃ©liorations complÃ¨tes et export rÃ©ussi.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 856
        },
        "id": "430hi9yQS6Sp",
        "outputId": "90baef8a-5074-4247-a066-b24b661cd321"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "Hit:1 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 36 not upgraded.\n",
            "Chargement du modÃ¨le MiDaS...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/intel-isl_MiDaS_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "â¬†ï¸ TÃ©lÃ©versez votre image...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/intel-isl_MiDaS_master\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1751c5f2-bb0a-4b55-91b7-aae3f964c7e2\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1751c5f2-bb0a-4b55-91b7-aae3f964c7e2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving 20250719_202118.jpg to 20250719_202118 (2).jpg\n",
            "[1/6] Chargement et prÃ©traitement de l'image...\n",
            "[LOG] NettetÃ© OK (Laplacian: 47787.33)\n",
            "[2/6] Inpainting automatique des zones sombres...\n",
            "[3/6] Segmentation sÃ©mantique en cours...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DeepLabV3_ResNet50_Weights.COCO_WITH_VOC_LABELS_V1`. You can also use `weights=DeepLabV3_ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/deeplabv3_resnet50_coco-cd0a2569.pth\" to /root/.cache/torch/hub/checkpoints/deeplabv3_resnet50_coco-cd0a2569.pth\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 161M/161M [00:02<00:00, 63.0MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LOG] Carte de segmentation sauvegardÃ©e.\n",
            "[4/6] AmÃ©lioration super-rÃ©solution (bicubique)...\n",
            "[5/6] Estimation profondeur MiDaS sur l'image SR...\n",
            "[LOG] Carte de profondeur sauvegardÃ©e.\n",
            "[6/6] GÃ©nÃ©ration du nuage de points 3D...\n",
            "\u001b[1;33m[Open3D WARNING] GLFW initialized for headless rendering.\u001b[0;m\n",
            "\u001b[1;33m[Open3D WARNING] GLFW Error: OSMesa: Library not found\u001b[0;m\n",
            "\u001b[1;33m[Open3D WARNING] Failed to create window\u001b[0;m\n",
            "\u001b[1;33m[Open3D WARNING] [DrawGeometries] Failed creating OpenGL window.\u001b[0;m\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_9854b787-25be-4a64-9039-1b39a8bcbff9\", \"scene3d_full_pipeline.ply\", 331984)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[âœ… FIN] Pipeline complet exÃ©cutÃ© et fichier 3D exportÃ©.\n"
          ]
        }
      ],
      "source": [
        "# --- INSTALLATION ---\n",
        "!pip install -q opencv-python-headless pillow imageio matplotlib timm torch torchvision open3d segmentation-models-pytorch\n",
        "!apt-get update && apt-get install -y ffmpeg\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "import open3d as o3d\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ExifTags, ImageEnhance, ImageFilter\n",
        "from google.colab import files\n",
        "import torchvision.transforms as T\n",
        "from torchvision.models.segmentation import deeplabv3_resnet50\n",
        "\n",
        "# --- SETUP ---\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "os.makedirs(\"output_frames\", exist_ok=True)\n",
        "\n",
        "# --- Fonctions Utilitaires ---\n",
        "\n",
        "def correct_orientation(image: Image.Image) -> Image.Image:\n",
        "    try:\n",
        "        for orientation in ExifTags.TAGS.keys():\n",
        "            if ExifTags.TAGS[orientation] == 'Orientation':\n",
        "                break\n",
        "        exif = dict(image._getexif().items())\n",
        "        orientation_value = exif.get(orientation, None)\n",
        "        if orientation_value == 3:\n",
        "            image = image.rotate(180, expand=True)\n",
        "        elif orientation_value == 6:\n",
        "            image = image.rotate(270, expand=True)\n",
        "        elif orientation_value == 8:\n",
        "            image = image.rotate(90, expand=True)\n",
        "    except:\n",
        "        pass\n",
        "    return image\n",
        "\n",
        "def enhance_image(image: Image.Image) -> Image.Image:\n",
        "    enhancer = ImageEnhance.Contrast(image)\n",
        "    image = enhancer.enhance(1.8)\n",
        "    enhancer = ImageEnhance.Sharpness(image)\n",
        "    image = enhancer.enhance(2.0)\n",
        "    image = image.filter(ImageFilter.EDGE_ENHANCE_MORE)\n",
        "    return image\n",
        "\n",
        "def load_and_prepare_image(image_path, target_max_size=512):\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    image = correct_orientation(image)\n",
        "    max_dim = max(image.size)\n",
        "    if max_dim > target_max_size:\n",
        "        scale = target_max_size / max_dim\n",
        "        image = image.resize((int(image.size[0]*scale), int(image.size[1]*scale)), Image.LANCZOS)\n",
        "    image = enhance_image(image)\n",
        "    return np.array(image)\n",
        "\n",
        "def check_image_quality(img):\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "    lap_var = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
        "    if lap_var < 50:\n",
        "        print(f\"[ALERTE] Image floue (Laplacian: {lap_var:.2f})\")\n",
        "    else:\n",
        "        print(f\"[LOG] NettetÃ© OK (Laplacian: {lap_var:.2f})\")\n",
        "    if img.std() < 10:\n",
        "        raise ValueError(\"Image trop plate (faible contraste)\")\n",
        "    if img.mean() < 10:\n",
        "        raise ValueError(\"Image trop sombre\")\n",
        "\n",
        "def auto_inpaint(img):\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "    _, mask = cv2.threshold(gray, 5, 255, cv2.THRESH_BINARY_INV)\n",
        "    inpainted = cv2.inpaint(img, mask, 3, cv2.INPAINT_TELEA)\n",
        "    return inpainted\n",
        "\n",
        "# --- Segmentation sÃ©mantique ---\n",
        "\n",
        "def run_segmentation(img_rgb):\n",
        "    model = deeplabv3_resnet50(pretrained=True).to(device)\n",
        "    model.eval()\n",
        "    preprocess = T.Compose([\n",
        "        T.ToTensor(),\n",
        "        T.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                    std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "    input_tensor = preprocess(Image.fromarray(img_rgb)).unsqueeze(0).to(device)\n",
        "    with torch.no_grad():\n",
        "        output = model(input_tensor)['out'][0]\n",
        "    output_predictions = output.argmax(0).byte().cpu().numpy()\n",
        "    return output_predictions\n",
        "\n",
        "def colorize_segmentation(segmentation):\n",
        "    # Couleurs simples pour les classes (21 classes)\n",
        "    palette = np.array([\n",
        "        [0, 0, 0],        # fond\n",
        "        [128, 0, 0],      # aeroplane\n",
        "        [0, 128, 0],      # bicycle\n",
        "        [128, 128, 0],    # bird\n",
        "        [0, 0, 128],      # boat\n",
        "        [128, 0, 128],    # bottle\n",
        "        [0, 128, 128],    # bus\n",
        "        [128, 128, 128],  # car\n",
        "        [64, 0, 0],       # cat\n",
        "        [192, 0, 0],      # chair\n",
        "        [64, 128, 0],     # cow\n",
        "        [192, 128, 0],    # diningtable\n",
        "        [64, 0, 128],     # dog\n",
        "        [192, 0, 128],    # horse\n",
        "        [64, 128, 128],   # motorbike\n",
        "        [192, 128, 128],  # person\n",
        "        [0, 64, 0],       # potted plant\n",
        "        [128, 64, 0],     # sheep\n",
        "        [0, 192, 0],      # sofa\n",
        "        [128, 192, 0],    # train\n",
        "        [0, 64, 128],     # tv/monitor\n",
        "    ])\n",
        "    color_seg = palette[segmentation % 21]\n",
        "    return color_seg.astype(np.uint8)\n",
        "\n",
        "# --- Super-rÃ©solution simplifiÃ©e (interpolation bicubique ici, tu peux remplacer par ESRGAN) ---\n",
        "\n",
        "def super_resolution(img_rgb, scale=2):\n",
        "    h, w = img_rgb.shape[:2]\n",
        "    new_h, new_w = h*scale, w*scale\n",
        "    img_sr = cv2.resize(img_rgb, (new_w, new_h), interpolation=cv2.INTER_CUBIC)\n",
        "    return img_sr\n",
        "\n",
        "# --- Chargement MiDaS ---\n",
        "\n",
        "print(\"Chargement du modÃ¨le MiDaS...\")\n",
        "model_type = \"DPT_Large\"\n",
        "midas = torch.hub.load(\"intel-isl/MiDaS\", model_type, trust_repo=True).to(device).eval()\n",
        "midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\", trust_repo=True)\n",
        "transform = midas_transforms.dpt_transform if model_type.startswith(\"DPT\") else midas_transforms.small_transform\n",
        "\n",
        "# --- Upload image ---\n",
        "print(\"â¬†ï¸ TÃ©lÃ©versez votre image...\")\n",
        "uploaded = files.upload()\n",
        "image_path = next(iter(uploaded))\n",
        "\n",
        "# --- Pipeline complet ---\n",
        "print(\"[1/6] Chargement et prÃ©traitement de l'image...\")\n",
        "img_rgb = load_and_prepare_image(image_path)\n",
        "check_image_quality(img_rgb)\n",
        "\n",
        "print(\"[2/6] Inpainting automatique des zones sombres...\")\n",
        "img_rgb = auto_inpaint(img_rgb)\n",
        "\n",
        "print(\"[3/6] Segmentation sÃ©mantique en cours...\")\n",
        "segmentation = run_segmentation(img_rgb)\n",
        "color_seg = colorize_segmentation(segmentation)\n",
        "plt.imsave(\"output_frames/segmentation.png\", color_seg)\n",
        "print(\"[LOG] Carte de segmentation sauvegardÃ©e.\")\n",
        "\n",
        "print(\"[4/6] AmÃ©lioration super-rÃ©solution (bicubique)...\")\n",
        "img_sr = super_resolution(img_rgb, scale=2)\n",
        "plt.imsave(\"output_frames/super_resolution.png\", img_sr)\n",
        "\n",
        "print(\"[5/6] Estimation profondeur MiDaS sur l'image SR...\")\n",
        "input_tensor = transform(img_sr).to(device)\n",
        "with torch.no_grad():\n",
        "    prediction = midas(input_tensor)\n",
        "    prediction = torch.nn.functional.interpolate(\n",
        "        prediction.unsqueeze(1),\n",
        "        size=img_sr.shape[:2],\n",
        "        mode=\"bicubic\",\n",
        "        align_corners=False,\n",
        "    ).squeeze()\n",
        "depth = prediction.cpu().numpy()\n",
        "plt.imsave(\"output_frames/depth_map.png\", depth, cmap=\"inferno\")\n",
        "print(\"[LOG] Carte de profondeur sauvegardÃ©e.\")\n",
        "\n",
        "print(\"[6/6] GÃ©nÃ©ration du nuage de points 3D...\")\n",
        "fx, fy = 500, 500\n",
        "h, w = depth.shape\n",
        "cx, cy = w / 2, h / 2\n",
        "depth = np.clip(depth, 0.1, 100)\n",
        "\n",
        "all_points, all_colors = [], []\n",
        "stride = 8\n",
        "for y in range(0, h, stride):\n",
        "    for x in range(0, w, stride):\n",
        "        z = depth[y, x]\n",
        "        if np.isnan(z) or np.isinf(z):\n",
        "            continue\n",
        "        X = (x - cx) * z / fx\n",
        "        Y = (y - cy) * z / fy\n",
        "        all_points.append([X, -Y, -z])\n",
        "        # Couleur depuis l'image super-rÃ©solution (index possible hors limite, on clamp)\n",
        "        c_x, c_y = min(x, img_sr.shape[1]-1), min(y, img_sr.shape[0]-1)\n",
        "        all_colors.append(img_sr[c_y, c_x] / 255.0)\n",
        "\n",
        "if not all_points:\n",
        "    raise RuntimeError(\"âŒ Aucun point valide gÃ©nÃ©rÃ© !\")\n",
        "\n",
        "pcd = o3d.geometry.PointCloud()\n",
        "pcd.points = o3d.utility.Vector3dVector(np.array(all_points))\n",
        "pcd.colors = o3d.utility.Vector3dVector(np.array(all_colors))\n",
        "\n",
        "try:\n",
        "    o3d.visualization.draw_geometries([pcd])\n",
        "except:\n",
        "    print(\"[LOG] Visualisation dÃ©sactivÃ©e (environnement non supportÃ©)\")\n",
        "\n",
        "output_file = \"scene3d_full_pipeline.ply\"\n",
        "o3d.io.write_point_cloud(output_file, pcd)\n",
        "files.download(output_file)\n",
        "\n",
        "print(\"[âœ… FIN] Pipeline complet exÃ©cutÃ© et fichier 3D exportÃ©.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4qTEPUbBYGUa",
        "outputId": "f73fd21a-8708-4bef-a249-3f369c25c42c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,840 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:8 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,764 kB]\n",
            "Get:9 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,267 kB]\n",
            "Hit:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:12 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,148 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:14 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,128 kB]\n",
            "Hit:15 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [4,932 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [5,139 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,461 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,572 kB]\n",
            "Fetched 33.6 MB in 3s (11.6 MB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 36 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!pip install -q opencv-python-headless pillow imageio matplotlib timm torch torchvision open3d segmentation-models-pytorch\n",
        "!apt-get update && apt-get install -y ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 526
        },
        "id": "_sXjWqDTYKw4",
        "outputId": "7c430e3c-a653-4659-95e8-90ef18dedbbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chargement MiDaS...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/intel-isl_MiDaS_master\n",
            "/usr/local/lib/python3.11/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "â¬†ï¸ Upload image pour reconstruction...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/intel-isl_MiDaS_master\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-33378c0d-4939-4871-9afb-3abac5044469\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-33378c0d-4939-4871-9afb-3abac5044469\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 20250719_220835.jpg to 20250719_220835 (1).jpg\n",
            "[1/6] PrÃ©traitement image...\n",
            "[LOG] NettetÃ© (Laplacian): 31067.61\n",
            "[2/6] Inpainting zones sombres...\n",
            "[3/6] Segmentation sÃ©mantique...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DeepLabV3_ResNet50_Weights.COCO_WITH_VOC_LABELS_V1`. You can also use `weights=DeepLabV3_ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4/6] Super-rÃ©solution...\n",
            "[5/6] Profondeur avec MiDaS...\n",
            "[6/6] Nuage de points 3D texturÃ©...\n",
            "\u001b[1;33m[Open3D WARNING] GLFW Error: Failed to detect any supported platform\u001b[0;m\n",
            "\u001b[1;33m[Open3D WARNING] GLFW initialized for headless rendering.\u001b[0;m\n",
            "\u001b[1;33m[Open3D WARNING] GLFW Error: OSMesa: Library not found\u001b[0;m\n",
            "\u001b[1;33m[Open3D WARNING] Failed to create window\u001b[0;m\n",
            "\u001b[1;33m[Open3D WARNING] [DrawGeometries] Failed creating OpenGL window.\u001b[0;m\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_edfa48eb-3274-4eae-abc1-ad30fae3af2d\", \"scene3d_splatting.ply\", 1327312)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… TerminÃ©. Nuage de points 3D exportÃ©.\n"
          ]
        }
      ],
      "source": [
        "# colorÃ© nuage et amÃ©lioration\n",
        "# âœ… IMPORTS\n",
        "import os, cv2, torch\n",
        "import numpy as np\n",
        "import open3d as o3d\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ExifTags, ImageEnhance, ImageFilter\n",
        "from google.colab import files\n",
        "import torchvision.transforms as T\n",
        "from torchvision.models.segmentation import deeplabv3_resnet50\n",
        "\n",
        "# âœ… SETUP\n",
        "torch.manual_seed(42)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "os.makedirs(\"output_frames\", exist_ok=True)\n",
        "\n",
        "# âœ… UTILS\n",
        "def correct_orientation(image: Image.Image) -> Image.Image:\n",
        "    try:\n",
        "        for orientation in ExifTags.TAGS.keys():\n",
        "            if ExifTags.TAGS[orientation] == 'Orientation':\n",
        "                break\n",
        "        exif = dict(image._getexif().items())\n",
        "        orientation_value = exif.get(orientation, None)\n",
        "        if orientation_value == 3:\n",
        "            image = image.rotate(180, expand=True)\n",
        "        elif orientation_value == 6:\n",
        "            image = image.rotate(270, expand=True)\n",
        "        elif orientation_value == 8:\n",
        "            image = image.rotate(90, expand=True)\n",
        "    except: pass\n",
        "    return image\n",
        "\n",
        "def enhance_image(image: Image.Image) -> Image.Image:\n",
        "    image = ImageEnhance.Contrast(image).enhance(1.8)\n",
        "    image = ImageEnhance.Sharpness(image).enhance(2.0)\n",
        "    image = image.filter(ImageFilter.EDGE_ENHANCE_MORE)\n",
        "    return image\n",
        "\n",
        "def load_and_prepare_image(image_path, target_max_size=512):\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    image = correct_orientation(image)\n",
        "    max_dim = max(image.size)\n",
        "    if max_dim > target_max_size:\n",
        "        scale = target_max_size / max_dim\n",
        "        image = image.resize((int(image.size[0]*scale), int(image.size[1]*scale)), Image.LANCZOS)\n",
        "    image = enhance_image(image)\n",
        "    return np.array(image)  # âœ… Fix ici : on retourne un tableau NumPy\n",
        "\n",
        "def check_image_quality(img):\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "    lap_var = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
        "    print(f\"[LOG] NettetÃ© (Laplacian): {lap_var:.2f}\")\n",
        "    if img.std() < 10: raise ValueError(\"Image trop plate (contraste)\")\n",
        "    if img.mean() < 10: raise ValueError(\"Image trop sombre\")\n",
        "\n",
        "def auto_inpaint(img):\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "    _, mask = cv2.threshold(gray, 5, 255, cv2.THRESH_BINARY_INV)\n",
        "    return cv2.inpaint(img, mask, 3, cv2.INPAINT_TELEA)\n",
        "\n",
        "# âœ… SEGMENTATION DEEPLAB\n",
        "def run_segmentation(img_rgb):\n",
        "    model = deeplabv3_resnet50(pretrained=True).to(device)\n",
        "    model.eval()\n",
        "    preprocess = T.Compose([\n",
        "        T.ToTensor(),\n",
        "        T.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                    std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "    input_tensor = preprocess(Image.fromarray(img_rgb)).unsqueeze(0).to(device)\n",
        "    with torch.no_grad():\n",
        "        output = model(input_tensor)['out'][0]\n",
        "    return output.argmax(0).byte().cpu().numpy()\n",
        "\n",
        "def colorize_segmentation(seg):\n",
        "    palette = np.array([\n",
        "        [0,0,0],[128,0,0],[0,128,0],[128,128,0],[0,0,128],\n",
        "        [128,0,128],[0,128,128],[128,128,128],[64,0,0],[192,0,0],\n",
        "        [64,128,0],[192,128,0],[64,0,128],[192,0,128],[64,128,128],\n",
        "        [192,128,128],[0,64,0],[128,64,0],[0,192,0],[128,192,0],\n",
        "        [0,64,128]\n",
        "    ])\n",
        "    return palette[seg % 21].astype(np.uint8)\n",
        "\n",
        "def super_resolution(img, scale=2):\n",
        "    return cv2.resize(img, (img.shape[1]*scale, img.shape[0]*scale), interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "# âœ… MIDAS SETUP\n",
        "print(\"Chargement MiDaS...\")\n",
        "model_type = \"DPT_Large\"\n",
        "midas = torch.hub.load(\"intel-isl/MiDaS\", model_type, trust_repo=True).to(device).eval()\n",
        "midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\", trust_repo=True)\n",
        "transform = midas_transforms.dpt_transform\n",
        "\n",
        "# âœ… UPLOAD IMAGE\n",
        "print(\"â¬†ï¸ Upload image pour reconstruction...\")\n",
        "uploaded = files.upload()\n",
        "image_path = next(iter(uploaded))\n",
        "\n",
        "# âœ… PIPELINE\n",
        "print(\"[1/6] PrÃ©traitement image...\")\n",
        "img_rgb = load_and_prepare_image(image_path)\n",
        "check_image_quality(img_rgb)\n",
        "\n",
        "print(\"[2/6] Inpainting zones sombres...\")\n",
        "img_rgb = auto_inpaint(img_rgb)\n",
        "\n",
        "print(\"[3/6] Segmentation sÃ©mantique...\")\n",
        "seg = run_segmentation(img_rgb)\n",
        "color_seg = colorize_segmentation(seg)\n",
        "plt.imsave(\"output_frames/segmentation.png\", color_seg)\n",
        "\n",
        "print(\"[4/6] Super-rÃ©solution...\")\n",
        "img_sr = super_resolution(img_rgb, scale=2)\n",
        "plt.imsave(\"output_frames/super_resolution.png\", img_sr)\n",
        "\n",
        "print(\"[5/6] Profondeur avec MiDaS...\")\n",
        "input_tensor = transform(img_sr).to(device)\n",
        "with torch.no_grad():\n",
        "    prediction = midas(input_tensor)\n",
        "    prediction = torch.nn.functional.interpolate(\n",
        "        prediction.unsqueeze(1),\n",
        "        size=img_sr.shape[:2],\n",
        "        mode=\"bicubic\",\n",
        "        align_corners=False,\n",
        "    ).squeeze()\n",
        "depth = prediction.cpu().numpy()\n",
        "plt.imsave(\"output_frames/depth_map.png\", depth, cmap=\"inferno\")\n",
        "\n",
        "print(\"[6/6] Nuage de points 3D texturÃ©...\")\n",
        "fx, fy = 500, 500\n",
        "h, w = depth.shape\n",
        "cx, cy = w/2, h/2\n",
        "depth = np.clip(depth, 0.1, 100)\n",
        "\n",
        "points, colors = [], []\n",
        "stride = 4\n",
        "for y in range(0, h, stride):\n",
        "    for x in range(0, w, stride):\n",
        "        z = depth[y, x]\n",
        "        if np.isnan(z) or np.isinf(z): continue\n",
        "        X = (x - cx) * z / fx\n",
        "        Y = (y - cy) * z / fy\n",
        "        points.append([X, -Y, -z])\n",
        "        cx2, cy2 = min(x, img_sr.shape[1]-1), min(y, img_sr.shape[0]-1)\n",
        "        colors.append(img_sr[cy2, cx2] / 255.0)\n",
        "\n",
        "points = np.array(points)\n",
        "colors = np.array(colors)\n",
        "\n",
        "pcd = o3d.geometry.PointCloud()\n",
        "pcd.points = o3d.utility.Vector3dVector(points)\n",
        "pcd.colors = o3d.utility.Vector3dVector(colors)\n",
        "\n",
        "try:\n",
        "    o3d.visualization.draw_geometries([pcd])\n",
        "except:\n",
        "    print(\"[INFO] Visualisation dÃ©sactivÃ©e sur ce device\")\n",
        "\n",
        "output_file = \"scene3d_splatting.ply\"\n",
        "o3d.io.write_point_cloud(output_file, pcd)\n",
        "files.download(output_file)\n",
        "print(\"âœ… TerminÃ©. Nuage de points 3D exportÃ©.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 855
        },
        "id": "_FgVowC-b9yX",
        "outputId": "17bdc66a-d65f-4696-8709-bf68c0d35abe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Chargement nuage de points scene3d_splatting (1).ply...\n",
            "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to open file: scene3d_splatting (1).ply\u001b[0;m\n",
            "PointCloud with 0 points.\n",
            "[INFO] Calcul des normales...\n",
            "\u001b[1;33m[Open3D WARNING] [KDTreeFlann::SetRawData] Failed due to no data.\u001b[0;m\n",
            "[INFO] Reconstruction poisson en cours...\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "\u001b[1;31m[Open3D Error] (static std::tuple<std::shared_ptr<open3d::geometry::TriangleMesh>, std::vector<double, std::allocator<double> > > open3d::geometry::TriangleMesh::CreateFromPointCloudPoisson(const open3d::geometry::PointCloud&, size_t, float, float, bool, int)) /root/Open3D/cpp/open3d/geometry/SurfaceReconstructionPoisson.cpp:731: Point cloud has no normals\n\u001b[0;m",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1-1103138883.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# Exemple d'appel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mprocess_ply_to_textured_mesh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"scene3d_splatting (1).ply\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"scene3d_final.obj\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-1-1103138883.py\u001b[0m in \u001b[0;36mprocess_ply_to_textured_mesh\u001b[0;34m(ply_path, output_path, depth)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[INFO] Reconstruction poisson en cours...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mmesh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdensities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo3d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeometry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTriangleMesh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_from_point_cloud_poisson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpcd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# Filtrage pour supprimer les parties faibles densitÃ©s\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: \u001b[1;31m[Open3D Error] (static std::tuple<std::shared_ptr<open3d::geometry::TriangleMesh>, std::vector<double, std::allocator<double> > > open3d::geometry::TriangleMesh::CreateFromPointCloudPoisson(const open3d::geometry::PointCloud&, size_t, float, float, bool, int)) /root/Open3D/cpp/open3d/geometry/SurfaceReconstructionPoisson.cpp:731: Point cloud has no normals\n\u001b[0;m"
          ]
        }
      ],
      "source": [
        "import open3d as o3d\n",
        "import numpy as np\n",
        "\n",
        "def process_ply_to_textured_mesh(ply_path, output_path=\"output_mesh.obj\", depth=9):\n",
        "    print(f\"[INFO] Chargement nuage de points {ply_path}...\")\n",
        "    pcd = o3d.io.read_point_cloud(ply_path)\n",
        "    print(pcd)\n",
        "\n",
        "    if not pcd.has_normals():\n",
        "        print(\"[INFO] Calcul des normales...\")\n",
        "        pcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.1, max_nn=30))\n",
        "        pcd.normalize_normals()\n",
        "\n",
        "    print(\"[INFO] Reconstruction poisson en cours...\")\n",
        "    mesh, densities = o3d.geometry.TriangleMesh.create_from_point_cloud_poisson(pcd, depth=depth)\n",
        "\n",
        "    # Filtrage pour supprimer les parties faibles densitÃ©s\n",
        "    print(\"[INFO] Filtrage des faibles densitÃ©s...\")\n",
        "    densities = np.asarray(densities)\n",
        "    density_threshold = np.quantile(densities, 0.01)\n",
        "    vertices_to_keep = densities > density_threshold\n",
        "    mesh.remove_vertices_by_mask(~vertices_to_keep)\n",
        "\n",
        "    # Si le nuage a des couleurs, on les transfÃ¨re\n",
        "    if pcd.has_colors():\n",
        "        print(\"[INFO] Transfert couleurs vers le mesh...\")\n",
        "        mesh.vertex_colors = o3d.utility.Vector3dVector(\n",
        "            np.asarray(pcd.colors)[np.asarray(mesh.vertices)[:, 0].astype(int) % len(pcd.colors)]\n",
        "        )\n",
        "\n",
        "    # Sauvegarde du mesh en .obj\n",
        "    print(f\"[INFO] Export mesh final vers {output_path}\")\n",
        "    o3d.io.write_triangle_mesh(output_path, mesh)\n",
        "    print(\"[âœ…] TerminÃ© ! Vous pouvez maintenant charger le mesh dans Blender, Unreal Engine, etc.\")\n",
        "\n",
        "# Exemple d'appel\n",
        "process_ply_to_textured_mesh(\"scene3d_splatting (1).ply\", \"scene3d_final.obj\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 509
        },
        "id": "_LcAnRmOl_5P",
        "outputId": "6d23b815-7f2d-4d7c-f9a2-7dfc17f46ba3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chargement MiDaS...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/intel-isl_MiDaS_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "â¬†ï¸ Upload image pour reconstruction...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/intel-isl_MiDaS_master\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-28f2605a-ca96-471f-8e39-ae210d925899\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-28f2605a-ca96-471f-8e39-ae210d925899\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving 20250719_220848.jpg to 20250719_220848 (1).jpg\n",
            "[1/6] PrÃ©traitement image...\n",
            "[LOG] NettetÃ© (Laplacian): 34042.68\n",
            "[2/6] Inpainting zones sombres...\n",
            "[3/6] Segmentation sÃ©mantique...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DeepLabV3_ResNet50_Weights.COCO_WITH_VOC_LABELS_V1`. You can also use `weights=DeepLabV3_ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[4/6] Super-rÃ©solution...\n",
            "[5/6] Profondeur avec MiDaS...\n",
            "[Analyse] Statistiques et anomalies...\n",
            "ğŸ“Š Moyenne: 20.21, Ã‰cart-type: 12.40, Min: -0.27, Max: 49.78\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_fe6ce113-280d-4dc6-9b42-fd2457237802\", \"rapport.txt\", 155)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[6/6] Reconstruction 3D...\n",
            "\u001b[1;33m[Open3D WARNING] GLFW initialized for headless rendering.\u001b[0;m\n",
            "\u001b[1;33m[Open3D WARNING] GLFW Error: OSMesa: Library not found\u001b[0;m\n",
            "\u001b[1;33m[Open3D WARNING] Failed to create window\u001b[0;m\n",
            "\u001b[1;33m[Open3D WARNING] [DrawGeometries] Failed creating OpenGL window.\u001b[0;m\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_98d3441d-9985-4da0-bfd6-1ffe9301cfed\", \"scene3d_splatting.ply\", 1327312)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… TerminÃ©. Tous les fichiers exportÃ©s dans 'output_frames'.\n"
          ]
        }
      ],
      "source": [
        "# âœ… IMPORTS\n",
        "import os, cv2, torch\n",
        "import numpy as np\n",
        "import open3d as o3d\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image, ExifTags, ImageEnhance, ImageFilter\n",
        "from google.colab import files\n",
        "import torchvision.transforms as T\n",
        "from torchvision.models.segmentation import deeplabv3_resnet50\n",
        "\n",
        "from scipy import ndimage\n",
        "\n",
        "# âœ… SETUP\n",
        "torch.manual_seed(42)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "os.makedirs(\"output_frames\", exist_ok=True)\n",
        "\n",
        "# âœ… UTILS\n",
        "def correct_orientation(image: Image.Image) -> Image.Image:\n",
        "    try:\n",
        "        for orientation in ExifTags.TAGS.keys():\n",
        "            if ExifTags.TAGS[orientation] == 'Orientation':\n",
        "                break\n",
        "        exif = dict(image._getexif().items())\n",
        "        orientation_value = exif.get(orientation, None)\n",
        "        if orientation_value == 3:\n",
        "            image = image.rotate(180, expand=True)\n",
        "        elif orientation_value == 6:\n",
        "            image = image.rotate(270, expand=True)\n",
        "        elif orientation_value == 8:\n",
        "            image = image.rotate(90, expand=True)\n",
        "    except: pass\n",
        "    return image\n",
        "\n",
        "def enhance_image(image: Image.Image) -> Image.Image:\n",
        "    image = ImageEnhance.Contrast(image).enhance(1.8)\n",
        "    image = ImageEnhance.Sharpness(image).enhance(2.0)\n",
        "    image = image.filter(ImageFilter.EDGE_ENHANCE_MORE)\n",
        "    return image\n",
        "\n",
        "def load_and_prepare_image(image_path, target_max_size=512):\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    image = correct_orientation(image)\n",
        "    max_dim = max(image.size)\n",
        "    if max_dim > target_max_size:\n",
        "        scale = target_max_size / max_dim\n",
        "        image = image.resize((int(image.size[0]*scale), int(image.size[1]*scale)), Image.LANCZOS)\n",
        "    image = enhance_image(image)\n",
        "    return np.array(image)\n",
        "\n",
        "def check_image_quality(img):\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "    lap_var = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
        "    print(f\"[LOG] NettetÃ© (Laplacian): {lap_var:.2f}\")\n",
        "    if img.std() < 10: raise ValueError(\"Image trop plate (contraste)\")\n",
        "    if img.mean() < 10: raise ValueError(\"Image trop sombre\")\n",
        "\n",
        "def auto_inpaint(img):\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "    _, mask = cv2.threshold(gray, 5, 255, cv2.THRESH_BINARY_INV)\n",
        "    return cv2.inpaint(img, mask, 3, cv2.INPAINT_TELEA)\n",
        "\n",
        "# âœ… SEGMENTATION DEEPLAB\n",
        "def run_segmentation(img_rgb):\n",
        "    model = deeplabv3_resnet50(pretrained=True).to(device)\n",
        "    model.eval()\n",
        "    preprocess = T.Compose([\n",
        "        T.ToTensor(),\n",
        "        T.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                    std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "    input_tensor = preprocess(Image.fromarray(img_rgb)).unsqueeze(0).to(device)\n",
        "    with torch.no_grad():\n",
        "        output = model(input_tensor)['out'][0]\n",
        "    return output.argmax(0).byte().cpu().numpy()\n",
        "\n",
        "def colorize_segmentation(seg):\n",
        "    palette = np.array([\n",
        "        [0,0,0],[128,0,0],[0,128,0],[128,128,0],[0,0,128],\n",
        "        [128,0,128],[0,128,128],[128,128,128],[64,0,0],[192,0,0],\n",
        "        [64,128,0],[192,128,0],[64,0,128],[192,0,128],[64,128,128],\n",
        "        [192,128,128],[0,64,0],[128,64,0],[0,192,0],[128,192,0],\n",
        "        [0,64,128]\n",
        "    ])\n",
        "    return palette[seg % 21].astype(np.uint8)\n",
        "\n",
        "def super_resolution(img, scale=2):\n",
        "    return cv2.resize(img, (img.shape[1]*scale, img.shape[0]*scale), interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "# âœ… MIDAS SETUP\n",
        "print(\"Chargement MiDaS...\")\n",
        "model_type = \"DPT_Large\"\n",
        "midas = torch.hub.load(\"intel-isl/MiDaS\", model_type, trust_repo=True).to(device).eval()\n",
        "midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\", trust_repo=True)\n",
        "transform = midas_transforms.dpt_transform\n",
        "\n",
        "# âœ… UPLOAD IMAGE\n",
        "print(\"â¬†ï¸ Upload image pour reconstruction...\")\n",
        "uploaded = files.upload()\n",
        "image_path = next(iter(uploaded))\n",
        "\n",
        "# âœ… PIPELINE\n",
        "print(\"[1/6] PrÃ©traitement image...\")\n",
        "img_rgb = load_and_prepare_image(image_path)\n",
        "check_image_quality(img_rgb)\n",
        "\n",
        "print(\"[2/6] Inpainting zones sombres...\")\n",
        "img_rgb = auto_inpaint(img_rgb)\n",
        "\n",
        "print(\"[3/6] Segmentation sÃ©mantique...\")\n",
        "seg = run_segmentation(img_rgb)\n",
        "color_seg = colorize_segmentation(seg)\n",
        "plt.imsave(\"output_frames/segmentation.png\", color_seg)\n",
        "\n",
        "print(\"[4/6] Super-rÃ©solution...\")\n",
        "img_sr = super_resolution(img_rgb, scale=2)\n",
        "plt.imsave(\"output_frames/super_resolution.png\", img_sr)\n",
        "\n",
        "print(\"[5/6] Profondeur avec MiDaS...\")\n",
        "input_tensor = transform(img_sr).to(device)\n",
        "with torch.no_grad():\n",
        "    prediction = midas(input_tensor)\n",
        "    prediction = torch.nn.functional.interpolate(\n",
        "        prediction.unsqueeze(1),\n",
        "        size=img_sr.shape[:2],\n",
        "        mode=\"bicubic\",\n",
        "        align_corners=False,\n",
        "    ).squeeze()\n",
        "depth = prediction.cpu().numpy()\n",
        "plt.imsave(\"output_frames/depth_map.png\", depth, cmap=\"inferno\")\n",
        "\n",
        "# âœ… ANALYSE DE PROFONDEUR\n",
        "print(\"[Analyse] Statistiques et anomalies...\")\n",
        "depth_flat = depth.flatten()\n",
        "depth_flat = depth_flat[~np.isnan(depth_flat)]\n",
        "\n",
        "mean_depth = np.mean(depth_flat)\n",
        "std_depth = np.std(depth_flat)\n",
        "max_depth = np.max(depth_flat)\n",
        "min_depth = np.min(depth_flat)\n",
        "\n",
        "print(f\"ğŸ“Š Moyenne: {mean_depth:.2f}, Ã‰cart-type: {std_depth:.2f}, Min: {min_depth:.2f}, Max: {max_depth:.2f}\")\n",
        "\n",
        "anomalies = (depth < (mean_depth - 2*std_depth)) | (depth > (mean_depth + 2*std_depth))\n",
        "anomaly_map = anomalies.astype(np.uint8) * 255\n",
        "plt.imsave(\"output_frames/anomaly_map.png\", anomaly_map, cmap=\"gray\")\n",
        "\n",
        "# âœ… Histogramme profondeur\n",
        "plt.figure(figsize=(10,4))\n",
        "sns.histplot(depth_flat, bins=100, kde=True, color=\"blue\")\n",
        "plt.title(\"Distribution des valeurs de profondeur\")\n",
        "plt.xlabel(\"Profondeur\")\n",
        "plt.ylabel(\"FrÃ©quence\")\n",
        "plt.savefig(\"output_frames/depth_distribution.png\")\n",
        "plt.close()\n",
        "\n",
        "# âœ… Contours sur lâ€™image\n",
        "contours, _ = cv2.findContours(anomaly_map, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "img_contours = img_rgb.copy()\n",
        "cv2.drawContours(img_contours, contours, -1, (255, 0, 0), 2)\n",
        "plt.imsave(\"output_frames/zones_anomalies.png\", img_contours)\n",
        "\n",
        "# âœ… Rapport automatique\n",
        "rapport = []\n",
        "rapport.append(\"ğŸ“„ Rapport d'analyse de scÃ¨ne 3D :\\n\")\n",
        "rapport.append(f\"- Moyenne de profondeur : {mean_depth:.2f}\")\n",
        "rapport.append(f\"- Ã‰cart-type : {std_depth:.2f}\")\n",
        "rapport.append(f\"- Min : {min_depth:.2f}, Max : {max_depth:.2f}\")\n",
        "rapport.append(f\"- Zones anormales dÃ©tectÃ©es : {'Oui' if anomalies.any() else 'Non'}\")\n",
        "\n",
        "with open(\"output_frames/rapport.txt\", \"w\") as f:\n",
        "    f.write(\"\\n\".join(rapport))\n",
        "\n",
        "files.download(\"output_frames/rapport.txt\")\n",
        "\n",
        "# âœ… Nuage de points 3D\n",
        "print(\"[6/6] Reconstruction 3D...\")\n",
        "fx, fy = 500, 500\n",
        "h, w = depth.shape\n",
        "cx, cy = w/2, h/2\n",
        "depth = np.clip(depth, 0.1, 100)\n",
        "\n",
        "points, colors = [], []\n",
        "stride = 4\n",
        "for y in range(0, h, stride):\n",
        "    for x in range(0, w, stride):\n",
        "        z = depth[y, x]\n",
        "        if np.isnan(z) or np.isinf(z): continue\n",
        "        X = (x - cx) * z / fx\n",
        "        Y = (y - cy) * z / fy\n",
        "        points.append([X, -Y, -z])\n",
        "        cx2, cy2 = min(x, img_sr.shape[1]-1), min(y, img_sr.shape[0]-1)\n",
        "        colors.append(img_sr[cy2, cx2] / 255.0)\n",
        "\n",
        "points = np.array(points)\n",
        "colors = np.array(colors)\n",
        "\n",
        "pcd = o3d.geometry.PointCloud()\n",
        "pcd.points = o3d.utility.Vector3dVector(points)\n",
        "pcd.colors = o3d.utility.Vector3dVector(colors)\n",
        "\n",
        "try:\n",
        "    o3d.visualization.draw_geometries([pcd])\n",
        "except:\n",
        "    print(\"[INFO] Visualisation dÃ©sactivÃ©e sur ce device\")\n",
        "\n",
        "output_file = \"scene3d_splatting.ply\"\n",
        "o3d.io.write_point_cloud(output_file, pcd)\n",
        "files.download(output_file)\n",
        "print(\"âœ… TerminÃ©. Tous les fichiers exportÃ©s dans 'output_frames'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "bONvuz1bqKw9",
        "outputId": "c207ae1f-2072-4aff-c108-784b7a71c5db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.7)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Collecting open3d\n",
            "  Downloading open3d-0.19.0-cp311-cp311-manylinux_2_31_x86_64.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.16.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.11.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (25.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.11/dist-packages (from seaborn) (2.2.2)\n",
            "Collecting dash>=2.6.0 (from open3d)\n",
            "  Downloading dash-3.1.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: werkzeug>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from open3d) (3.1.3)\n",
            "Requirement already satisfied: flask>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from open3d) (3.1.1)\n",
            "Requirement already satisfied: nbformat>=5.7.0 in /usr/local/lib/python3.11/dist-packages (from open3d) (5.10.4)\n",
            "Collecting configargparse (from open3d)\n",
            "  Downloading configargparse-1.7.1-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting ipywidgets>=8.0.4 (from open3d)\n",
            "  Downloading ipywidgets-8.1.7-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting addict (from open3d)\n",
            "  Downloading addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: pyyaml>=5.4.1 in /usr/local/lib/python3.11/dist-packages (from open3d) (6.0.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21 in /usr/local/lib/python3.11/dist-packages (from open3d) (1.6.1)\n",
            "Collecting pyquaternion (from open3d)\n",
            "  Downloading pyquaternion-0.9.9-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.5)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: plotly>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from dash>=2.6.0->open3d) (5.24.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from dash>=2.6.0->open3d) (8.7.0)\n",
            "Collecting retrying (from dash>=2.6.0->open3d)\n",
            "  Downloading retrying-1.4.1-py3-none-any.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from dash>=2.6.0->open3d) (1.6.0)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from flask>=3.0.0->open3d) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask>=3.0.0->open3d) (8.2.1)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from flask>=3.0.0->open3d) (2.2.0)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from flask>=3.0.0->open3d) (3.0.2)\n",
            "Collecting comm>=0.1.3 (from ipywidgets>=8.0.4->open3d)\n",
            "  Downloading comm-0.2.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.0.4->open3d) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.0.4->open3d) (5.7.1)\n",
            "Collecting widgetsnbextension~=4.0.14 (from ipywidgets>=8.0.4->open3d)\n",
            "  Downloading widgetsnbextension-4.0.14-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.0.4->open3d) (3.0.15)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.7.0->open3d) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.7.0->open3d) (4.24.0)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.7.0->open3d) (5.8.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.7.14)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21->open3d) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21->open3d) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21->open3d) (3.6.0)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.3.0.post1)\n",
            "Collecting jedi>=0.16 (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (3.0.51)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (4.9.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (0.26.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core!=5.0.*,>=4.12->nbformat>=5.7.0->open3d) (4.3.8)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly>=5.0.0->dash>=2.6.0->open3d) (8.5.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->dash>=2.6.0->open3d) (3.23.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.8.4)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.13)\n",
            "Downloading open3d-0.19.0-cp311-cp311-manylinux_2_31_x86_64.whl (447.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m447.7/447.7 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m74.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m79.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dash-3.1.1-py3-none-any.whl (7.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m105.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ipywidgets-8.1.7-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Downloading configargparse-1.7.1-py3-none-any.whl (25 kB)\n",
            "Downloading pyquaternion-0.9.9-py3-none-any.whl (14 kB)\n",
            "Downloading comm-0.2.2-py3-none-any.whl (7.2 kB)\n",
            "Downloading widgetsnbextension-4.0.14-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m79.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading retrying-1.4.1-py3-none-any.whl (12 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: addict, widgetsnbextension, retrying, pyquaternion, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, jedi, configargparse, comm, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ipywidgets, dash, open3d\n",
            "  Attempting uninstall: widgetsnbextension\n",
            "    Found existing installation: widgetsnbextension 3.6.10\n",
            "    Uninstalling widgetsnbextension-3.6.10:\n",
            "      Successfully uninstalled widgetsnbextension-3.6.10\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: ipywidgets\n",
            "    Found existing installation: ipywidgets 7.7.1\n",
            "    Uninstalling ipywidgets-7.7.1:\n",
            "      Successfully uninstalled ipywidgets-7.7.1\n",
            "Successfully installed addict-2.4.0 comm-0.2.2 configargparse-1.7.1 dash-3.1.1 ipywidgets-8.1.7 jedi-0.19.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 open3d-0.19.0 pyquaternion-0.9.9 retrying-1.4.1 widgetsnbextension-4.0.14\n",
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m102.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3mâš  Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "!pip install spacy seaborn open3d torch torchvision matplotlib pillow\n",
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3lJ06KeoXv6c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 509
        },
        "id": "V0gIUnesvcbt",
        "outputId": "340bddb9-ba6f-41a5-cceb-bffd75569328"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chargement MiDaS...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/intel-isl_MiDaS_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "â¬†ï¸ Upload image pour reconstruction...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/intel-isl_MiDaS_master\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-fdafbeec-5bc4-4835-aa4f-3b52266aca56\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-fdafbeec-5bc4-4835-aa4f-3b52266aca56\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving 20250719_220848.jpg to 20250719_220848 (2).jpg\n",
            "[1/6] PrÃ©traitement image...\n",
            "[LOG] NettetÃ© (Laplacian): 34042.68\n",
            "[2/6] Inpainting zones sombres...\n",
            "[3/6] Segmentation sÃ©mantique...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DeepLabV3_ResNet50_Weights.COCO_WITH_VOC_LABELS_V1`. You can also use `weights=DeepLabV3_ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[4/6] Super-rÃ©solution...\n",
            "[5/6] Profondeur avec MiDaS...\n",
            "[Analyse] Statistiques et anomalies...\n",
            "ğŸ“Š Moyenne: 20.21, Ã‰cart-type: 12.40, Min: -0.27, Max: 49.78\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_62ceef99-f710-4812-bd12-09b0b02d32e1\", \"rapport.txt\", 155)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[6/6] Reconstruction 3D avec analyse...\n",
            "\u001b[1;33m[Open3D WARNING] GLFW initialized for headless rendering.\u001b[0;m\n",
            "\u001b[1;33m[Open3D WARNING] GLFW Error: OSMesa: Library not found\u001b[0;m\n",
            "\u001b[1;33m[Open3D WARNING] Failed to create window\u001b[0;m\n",
            "\u001b[1;33m[Open3D WARNING] [DrawGeometries] Failed creating OpenGL window.\u001b[0;m\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_ad22240d-77e9-4075-8264-b7cf1baf4b79\", \"scene3d_splatting_with_analysis.ply\", 3020793)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… TerminÃ©. Nuage de points 3D avec analyse exportÃ© dans 'scene3d_splatting_with_analysis.ply'.\n"
          ]
        }
      ],
      "source": [
        "# âœ… IMPORTS\n",
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "import open3d as o3d\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image, ExifTags, ImageEnhance, ImageFilter\n",
        "from google.colab import files\n",
        "import torchvision.transforms as T\n",
        "from torchvision.models.segmentation import deeplabv3_resnet50\n",
        "from scipy import ndimage\n",
        "\n",
        "# âœ… SETUP\n",
        "torch.manual_seed(42)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "os.makedirs(\"output_frames\", exist_ok=True)\n",
        "\n",
        "# âœ… UTILS\n",
        "def correct_orientation(image: Image.Image) -> Image.Image:\n",
        "    try:\n",
        "        for orientation in ExifTags.TAGS.keys():\n",
        "            if ExifTags.TAGS[orientation] == 'Orientation':\n",
        "                break\n",
        "        exif = dict(image._getexif().items())\n",
        "        orientation_value = exif.get(orientation, None)\n",
        "        if orientation_value == 3:\n",
        "            image = image.rotate(180, expand=True)\n",
        "        elif orientation_value == 6:\n",
        "            image = image.rotate(270, expand=True)\n",
        "        elif orientation_value == 8:\n",
        "            image = image.rotate(90, expand=True)\n",
        "    except:\n",
        "        pass\n",
        "    return image\n",
        "\n",
        "def enhance_image(image: Image.Image) -> Image.Image:\n",
        "    image = ImageEnhance.Contrast(image).enhance(1.8)\n",
        "    image = ImageEnhance.Sharpness(image).enhance(2.0)\n",
        "    image = image.filter(ImageFilter.EDGE_ENHANCE_MORE)\n",
        "    return image\n",
        "\n",
        "def load_and_prepare_image(image_path, target_max_size=512):\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    image = correct_orientation(image)\n",
        "    max_dim = max(image.size)\n",
        "    if max_dim > target_max_size:\n",
        "        scale = target_max_size / max_dim\n",
        "        image = image.resize((int(image.size[0]*scale), int(image.size[1]*scale)), Image.LANCZOS)\n",
        "    image = enhance_image(image)\n",
        "    return np.array(image)\n",
        "\n",
        "def check_image_quality(img):\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "    lap_var = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
        "    print(f\"[LOG] NettetÃ© (Laplacian): {lap_var:.2f}\")\n",
        "    if img.std() < 10: raise ValueError(\"Image trop plate (contraste)\")\n",
        "    if img.mean() < 10: raise ValueError(\"Image trop sombre\")\n",
        "\n",
        "def auto_inpaint(img):\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "    _, mask = cv2.threshold(gray, 5, 255, cv2.THRESH_BINARY_INV)\n",
        "    return cv2.inpaint(img, mask, 3, cv2.INPAINT_TELEA)\n",
        "\n",
        "# âœ… SEGMENTATION DEEPLAB\n",
        "def run_segmentation(img_rgb):\n",
        "    model = deeplabv3_resnet50(pretrained=True).to(device)\n",
        "    model.eval()\n",
        "    preprocess = T.Compose([\n",
        "        T.ToTensor(),\n",
        "        T.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                    std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "    input_tensor = preprocess(Image.fromarray(img_rgb)).unsqueeze(0).to(device)\n",
        "    with torch.no_grad():\n",
        "        output = model(input_tensor)['out'][0]\n",
        "    return output.argmax(0).byte().cpu().numpy()\n",
        "\n",
        "def colorize_segmentation(seg):\n",
        "    palette = np.array([\n",
        "        [0,0,0],[128,0,0],[0,128,0],[128,128,0],[0,0,128],\n",
        "        [128,0,128],[0,128,128],[128,128,128],[64,0,0],[192,0,0],\n",
        "        [64,128,0],[192,128,0],[64,0,128],[192,0,128],[64,128,128],\n",
        "        [192,128,128],[0,64,0],[128,64,0],[0,192,0],[128,192,0],\n",
        "        [0,64,128]\n",
        "    ])\n",
        "    return palette[seg % 21].astype(np.uint8)\n",
        "\n",
        "def super_resolution(img, scale=2):\n",
        "    return cv2.resize(img, (img.shape[1]*scale, img.shape[0]*scale), interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "# âœ… MIDAS SETUP\n",
        "print(\"Chargement MiDaS...\")\n",
        "model_type = \"DPT_Large\"\n",
        "midas = torch.hub.load(\"intel-isl/MiDaS\", model_type, trust_repo=True).to(device).eval()\n",
        "midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\", trust_repo=True)\n",
        "transform = midas_transforms.dpt_transform\n",
        "\n",
        "# âœ… UPLOAD IMAGE\n",
        "print(\"â¬†ï¸ Upload image pour reconstruction...\")\n",
        "uploaded = files.upload()\n",
        "image_path = next(iter(uploaded))\n",
        "\n",
        "# âœ… PIPELINE\n",
        "print(\"[1/6] PrÃ©traitement image...\")\n",
        "img_rgb = load_and_prepare_image(image_path)\n",
        "check_image_quality(img_rgb)\n",
        "\n",
        "print(\"[2/6] Inpainting zones sombres...\")\n",
        "img_rgb = auto_inpaint(img_rgb)\n",
        "\n",
        "print(\"[3/6] Segmentation sÃ©mantique...\")\n",
        "seg = run_segmentation(img_rgb)\n",
        "color_seg = colorize_segmentation(seg)\n",
        "plt.imsave(\"output_frames/segmentation.png\", color_seg)\n",
        "\n",
        "print(\"[4/6] Super-rÃ©solution...\")\n",
        "img_sr = super_resolution(img_rgb, scale=2)\n",
        "plt.imsave(\"output_frames/super_resolution.png\", img_sr)\n",
        "\n",
        "print(\"[5/6] Profondeur avec MiDaS...\")\n",
        "input_tensor = transform(img_sr).to(device)\n",
        "with torch.no_grad():\n",
        "    prediction = midas(input_tensor)\n",
        "    prediction = torch.nn.functional.interpolate(\n",
        "        prediction.unsqueeze(1),\n",
        "        size=img_sr.shape[:2],\n",
        "        mode=\"bicubic\",\n",
        "        align_corners=False,\n",
        "    ).squeeze()\n",
        "depth = prediction.cpu().numpy()\n",
        "plt.imsave(\"output_frames/depth_map.png\", depth, cmap=\"inferno\")\n",
        "\n",
        "# âœ… ANALYSE DE PROFONDEUR\n",
        "print(\"[Analyse] Statistiques et anomalies...\")\n",
        "depth_flat = depth.flatten()\n",
        "depth_flat = depth_flat[~np.isnan(depth_flat)]\n",
        "\n",
        "mean_depth = np.mean(depth_flat)\n",
        "std_depth = np.std(depth_flat)\n",
        "max_depth = np.max(depth_flat)\n",
        "min_depth = np.min(depth_flat)\n",
        "\n",
        "print(f\"ğŸ“Š Moyenne: {mean_depth:.2f}, Ã‰cart-type: {std_depth:.2f}, Min: {min_depth:.2f}, Max: {max_depth:.2f}\")\n",
        "\n",
        "anomalies = (depth < (mean_depth - 2*std_depth)) | (depth > (mean_depth + 2*std_depth))\n",
        "anomaly_map = anomalies.astype(np.uint8) * 255\n",
        "plt.imsave(\"output_frames/anomaly_map.png\", anomaly_map, cmap=\"gray\")\n",
        "\n",
        "# âœ… Histogramme profondeur\n",
        "plt.figure(figsize=(10,4))\n",
        "sns.histplot(depth_flat, bins=100, kde=True, color=\"blue\")\n",
        "plt.title(\"Distribution des valeurs de profondeur\")\n",
        "plt.xlabel(\"Profondeur\")\n",
        "plt.ylabel(\"FrÃ©quence\")\n",
        "plt.savefig(\"output_frames/depth_distribution.png\")\n",
        "plt.close()\n",
        "\n",
        "# âœ… Contours sur lâ€™image\n",
        "contours, _ = cv2.findContours(anomaly_map, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "img_contours = img_rgb.copy()\n",
        "cv2.drawContours(img_contours, contours, -1, (255, 0, 0), 2)\n",
        "plt.imsave(\"output_frames/zones_anomalies.png\", img_contours)\n",
        "\n",
        "# âœ… Rapport automatique\n",
        "rapport = []\n",
        "rapport.append(\"ğŸ“„ Rapport d'analyse de scÃ¨ne 3D :\\n\")\n",
        "rapport.append(f\"- Moyenne de profondeur : {mean_depth:.2f}\")\n",
        "rapport.append(f\"- Ã‰cart-type : {std_depth:.2f}\")\n",
        "rapport.append(f\"- Min : {min_depth:.2f}, Max : {max_depth:.2f}\")\n",
        "rapport.append(f\"- Zones anormales dÃ©tectÃ©es : {'Oui' if anomalies.any() else 'Non'}\")\n",
        "\n",
        "with open(\"output_frames/rapport.txt\", \"w\") as f:\n",
        "    f.write(\"\\n\".join(rapport))\n",
        "\n",
        "files.download(\"output_frames/rapport.txt\")\n",
        "\n",
        "# âœ… Nuage de points 3D avec analyse intÃ©grÃ©e\n",
        "print(\"[6/6] Reconstruction 3D avec analyse...\")\n",
        "fx, fy = 500, 500\n",
        "h, w = depth.shape\n",
        "cx, cy = w/2, h/2\n",
        "depth = np.clip(depth, 0.1, 100)\n",
        "\n",
        "points, colors, anomaly_flags = [], [], []\n",
        "stride = 4\n",
        "for y in range(0, h, stride):\n",
        "    for x in range(0, w, stride):\n",
        "        z = depth[y, x]\n",
        "        if np.isnan(z) or np.isinf(z): continue\n",
        "        X = (x - cx) * z / fx\n",
        "        Y = (y - cy) * z / fy\n",
        "        points.append([X, -Y, -z])\n",
        "        cx2, cy2 = min(x, img_sr.shape[1]-1), min(y, img_sr.shape[0]-1)\n",
        "        colors.append(img_sr[cy2, cx2] / 255.0)\n",
        "        anomaly_flags.append(1.0 if anomalies[y, x] else 0.0)  # 1 pour anomalie, 0 sinon\n",
        "\n",
        "points = np.array(points)\n",
        "colors = np.array(colors)\n",
        "anomaly_flags = np.array(anomaly_flags)\n",
        "\n",
        "# CrÃ©er le nuage de points\n",
        "pcd = o3d.geometry.PointCloud()\n",
        "pcd.points = o3d.utility.Vector3dVector(points)\n",
        "pcd.colors = o3d.utility.Vector3dVector(colors)\n",
        "\n",
        "# Ajouter la propriÃ©tÃ© d'anomalie comme propriÃ©tÃ© personnalisÃ©e\n",
        "# Note : Open3D ne supporte pas nativement les propriÃ©tÃ©s personnalisÃ©es, donc on utilise un fichier PLY personnalisÃ©\n",
        "output_file = \"scene3d_splatting_with_analysis.ply\"\n",
        "\n",
        "# Ã‰crire le fichier PLY manuellement avec les mÃ©tadonnÃ©es et propriÃ©tÃ©s\n",
        "with open(output_file, \"w\") as f:\n",
        "    # En-tÃªte PLY\n",
        "    f.write(\"ply\\n\")\n",
        "    f.write(\"format ascii 1.0\\n\")\n",
        "    f.write(f\"comment Mean Depth: {mean_depth:.2f}\\n\")\n",
        "    f.write(f\"comment Std Depth: {std_depth:.2f}\\n\")\n",
        "    f.write(f\"comment Min Depth: {min_depth:.2f}\\n\")\n",
        "    f.write(f\"comment Max Depth: {max_depth:.2f}\\n\")\n",
        "    f.write(f\"comment Anomalies Detected: {'Yes' if anomalies.any() else 'No'}\\n\")\n",
        "    f.write(f\"element vertex {len(points)}\\n\")\n",
        "    f.write(\"property float x\\n\")\n",
        "    f.write(\"property float y\\n\")\n",
        "    f.write(\"property float z\\n\")\n",
        "    f.write(\"property float red\\n\")\n",
        "    f.write(\"property float green\\n\")\n",
        "    f.write(\"property float blue\\n\")\n",
        "    f.write(\"property float anomaly\\n\")  # PropriÃ©tÃ© personnalisÃ©e pour les anomalies\n",
        "    f.write(\"end_header\\n\")\n",
        "\n",
        "    # Ã‰crire les donnÃ©es des points\n",
        "    for i in range(len(points)):\n",
        "        x, y, z = points[i]\n",
        "        r, g, b = colors[i]\n",
        "        anomaly = anomaly_flags[i]\n",
        "        f.write(f\"{x:.6f} {y:.6f} {z:.6f} {r:.6f} {g:.6f} {b:.6f} {anomaly:.1f}\\n\")\n",
        "\n",
        "# Visualisation\n",
        "try:\n",
        "    o3d.visualization.draw_geometries([pcd])\n",
        "except:\n",
        "    print(\"[INFO] Visualisation dÃ©sactivÃ©e sur ce device\")\n",
        "\n",
        "# TÃ©lÃ©chargement du fichier PLY\n",
        "files.download(output_file)\n",
        "print(\"âœ… TerminÃ©. Nuage de points 3D avec analyse exportÃ© dans 'scene3d_splatting_with_analysis.ply'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Tcmx3Cy2Xy1J",
        "outputId": "715e1a98-4e36-4616-9724-9b045cec345f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.11/dist-packages (0.116.1)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.11/dist-packages (0.35.0)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.11/dist-packages (0.0.20)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (1.0.17)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: open3d in /usr/local/lib/python3.11/dist-packages (0.19.0)\n",
            "Requirement already satisfied: starlette<0.48.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (0.47.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from fastapi) (2.11.7)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (4.14.1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (8.2.1)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (0.16.0)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (2.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.5)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from timm) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from timm) (0.33.4)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: dash>=2.6.0 in /usr/local/lib/python3.11/dist-packages (from open3d) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from open3d) (3.1.3)\n",
            "Requirement already satisfied: flask>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from open3d) (3.1.1)\n",
            "Requirement already satisfied: nbformat>=5.7.0 in /usr/local/lib/python3.11/dist-packages (from open3d) (5.10.4)\n",
            "Requirement already satisfied: configargparse in /usr/local/lib/python3.11/dist-packages (from open3d) (1.7.1)\n",
            "Requirement already satisfied: ipywidgets>=8.0.4 in /usr/local/lib/python3.11/dist-packages (from open3d) (8.1.7)\n",
            "Requirement already satisfied: addict in /usr/local/lib/python3.11/dist-packages (from open3d) (2.4.0)\n",
            "Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.11/dist-packages (from open3d) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21 in /usr/local/lib/python3.11/dist-packages (from open3d) (1.6.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from open3d) (4.67.1)\n",
            "Requirement already satisfied: pyquaternion in /usr/local/lib/python3.11/dist-packages (from open3d) (0.9.9)\n",
            "Requirement already satisfied: plotly>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from dash>=2.6.0->open3d) (5.24.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from dash>=2.6.0->open3d) (8.7.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from dash>=2.6.0->open3d) (2.32.3)\n",
            "Requirement already satisfied: retrying in /usr/local/lib/python3.11/dist-packages (from dash>=2.6.0->open3d) (1.4.1)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from dash>=2.6.0->open3d) (1.6.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from dash>=2.6.0->open3d) (75.2.0)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from flask>=3.0.0->open3d) (1.9.0)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from flask>=3.0.0->open3d) (2.2.0)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from flask>=3.0.0->open3d) (3.0.2)\n",
            "Requirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.0.4->open3d) (0.2.2)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.0.4->open3d) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.0.4->open3d) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=4.0.14 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.0.4->open3d) (4.0.14)\n",
            "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.0.4->open3d) (3.0.15)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.7.0->open3d) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.7.0->open3d) (4.24.0)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.7.0->open3d) (5.8.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0->open3d) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0->open3d) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21->open3d) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21->open3d) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21->open3d) (3.6.0)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.48.0,>=0.40.0->fastapi) (4.9.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (1.1.5)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.48.0,>=0.40.0->fastapi) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.48.0,>=0.40.0->fastapi) (1.3.1)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (3.0.51)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (4.9.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (0.26.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core!=5.0.*,>=4.12->nbformat>=5.7.0->open3d) (4.3.8)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly>=5.0.0->dash>=2.6.0->open3d) (8.5.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->dash>=2.6.0->open3d) (3.23.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->dash>=2.6.0->open3d) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->dash>=2.6.0->open3d) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->dash>=2.6.0->open3d) (2025.7.14)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.13)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:asyncio:Task exception was never retrieved\n",
            "future: <Task finished name='Task-1' coro=<Server.serve() done, defined at /usr/local/lib/python3.11/dist-packages/uvicorn/server.py:69> exception=KeyboardInterrupt()>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/main.py\", line 580, in run\n",
            "    server.run()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/server.py\", line 67, in run\n",
            "    return asyncio.run(self.serve(sockets=sockets))\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/nest_asyncio.py\", line 30, in run\n",
            "    return loop.run_until_complete(task)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/nest_asyncio.py\", line 92, in run_until_complete\n",
            "    self._run_once()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/nest_asyncio.py\", line 133, in _run_once\n",
            "    handle._run()\n",
            "  File \"/usr/lib/python3.11/asyncio/events.py\", line 84, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/usr/lib/python3.11/asyncio/tasks.py\", line 360, in __wakeup\n",
            "    self.__step()\n",
            "  File \"/usr/lib/python3.11/asyncio/tasks.py\", line 277, in __step\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/server.py\", line 70, in serve\n",
            "    with self.capture_signals():\n",
            "  File \"/usr/lib/python3.11/contextlib.py\", line 144, in __exit__\n",
            "    next(self.gen)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/server.py\", line 331, in capture_signals\n",
            "    signal.raise_signal(captured_signal)\n",
            "KeyboardInterrupt\n",
            "Using cache found in /root/.cache/torch/hub/intel-isl_MiDaS_master\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-19-379460978.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Charger modÃ¨le MiDaS une fois au dÃ©marrage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mmodel_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"DPT_Large\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mmidas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"intel-isl/MiDaS\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrust_repo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mmidas_transforms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"intel-isl/MiDaS\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transforms\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrust_repo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/hub.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(repo_or_dir, model, source, trust_repo, force_reload, verbose, skip_validation, *args, **kwargs)\u001b[0m\n\u001b[1;32m    645\u001b[0m         )\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 647\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_local\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepo_or_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    648\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/hub.py\u001b[0m in \u001b[0;36m_load_local\u001b[0;34m(hubconf_dir, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m         \u001b[0mentry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_entry_from_hubconf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhub_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.cache/torch/hub/intel-isl_MiDaS_master/hubconf.py\u001b[0m in \u001b[0;36mDPT_Large\u001b[0;34m(pretrained, **kwargs)\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0;34m\"https://github.com/isl-org/MiDaS/releases/download/v3/dpt_large_384.pt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         )\n\u001b[0;32m--> 234\u001b[0;31m         state_dict = torch.hub.load_state_dict_from_url(\n\u001b[0m\u001b[1;32m    235\u001b[0m             \u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_hash\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/hub.py\u001b[0m in \u001b[0;36mload_state_dict_from_url\u001b[0;34m(url, model_dir, map_location, progress, check_hash, file_name, weights_only)\u001b[0m\n\u001b[1;32m    869\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_legacy_zip_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcached_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_zip_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcached_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_only\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcached_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights_only\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1469\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1470\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_wo_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1471\u001b[0;31m                 return _load(\n\u001b[0m\u001b[1;32m   1472\u001b[0m                     \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1473\u001b[0m                     \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1962\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0m_serialization_tls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m     \u001b[0m_serialization_tls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_location\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1964\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1965\u001b[0m     \u001b[0m_serialization_tls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_location\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1926\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1927\u001b[0m             \u001b[0mnbytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumel\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1928\u001b[0;31m             typed_storage = load_tensor(\n\u001b[0m\u001b[1;32m   1929\u001b[0m                 \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_maybe_decode_ascii\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1930\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1886\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1887\u001b[0m             storage = (\n\u001b[0;32m-> 1888\u001b[0;31m                 \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_storage_from_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUntypedStorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1889\u001b[0m                 \u001b[0;34m.\u001b[0m\u001b[0m_typed_storage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m                 \u001b[0;34m.\u001b[0m\u001b[0m_untyped_storage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# INSTALLATION\n",
        "!pip install fastapi uvicorn python-multipart opencv-python matplotlib timm torch torchvision open3d\n",
        "\n",
        "# Imports\n",
        "import os\n",
        "import io\n",
        "import base64\n",
        "import numpy as np\n",
        "import torch\n",
        "import cv2\n",
        "import open3d as o3d\n",
        "import matplotlib.pyplot as plt\n",
        "from fastapi import FastAPI, UploadFile, File\n",
        "from fastapi.responses import JSONResponse\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "\n",
        "# Charger modÃ¨le MiDaS une fois au dÃ©marrage\n",
        "model_type = \"DPT_Large\"\n",
        "midas = torch.hub.load(\"intel-isl/MiDaS\", model_type, trust_repo=True)\n",
        "midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\", trust_repo=True)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "midas.to(device)\n",
        "midas.eval()\n",
        "\n",
        "transform = midas_transforms.dpt_transform if model_type.startswith(\"DPT\") else midas_transforms.small_transform\n",
        "\n",
        "# CrÃ©ation FastAPI app\n",
        "app = FastAPI()\n",
        "\n",
        "# CORS pour React frontend distant (adapter l'origin)\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=[\"*\"],  # mettre URL frontend en prod\n",
        "    allow_credentials=True,\n",
        "    allow_methods=[\"*\"],\n",
        "    allow_headers=[\"*\"],\n",
        ")\n",
        "\n",
        "def create_pointcloud_and_depth(image_np):\n",
        "    # image_np : numpy RGB uint8\n",
        "\n",
        "    input_tensor = transform(image_np).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        prediction = midas(input_tensor)\n",
        "        prediction = torch.nn.functional.interpolate(\n",
        "            prediction.unsqueeze(1),\n",
        "            size=image_np.shape[:2],\n",
        "            mode=\"bicubic\",\n",
        "            align_corners=False,\n",
        "        ).squeeze()\n",
        "\n",
        "    depth = prediction.cpu().numpy()\n",
        "    depth_norm = np.clip(depth, 0.1, 100)\n",
        "\n",
        "    # ParamÃ¨tres camÃ©ra\n",
        "    fx, fy = 500, 500\n",
        "    h, w = depth.shape\n",
        "    cx, cy = w / 2, h / 2\n",
        "\n",
        "    all_points = []\n",
        "    all_colors = []\n",
        "    stride = 8\n",
        "    for y in range(0, h, stride):\n",
        "        for x in range(0, w, stride):\n",
        "            z = depth_norm[y, x]\n",
        "            if np.isnan(z) or np.isinf(z):\n",
        "                continue\n",
        "            X = (x - cx) * z / fx\n",
        "            Y = (y - cy) * z / fy\n",
        "            if np.any(np.isnan([X, Y, z])) or np.any(np.isinf([X, Y, z])):\n",
        "                continue\n",
        "            all_points.append([X, -Y, -z])\n",
        "            all_colors.append(image_np[y, x] / 255.0)\n",
        "\n",
        "    if not all_points:\n",
        "        raise RuntimeError(\"Aucun point valide gÃ©nÃ©rÃ©.\")\n",
        "\n",
        "    pcd = o3d.geometry.PointCloud()\n",
        "    pcd.points = o3d.utility.Vector3dVector(np.array(all_points))\n",
        "    pcd.colors = o3d.utility.Vector3dVector(np.array(all_colors))\n",
        "\n",
        "    # Sauvegarder depth en PNG en mÃ©moire\n",
        "    depth_img_path = \"depth_image.png\"\n",
        "    plt.imsave(depth_img_path, depth, cmap='inferno')\n",
        "\n",
        "    # Sauvegarder nuage points en PLY en mÃ©moire\n",
        "    ply_path = \"scene3d.ply\"\n",
        "    o3d.io.write_point_cloud(ply_path, pcd)\n",
        "\n",
        "    # Lire fichiers en base64 pour rÃ©ponse\n",
        "    with open(depth_img_path, \"rb\") as f:\n",
        "        depth_b64 = base64.b64encode(f.read()).decode(\"utf-8\")\n",
        "    with open(ply_path, \"rb\") as f:\n",
        "        ply_b64 = base64.b64encode(f.read()).decode(\"utf-8\")\n",
        "\n",
        "    # Supprimer fichiers temporaires\n",
        "    os.remove(depth_img_path)\n",
        "    os.remove(ply_path)\n",
        "\n",
        "    return depth_b64, ply_b64\n",
        "\n",
        "@app.post(\"/predict\")\n",
        "async def predict(image: UploadFile = File(...)):\n",
        "    try:\n",
        "        contents = await image.read()\n",
        "        np_arr = np.frombuffer(contents, np.uint8)\n",
        "        img_bgr = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)\n",
        "        if img_bgr is None:\n",
        "            return JSONResponse(status_code=400, content={\"error\": \"Image invalide\"})\n",
        "        img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        depth_b64, ply_b64 = create_pointcloud_and_depth(img_rgb)\n",
        "\n",
        "        return {\n",
        "            \"depth_image_base64\": depth_b64,\n",
        "            \"pointcloud_ply_base64\": ply_b64,\n",
        "            \"message\": \"SuccÃ¨s de la prÃ©diction MiDaS\",\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return JSONResponse(status_code=500, content={\"error\": str(e)})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 526
        },
        "id": "nYgnPLiG1vM2",
        "outputId": "897731a5-d1ca-4d3d-b062-f02e00c6efab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chargement MiDaS...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/intel-isl/MiDaS/zipball/master\" to /root/.cache/torch/hub/master.zip\n",
            "/usr/local/lib/python3.11/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
            "Downloading: \"https://github.com/isl-org/MiDaS/releases/download/v3/dpt_large_384.pt\" to /root/.cache/torch/hub/checkpoints/dpt_large_384.pt\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.28G/1.28G [00:05<00:00, 260MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "â¬†ï¸ Upload image pour reconstruction...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/intel-isl_MiDaS_master\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-12a0fce3-3245-45fc-8212-0a632ac313ca\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-12a0fce3-3245-45fc-8212-0a632ac313ca\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 20250719_220835.jpg to 20250719_220835.jpg\n",
            "[1/7] PrÃ©traitement image...\n",
            "[LOG] NettetÃ© (Laplacian): 31067.61\n",
            "[2/7] Inpainting zones sombres...\n",
            "[3/7] Segmentation sÃ©mantique...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DeepLabV3_ResNet50_Weights.COCO_WITH_VOC_LABELS_V1`. You can also use `weights=DeepLabV3_ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/deeplabv3_resnet50_coco-cd0a2569.pth\" to /root/.cache/torch/hub/checkpoints/deeplabv3_resnet50_coco-cd0a2569.pth\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 161M/161M [00:01<00:00, 146MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4/7] Super-rÃ©solution...\n",
            "[5/7] Profondeur avec MiDaS...\n",
            "[6/7] Reconstruction 3D avec maillage...\n",
            "[INFO] Reconstruction de maillage avec Poisson...\n",
            "[7/7] Exportation en OBJ et PNG...\n"
          ]
        }
      ],
      "source": [
        "# âœ… IMPORTS\n",
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "import open3d as o3d\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ExifTags, ImageEnhance, ImageFilter\n",
        "from google.colab import files\n",
        "import torchvision.transforms as T\n",
        "from torchvision.models.segmentation import deeplabv3_resnet50\n",
        "import time  # AjoutÃ© pour gÃ©rer les dÃ©lais\n",
        "\n",
        "# âœ… SETUP\n",
        "torch.manual_seed(42)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "os.makedirs(\"output_frames\", exist_ok=True)\n",
        "\n",
        "# âœ… UTILS\n",
        "def correct_orientation(image: Image.Image) -> Image.Image:\n",
        "    try:\n",
        "        for orientation in ExifTags.TAGS.keys():\n",
        "            if ExifTags.TAGS[orientation] == 'Orientation':\n",
        "                break\n",
        "        exif = dict(image._getexif().items())\n",
        "        orientation_value = exif.get(orientation, None)\n",
        "        if orientation_value == 3:\n",
        "            image = image.rotate(180, expand=True)\n",
        "        elif orientation_value == 6:\n",
        "            image = image.rotate(270, expand=True)\n",
        "        elif orientation_value == 8:\n",
        "            image = image.rotate(90, expand=True)\n",
        "    except:\n",
        "        pass\n",
        "    return image\n",
        "\n",
        "def enhance_image(image: Image.Image) -> Image.Image:\n",
        "    image = ImageEnhance.Contrast(image).enhance(1.8)\n",
        "    image = ImageEnhance.Sharpness(image).enhance(2.0)\n",
        "    image = image.filter(ImageFilter.EDGE_ENHANCE_MORE)\n",
        "    return image\n",
        "\n",
        "def load_and_prepare_image(image_path, target_max_size=512):\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    image = correct_orientation(image)\n",
        "    max_dim = max(image.size)\n",
        "    if max_dim > target_max_size:\n",
        "        scale = target_max_size / max_dim\n",
        "        image = image.resize((int(image.size[0]*scale), int(image.size[1]*scale)), Image.LANCZOS)\n",
        "    image = enhance_image(image)\n",
        "    return np.array(image)\n",
        "\n",
        "def check_image_quality(img):\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "    lap_var = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
        "    print(f\"[LOG] NettetÃ© (Laplacian): {lap_var:.2f}\")\n",
        "    if img.std() < 10:\n",
        "        raise ValueError(\"Image trop plate (contraste)\")\n",
        "    if img.mean() < 10:\n",
        "        raise ValueError(\"Image trop sombre\")\n",
        "\n",
        "def auto_inpaint(img):\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "    _, mask = cv2.threshold(gray, 5, 255, cv2.THRESH_BINARY_INV)\n",
        "    return cv2.inpaint(img, mask, 3, cv2.INPAINT_TELEA)\n",
        "\n",
        "# âœ… SEGMENTATION DEEPLAB\n",
        "def run_segmentation(img_rgb):\n",
        "    model = deeplabv3_resnet50(pretrained=True).to(device)\n",
        "    model.eval()\n",
        "    preprocess = T.Compose([\n",
        "        T.ToTensor(),\n",
        "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "    input_tensor = preprocess(Image.fromarray(img_rgb)).unsqueeze(0).to(device)\n",
        "    with torch.no_grad():\n",
        "        output = model(input_tensor)['out'][0]\n",
        "    return output.argmax(0).byte().cpu().numpy()\n",
        "\n",
        "def colorize_segmentation(seg):\n",
        "    palette = np.array([\n",
        "        [0,0,0],[128,0,0],[0,128,0],[128,128,0],[0,0,128],\n",
        "        [128,0,128],[0,128,128],[128,128,128],[64,0,0],[192,0,0],\n",
        "        [64,128,0],[192,128,0],[64,0,128],[192,0,128],[64,128,128],\n",
        "        [192,128,128],[0,64,0],[128,64,0],[0,192,0],[128,192,0],\n",
        "        [0,64,128]\n",
        "    ])\n",
        "    return palette[seg % 21].astype(np.uint8)\n",
        "\n",
        "def super_resolution(img, scale=2):\n",
        "    return cv2.resize(img, (img.shape[1]*scale, img.shape[0]*scale), interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "# âœ… MIDAS SETUP\n",
        "print(\"Chargement MiDaS...\")\n",
        "model_type = \"DPT_Large\"\n",
        "midas = torch.hub.load(\"intel-isl/MiDaS\", model_type, trust_repo=True).to(device).eval()\n",
        "midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\", trust_repo=True)\n",
        "transform = midas_transforms.dpt_transform\n",
        "\n",
        "# âœ… UPLOAD IMAGE\n",
        "print(\"â¬†ï¸ Upload image pour reconstruction...\")\n",
        "uploaded = files.upload()\n",
        "image_path = next(iter(uploaded))\n",
        "\n",
        "# âœ… PIPELINE\n",
        "print(\"[1/7] PrÃ©traitement image...\")\n",
        "img_rgb = load_and_prepare_image(image_path)\n",
        "check_image_quality(img_rgb)\n",
        "\n",
        "print(\"[2/7] Inpainting zones sombres...\")\n",
        "img_rgb = auto_inpaint(img_rgb)\n",
        "\n",
        "print(\"[3/7] Segmentation sÃ©mantique...\")\n",
        "seg = run_segmentation(img_rgb)\n",
        "color_seg = colorize_segmentation(seg)\n",
        "plt.imsave(\"output_frames/segmentation.png\", color_seg)\n",
        "\n",
        "print(\"[4/7] Super-rÃ©solution...\")\n",
        "img_sr = super_resolution(img_rgb, scale=2)\n",
        "plt.imsave(\"output_frames/super_resolution.png\", img_sr)\n",
        "\n",
        "print(\"[5/7] Profondeur avec MiDaS...\")\n",
        "input_tensor = transform(img_sr).to(device)\n",
        "with torch.no_grad():\n",
        "    prediction = midas(input_tensor)\n",
        "    prediction = torch.nn.functional.interpolate(\n",
        "        prediction.unsqueeze(1),\n",
        "        size=img_sr.shape[:2],\n",
        "        mode=\"bicubic\",\n",
        "        align_corners=False,\n",
        "    ).squeeze()\n",
        "depth = prediction.cpu().numpy()\n",
        "plt.imsave(\"output_frames/depth_map.png\", depth, cmap=\"inferno\")\n",
        "\n",
        "print(\"[6/7] Reconstruction 3D avec maillage...\")\n",
        "fx, fy = 500, 500\n",
        "h, w = depth.shape\n",
        "cx, cy = w/2, h/2\n",
        "depth = np.clip(depth, 0.1, 100)\n",
        "\n",
        "# GÃ©nÃ©rer nuage de points\n",
        "points, colors, texcoords = [], [], []\n",
        "stride = 4\n",
        "for y in range(0, h, stride):\n",
        "    for x in range(0, w, stride):\n",
        "        z = depth[y, x]\n",
        "        if np.isnan(z) or np.isinf(z):\n",
        "            continue\n",
        "        X = (x - cx) * z / fx\n",
        "        Y = (y - cy) * z / fy\n",
        "        points.append([X, -Y, -z])\n",
        "        cx2, cy2 = min(x, img_sr.shape[1]-1), min(y, img_sr.shape[0]-1)\n",
        "        colors.append(img_sr[cy2, cx2] / 255.0)\n",
        "        texcoords.append([x / w, 1.0 - y / h])\n",
        "\n",
        "points = np.array(points)\n",
        "colors = np.array(colors)\n",
        "texcoords = np.array(texcoords)\n",
        "\n",
        "# CrÃ©er nuage de points\n",
        "pcd = o3d.geometry.PointCloud()\n",
        "pcd.points = o3d.utility.Vector3dVector(points)\n",
        "pcd.colors = o3d.utility.Vector3dVector(colors)\n",
        "\n",
        "# Estimation des normales\n",
        "pcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.1, max_nn=30))\n",
        "\n",
        "# Reconstruction de maillage avec Poisson\n",
        "print(\"[INFO] Reconstruction de maillage avec Poisson...\")\n",
        "mesh, densities = o3d.geometry.TriangleMesh.create_from_point_cloud_poisson(\n",
        "    pcd, depth=8, scale=1.1, linear_fit=True\n",
        ")\n",
        "mesh.compute_vertex_normals()\n",
        "\n",
        "# Sauvegarde de la carte de texture\n",
        "texture_path = \"output_frames/texture.png\"\n",
        "plt.imsave(texture_path, img_sr)\n",
        "\n",
        "# Exportation en OBJ avec MTL\n",
        "print(\"[7/7] Exportation en OBJ et PNG...\")\n",
        "def save_obj_with_mtl(mesh, texture_path, output_obj_path=\"scene3d.obj\"):\n",
        "    vertices = np.asarray(mesh.vertices)\n",
        "    normals = np.asarray(mesh.vertex_normals)\n",
        "    triangles = np.asarray(mesh.triangles)\n",
        "    texcoords = np.random.rand(len(vertices), 2)  # Placeholder pour UV\n",
        "\n",
        "    mtl_path = output_obj_path.replace(\".obj\", \".mtl\")\n",
        "    with open(mtl_path, \"w\") as mtl_file:\n",
        "        mtl_file.write(f\"newmtl material_0\\n\")\n",
        "        mtl_file.write(f\"map_Kd {os.path.basename(texture_path)}\\n\")\n",
        "\n",
        "    with open(output_obj_path, \"w\") as obj_file:\n",
        "        obj_file.write(f\"mtllib {os.path.basename(mtl_path)}\\n\")\n",
        "        for v in vertices:\n",
        "            obj_file.write(f\"v {v[0]} {v[1]} {v[2]}\\n\")\n",
        "        for n in normals:\n",
        "            obj_file.write(f\"vn {n[0]} {n[1]} {n[2]}\\n\")\n",
        "        for uv in texcoords:\n",
        "            obj_file.write(f\"vt {uv[0]} {uv[1]}\\n\")\n",
        "        obj_file.write(\"usemtl material_0\\n\")\n",
        "        for t in triangles:\n",
        "            obj_file.write(f\"f {t[0]+1}/{t[0]+1}/{t[0]+1} {t[1]+1}/{t[1]+1}/{t[1]+1} {t[2]+1}/{t[2]+1}/{t[2]+1}\\n\")\n",
        "\n",
        "save_obj_with_mtl(mesh, texture_path, \"scene3d.obj\")\n",
        "\n",
        "# Rendu PNG de la scÃ¨ne 3D\n",
        "vis = o3d.visualization.Visualizer()\n",
        "vis.create_window(visible=False)\n",
        "vis.add_geometry(mesh)\n",
        "vis.capture_screen_image(\"output_frames/rendered_scene.png\")\n",
        "vis.destroy_window()\n",
        "\n",
        "# TÃ©lÃ©chargements sÃ©quentiels avec dÃ©lais\n",
        "print(\"[INFO] TÃ©lÃ©chargement des fichiers...\")\n",
        "file_list = [\"scene3d.obj\", \"scene3d.mtl\", \"output_frames/texture.png\", \"output_frames/rendered_scene.png\"]\n",
        "for file_path in file_list:\n",
        "    if os.path.exists(file_path):\n",
        "        print(f\"[INFO] TÃ©lÃ©chargement de {file_path}...\")\n",
        "        files.download(file_path)\n",
        "        time.sleep(2)  # DÃ©lai de 2 secondes entre chaque tÃ©lÃ©chargement\n",
        "    else:\n",
        "        print(f\"[ERREUR] Le fichier {file_path} n'existe pas.\")\n",
        "\n",
        "print(\"âœ… TerminÃ©. Maillage 3D avec texture exportÃ© (OBJ, MTL, PNG) et rendu PNG gÃ©nÃ©rÃ©.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r3UbRD5Bg0gu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# âœ… IMPORTS\n",
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "import open3d as o3d\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ExifTags, ImageEnhance, ImageFilter\n",
        "from google.colab import files\n",
        "import torchvision.transforms as T\n",
        "from torchvision.models.segmentation import deeplabv3_resnet50\n",
        "import time\n",
        "\n",
        "# âœ… SETUP\n",
        "torch.manual_seed(42)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "os.makedirs(\"output_frames\", exist_ok=True)\n",
        "\n",
        "# âœ… UTILS\n",
        "def correct_orientation(image: Image.Image) -> Image.Image:\n",
        "    try:\n",
        "        for orientation in ExifTags.TAGS.keys():\n",
        "            if ExifTags.TAGS[orientation] == 'Orientation':\n",
        "                break\n",
        "        exif = dict(image._getexif().items())\n",
        "        orientation_value = exif.get(orientation, None)\n",
        "        if orientation_value == 3:\n",
        "            image = image.rotate(180, expand=True)\n",
        "        elif orientation_value == 6:\n",
        "            image = image.rotate(270, expand=True)\n",
        "        elif orientation_value == 8:\n",
        "            image = image.rotate(90, expand=True)\n",
        "    except:\n",
        "        pass\n",
        "    return image\n",
        "\n",
        "def enhance_image(image: Image.Image) -> Image.Image:\n",
        "    image = ImageEnhance.Contrast(image).enhance(1.8)\n",
        "    image = ImageEnhance.Sharpness(image).enhance(2.0)\n",
        "    image = image.filter(ImageFilter.EDGE_ENHANCE_MORE)\n",
        "    return image\n",
        "\n",
        "def load_and_prepare_image(image_path, target_max_size=512):\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    image = correct_orientation(image)\n",
        "    max_dim = max(image.size)\n",
        "    if max_dim > target_max_size:\n",
        "        scale = target_max_size / max_dim\n",
        "        image = image.resize((int(image.size[0]*scale), int(image.size[1]*scale)), Image.LANCZOS)\n",
        "    image = enhance_image(image)\n",
        "    return np.array(image)\n",
        "\n",
        "def check_image_quality(img):\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "    lap_var = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
        "    print(f\"[LOG] NettetÃ© (Laplacian): {lap_var:.2f}\")\n",
        "    if img.std() < 10:\n",
        "        raise ValueError(\"Image trop plate (contraste)\")\n",
        "    if img.mean() < 10:\n",
        "        raise ValueError(\"Image trop sombre\")\n",
        "\n",
        "def auto_inpaint(img):\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "    _, mask = cv2.threshold(gray, 5, 255, cv2.THRESH_BINARY_INV)\n",
        "    return cv2.inpaint(img, mask, 3, cv2.INPAINT_TELEA)\n",
        "\n",
        "# âœ… SEGMENTATION DEEPLAB\n",
        "def run_segmentation(img_rgb):\n",
        "    model = deeplabv3_resnet50(pretrained=True).to(device)\n",
        "    model.eval()\n",
        "    preprocess = T.Compose([\n",
        "        T.ToTensor(),\n",
        "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "    input_tensor = preprocess(Image.fromarray(img_rgb)).unsqueeze(0).to(device)\n",
        "    with torch.no_grad():\n",
        "        output = model(input_tensor)['out'][0]\n",
        "    return output.argmax(0).byte().cpu().numpy()\n",
        "\n",
        "def colorize_segmentation(seg):\n",
        "    palette = np.array([\n",
        "        [0,0,0],[128,0,0],[0,128,0],[128,128,0],[0,0,128],\n",
        "        [128,0,128],[0,128,128],[128,128,128],[64,0,0],[192,0,0],\n",
        "        [64,128,0],[192,128,0],[64,0,128],[192,0,128],[64,128,128],\n",
        "        [192,128,128],[0,64,0],[128,64,0],[0,192,0],[128,192,0],\n",
        "        [0,64,128]\n",
        "    ])\n",
        "    return palette[seg % 21].astype(np.uint8)\n",
        "\n",
        "def super_resolution(img, scale=2):\n",
        "    return cv2.resize(img, (img.shape[1]*scale, img.shape[0]*scale), interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "# âœ… MIDAS SETUP\n",
        "print(\"Chargement MiDaS...\")\n",
        "model_type = \"DPT_Large\"\n",
        "midas = torch.hub.load(\"intel-isl/MiDaS\", model_type, trust_repo=True).to(device).eval()\n",
        "midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\", trust_repo=True)\n",
        "transform = midas_transforms.dpt_transform\n",
        "\n",
        "# âœ… UPLOAD IMAGE\n",
        "print(\"â¬†ï¸ Upload image pour reconstruction...\")\n",
        "uploaded = files.upload()\n",
        "image_path = next(iter(uploaded))\n",
        "\n",
        "# âœ… PIPELINE\n",
        "print(\"[1/6] PrÃ©traitement image...\")\n",
        "img_rgb = load_and_prepare_image(image_path)\n",
        "check_image_quality(img_rgb)\n",
        "\n",
        "print(\"[2/6] Inpainting zones sombres...\")\n",
        "img_rgb = auto_inpaint(img_rgb)\n",
        "\n",
        "print(\"[3/6] Segmentation sÃ©mantique...\")\n",
        "seg = run_segmentation(img_rgb)\n",
        "color_seg = colorize_segmentation(seg)\n",
        "plt.imsave(\"output_frames/segmentation.png\", color_seg)\n",
        "\n",
        "print(\"[4/6] Super-rÃ©solution...\")\n",
        "img_sr = super_resolution(img_rgb, scale=2)\n",
        "plt.imsave(\"output_frames/super_resolution.png\", img_sr)\n",
        "\n",
        "print(\"[5/6] Profondeur avec MiDaS...\")\n",
        "input_tensor = transform(img_sr).to(device)\n",
        "with torch.no_grad():\n",
        "    prediction = midas(input_tensor)\n",
        "    prediction = torch.nn.functional.interpolate(\n",
        "        prediction.unsqueeze(1),\n",
        "        size=img_sr.shape[:2],\n",
        "        mode=\"bicubic\",\n",
        "        align_corners=False,\n",
        "    ).squeeze()\n",
        "depth = prediction.cpu().numpy()\n",
        "plt.imsave(\"output_frames/depth_map.png\", depth, cmap=\"inferno\")\n",
        "\n",
        "print(\"[6/6] Reconstruction 3D et rendu PNG...\")\n",
        "fx, fy = 500, 500\n",
        "h, w = depth.shape\n",
        "cx, cy = w/2, h/2\n",
        "depth = np.clip(depth, 0.1, 100)\n",
        "\n",
        "# GÃ©nÃ©rer nuage de points\n",
        "points, colors = [], []\n",
        "stride = 4\n",
        "for y in range(0, h, stride):\n",
        "    for x in range(0, w, stride):\n",
        "        z = depth[y, x]\n",
        "        if np.isnan(z) or np.isinf(z):\n",
        "            continue\n",
        "        X = (x - cx) * z / fx\n",
        "        Y = (y - cy) * z / fy\n",
        "        points.append([X, -Y, -z])\n",
        "        cx2, cy2 = min(x, img_sr.shape[1]-1), min(y, img_sr.shape[0]-1)\n",
        "        colors.append(img_sr[cy2, cx2] / 255.0)\n",
        "\n",
        "points = np.array(points)\n",
        "colors = np.array(colors)\n",
        "\n",
        "# CrÃ©er nuage de points\n",
        "pcd = o3d.geometry.PointCloud()\n",
        "pcd.points = o3d.utility.Vector3dVector(points)\n",
        "pcd.colors = o3d.utility.Vector3dVector(colors)\n",
        "\n",
        "# Estimation des normales\n",
        "pcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.1, max_nn=30))\n",
        "\n",
        "# Reconstruction de maillage avec Poisson\n",
        "print(\"[INFO] Reconstruction de maillage avec Poisson...\")\n",
        "mesh, _ = o3d.geometry.TriangleMesh.create_from_point_cloud_poisson(\n",
        "    pcd, depth=8, scale=1.1, linear_fit=True\n",
        ")\n",
        "mesh.compute_vertex_normals()\n",
        "\n",
        "# Rendu PNG de la scÃ¨ne 3D\n",
        "rendered_png_path = \"output_frames/rendered_scene.png\"\n",
        "vis = o3d.visualization.Visualizer()\n",
        "vis.create_window(visible=False)\n",
        "vis.add_geometry(mesh)\n",
        "vis.capture_screen_image(rendered_png_path)\n",
        "vis.destroy_window()\n",
        "\n",
        "# TÃ©lÃ©chargement du fichier PNG\n",
        "print(\"[INFO] TÃ©lÃ©chargement du rendu PNG...\")\n",
        "if os.path.exists(rendered_png_path):\n",
        "    files.download(rendered_png_path)\n",
        "    print(f\"[INFO] Fichier {rendered_png_path} tÃ©lÃ©chargÃ© avec succÃ¨s.\")\n",
        "else:\n",
        "    print(f\"[ERREUR] Le fichier {rendered_png_path} n'a pas Ã©tÃ© gÃ©nÃ©rÃ©.\")\n",
        "\n",
        "print(\"âœ… TerminÃ©. Rendu PNG gÃ©nÃ©rÃ© et tÃ©lÃ©chargÃ©.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "AV4wepEp70tH",
        "outputId": "eb97e4dd-b212-4f2c-eed8-71335f900a8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chargement MiDaS...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/intel-isl_MiDaS_master\n",
            "/usr/local/lib/python3.11/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "â¬†ï¸ Upload image pour reconstruction...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/intel-isl_MiDaS_master\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-59ac6fa7-277a-4586-a862-b89f27767cfc\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-59ac6fa7-277a-4586-a862-b89f27767cfc\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving IMG-20250719-WA0036.jpg to IMG-20250719-WA0036.jpg\n",
            "[1/6] PrÃ©traitement image...\n",
            "[LOG] NettetÃ© (Laplacian): 114142.72\n",
            "[2/6] Inpainting zones sombres...\n",
            "[3/6] Segmentation sÃ©mantique...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DeepLabV3_ResNet50_Weights.COCO_WITH_VOC_LABELS_V1`. You can also use `weights=DeepLabV3_ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4/6] Super-rÃ©solution...\n",
            "[5/6] Profondeur avec MiDaS...\n",
            "[6/6] Reconstruction 3D et rendu PNG...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Installer les dÃ©pendances nÃ©cessaires\n",
        "!pip install open3d pythreejs trimesh --quiet\n",
        "\n",
        "import open3d as o3d\n",
        "import numpy as np\n",
        "import trimesh\n",
        "from google.colab import files\n",
        "from IPython.display import display\n",
        "from pythreejs import *\n",
        "import ipywidgets\n",
        "\n",
        "# Upload fichier nuage de points\n",
        "uploaded = files.upload()\n",
        "filename = list(uploaded.keys())[0]\n",
        "\n",
        "# Lecture du nuage\n",
        "pcd = o3d.io.read_point_cloud(filename)\n",
        "print(f\"Nuage chargÃ© : {len(pcd.points)} points\")\n",
        "\n",
        "# Nettoyage statistique\n",
        "pcd, ind = pcd.remove_statistical_outlier(nb_neighbors=20, std_ratio=2.0)\n",
        "print(f\"Points aprÃ¨s nettoyage : {len(pcd.points)}\")\n",
        "\n",
        "# Normales\n",
        "pcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=1.0, max_nn=30))\n",
        "\n",
        "# Reconstruction Poisson\n",
        "mesh, densities = o3d.geometry.TriangleMesh.create_from_point_cloud_poisson(pcd, depth=9)\n",
        "threshold = np.quantile(densities, 0.01)\n",
        "mesh.remove_vertices_by_mask(densities < threshold)\n",
        "mesh.compute_vertex_normals()\n",
        "\n",
        "# Transfert couleurs si prÃ©sentes\n",
        "if pcd.has_colors():\n",
        "    mesh.vertex_colors = pcd.colors\n",
        "\n",
        "# Export mesh en .glb pour visualisation web\n",
        "mesh_trimesh = trimesh.Trimesh(\n",
        "    vertices=np.asarray(mesh.vertices),\n",
        "    faces=np.asarray(mesh.triangles),\n",
        "    vertex_colors=np.asarray(mesh.vertex_colors) if mesh.has_vertex_colors() else None\n",
        ")\n",
        "mesh_trimesh.export('mesh.glb')\n",
        "\n",
        "print(\"Mesh exportÃ© sous mesh.glb\")\n",
        "\n",
        "# Visualisation interactive avec pythreejs\n",
        "\n",
        "def trimesh_to_geometry(mesh):\n",
        "    positions = np.array(mesh.vertices).astype(np.float32)\n",
        "    faces = np.array(mesh.faces).astype(np.uint32)\n",
        "    colors = None\n",
        "    if mesh.visual.vertex_colors is not None:\n",
        "        colors = np.array(mesh.visual.vertex_colors)[:, :3] / 255.0\n",
        "    geometry = BufferGeometry(\n",
        "        attributes={\n",
        "            'position': BufferAttribute(positions, normalized=False),\n",
        "            'index': BufferAttribute(faces.flatten(), normalized=False),\n",
        "        }\n",
        "    )\n",
        "    if colors is not None:\n",
        "        geometry.attributes['color'] = BufferAttribute(colors, normalized=False)\n",
        "    return geometry\n",
        "\n",
        "geometry = trimesh_to_geometry(mesh_trimesh)\n",
        "material = MeshLambertMaterial(vertexColors='VertexColors') if mesh_trimesh.visual.vertex_colors.any() else MeshLambertMaterial(color='gray')\n",
        "mesh3js = Mesh(geometry=geometry, material=material)\n",
        "\n",
        "scene = Scene(children=[\n",
        "    mesh3js,\n",
        "    AmbientLight(intensity=0.5),\n",
        "    DirectionalLight(position=[3, 5, 1], intensity=0.6)\n",
        "])\n",
        "\n",
        "camera = PerspectiveCamera(position=[0, 0, 3], fov=60,\n",
        "                           children=[DirectionalLight(color='white', position=[0, 0, 1], intensity=0.5)])\n",
        "\n",
        "controller = OrbitControls(controlling=camera)\n",
        "\n",
        "renderer = Renderer(camera=camera, scene=scene, controls=[controller], width=800, height=600)\n",
        "\n",
        "display(renderer)\n",
        "\n",
        "# Lien tÃ©lÃ©chargement\n",
        "files.download('mesh.glb')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249,
          "referenced_widgets": [
            "4c3da33fd4e74c8582363fba0f5645ea"
          ]
        },
        "id": "eH2VONMXg3pc",
        "outputId": "2324e68e-58ce-4777-fb36-8b6a2cef3649"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m271.7/271.7 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-cd37d3ba-085e-4e9a-8113-e1c88cbd7a10\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-cd37d3ba-085e-4e9a-8113-e1c88cbd7a10\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving gh.ply to gh.ply\n",
            "Nuage chargÃ© : 49152 points\n",
            "Points aprÃ¨s nettoyage : 48129\n",
            "Mesh exportÃ© sous mesh.glb\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pythreejs/traits.py:257: UserWarning: 64-bit data types not supported for WebGL data, casting to 32-bit.\n",
            "  warnings.warn('64-bit data types not supported for WebGL '\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Renderer(camera=PerspectiveCamera(children=(DirectionalLight(color='white', intensity=0.5, position=(0.0, 0.0,â€¦"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4c3da33fd4e74c8582363fba0f5645ea"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_097bfa97-0f32-470c-ae91-45b108ca573c\", \"mesh.glb\", 4114440)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install open3d trimesh gradio --quiet"
      ],
      "metadata": {
        "id": "gD19UjVcjoam"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ã‰tape 1 : Installer les dÃ©pendances\n",
        "!pip install torch torchvision open3d pyrender numpy opencv-python pillow trimesh ultralytics matplotlib vtk\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import open3d as o3d\n",
        "import pyrender\n",
        "import trimesh\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "import os\n",
        "import uuid\n",
        "from ultralytics import YOLO\n",
        "import vtk\n",
        "\n",
        "# Ã‰tape 2 : Charger les modÃ¨les MiDaS et YOLOv8\n",
        "def load_models():\n",
        "    model_type = \"MiDaS_small\"\n",
        "    midas = torch.hub.load(\"intel-isl/MiDaS\", model_type, pretrained=True, trust_repo=True)\n",
        "    midas.eval()\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    midas.to(device)\n",
        "    midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\", trust_repo=True)\n",
        "    transform = midas_transforms.small_transform\n",
        "\n",
        "    yolo = YOLO(\"yolov8n.pt\")\n",
        "    yolo.to(device)\n",
        "\n",
        "    return midas, transform, yolo, device\n",
        "\n",
        "midas, midas_transform, yolo, device = load_models()\n",
        "print(\"ModÃ¨les MiDaS et YOLOv8 chargÃ©s avec succÃ¨s\")\n",
        "\n",
        "# Ã‰tape 3 : CrÃ©er un nuage de points Ã  partir dâ€™une image\n",
        "def create_point_cloud_from_image(image_path):\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    image = image.resize((160, 120), Image.LANCZOS)\n",
        "    image_np = np.array(image)\n",
        "\n",
        "    img = cv2.cvtColor(image_np, cv2.COLOR_RGB2BGR)\n",
        "    input_batch = midas_transform(img).to(device)\n",
        "    with torch.no_grad():\n",
        "        prediction = midas(input_batch)\n",
        "        prediction = torch.nn.functional.interpolate(\n",
        "            prediction.unsqueeze(1),\n",
        "            size=(120, 160),\n",
        "            mode=\"bicubic\",\n",
        "            align_corners=False,\n",
        "        ).squeeze().cpu().numpy()\n",
        "    depth = prediction\n",
        "\n",
        "    results = yolo(image_np, conf=0.5)\n",
        "    annotations = []\n",
        "    for result in results:\n",
        "        for box in result.boxes:\n",
        "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "            cls = int(box.cls[0])\n",
        "            label = yolo.names[cls]\n",
        "            if label in [\"person\", \"car\", \"truck\", \"animal\", \"bed\", \"tv\"]:\n",
        "                x_center = (x1 + x2) // 2\n",
        "                y_center = (y1 + y2) // 2\n",
        "                z = float(depth[y_center, x_center] / np.max(depth))\n",
        "                x_norm = float((x_center - 160 / 2) / max(160, 120))\n",
        "                y_norm = float((y_center - 120 / 2) / max(160, 120))\n",
        "                annotations.append({\n",
        "                    \"type\": \"sphere\",\n",
        "                    \"position\": [x_norm, -y_norm, z],\n",
        "                    \"radius\": 0.02,\n",
        "                    \"color\": [1.0, 0.0, 0.0],\n",
        "                    \"label\": label\n",
        "                })\n",
        "    print(f\"{len(annotations)} objets dÃ©tectÃ©s par YOLOv8\")\n",
        "\n",
        "    positions = []\n",
        "    colors = []\n",
        "    h, w = depth.shape\n",
        "    for y in range(0, h, 2):\n",
        "        for x in range(0, w, 2):\n",
        "            z = depth[y, x]\n",
        "            x_norm = float((x - w / 2) / max(w, h))\n",
        "            y_norm = float((y - h / 2) / max(w, h))\n",
        "            z_norm = float(z / np.max(depth))\n",
        "            positions.append([x_norm, -y_norm, z_norm])\n",
        "            colors.append(image_np[y, x] / 255.0)\n",
        "\n",
        "    return np.array(positions), np.array(colors), annotations, image_np\n",
        "\n",
        "# Ã‰tape 4 : Charger un nuage de points Ã  partir dâ€™un fichier PLY\n",
        "def load_ply(file_path):\n",
        "    mesh = trimesh.load(file_path, file_type=\"ply\")\n",
        "    if not isinstance(mesh, trimesh.PointCloud):\n",
        "        raise ValueError(\"Le fichier n'est pas un nuage de points valide\")\n",
        "    positions = mesh.vertices.astype(np.float32)\n",
        "    colors = mesh.colors[:, :3].astype(float) / 255.0 if hasattr(mesh, \"colors\") and mesh.colors is not None else None\n",
        "    return positions, colors\n",
        "\n",
        "# Ã‰tape 5 : DÃ©cimation du nuage de points\n",
        "def decimate_point_cloud(positions, colors=None, max_points=50000):\n",
        "    if len(positions) > max_points:\n",
        "        points = vtk.vtkPoints()\n",
        "        for pos in positions:\n",
        "            points.InsertNextPoint(pos)\n",
        "        polydata = vtk.vtkPolyData()\n",
        "        polydata.SetPoints(points)\n",
        "\n",
        "        if colors is not None:\n",
        "            color_array = vtk.vtkUnsignedCharArray()\n",
        "            color_array.SetNumberOfComponents(3)\n",
        "            color_array.SetName(\"Colors\")\n",
        "            for color in colors:\n",
        "                color_array.InsertNextTuple3(int(color[0] * 255), int(color[1] * 255), int(color[2] * 255))\n",
        "            polydata.GetPointData().SetScalars(color_array)\n",
        "\n",
        "        decimate = vtk.vtkDecimatePro()\n",
        "        decimate.SetInputData(polydata)\n",
        "        decimate.SetTargetReduction(0.7)\n",
        "        decimate.Update()\n",
        "        reduced_polydata = decimate.GetOutput()\n",
        "        positions = np.array(reduced_polydata.GetPoints().GetData())\n",
        "        if colors is not None:\n",
        "            colors = colors[:len(positions)]\n",
        "        print(f\"Nuage de points rÃ©duit Ã  {len(positions)} points\")\n",
        "    return positions, colors\n",
        "\n",
        "# Ã‰tape 6 : Reconstruction de surface\n",
        "def reconstruct_surface(positions, colors=None):\n",
        "    pcd = o3d.geometry.PointCloud()\n",
        "    pcd.points = o3d.utility.Vector3dVector(positions)\n",
        "    if colors is not None:\n",
        "        pcd.colors = o3d.utility.Vector3dVector(colors)\n",
        "\n",
        "    pcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.1, max_nn=30))\n",
        "    mesh, _ = o3d.geometry.TriangleMesh.create_from_point_cloud_poisson(pcd, depth=8)\n",
        "    mesh.compute_vertex_normals()\n",
        "    return mesh\n",
        "\n",
        "# Ã‰tape 7 : Convertir le maillage open3d en trimesh\n",
        "def open3d_to_trimesh(open3d_mesh):\n",
        "    vertices = np.asarray(open3d_mesh.vertices)\n",
        "    faces = np.asarray(open3d_mesh.triangles)\n",
        "    vertex_colors = np.asarray(open3d_mesh.vertex_colors) if open3d_mesh.has_vertex_colors() else None\n",
        "    trimesh_mesh = trimesh.Trimesh(vertices=vertices, faces=faces, vertex_colors=vertex_colors)\n",
        "    return trimesh_mesh\n",
        "\n",
        "# Ã‰tape 8 : Appliquer une texture\n",
        "def apply_texture(mesh, image_np):\n",
        "    material = trimesh.visual.material.SimpleMaterial(image=Image.fromarray(image_np))\n",
        "    mesh.visual.material = material\n",
        "    return mesh\n",
        "\n",
        "# Ã‰tape 9 : Rendu photorÃ©aliste avec annotations\n",
        "def render_photorealistic(mesh, annotations, output_path=\"render.png\"):\n",
        "    scene = pyrender.Scene(ambient_light=[0.3, 0.3, 0.3])\n",
        "\n",
        "    # Convertir le maillage open3d en trimesh si nÃ©cessaire\n",
        "    if isinstance(mesh, o3d.geometry.TriangleMesh):\n",
        "        mesh = open3d_to_trimesh(mesh)\n",
        "\n",
        "    mesh_node = pyrender.Mesh.from_trimesh(mesh)\n",
        "    scene.add(mesh_node)\n",
        "\n",
        "    for anno in annotations:\n",
        "        if anno[\"type\"] == \"sphere\":\n",
        "            sphere = trimesh.creation.icosphere(radius=anno[\"radius\"])\n",
        "            sphere.visual.vertex_colors = anno[\"color\"]\n",
        "            sphere_node = pyrender.Mesh.from_trimesh(sphere, poses=np.array([\n",
        "                [1, 0, 0, anno[\"position\"][0]],\n",
        "                [0, 1, 0, anno[\"position\"][1]],\n",
        "                [0, 0, 1, anno[\"position\"][2]],\n",
        "                [0, 0, 0, 1]\n",
        "            ]))\n",
        "            scene.add(sphere_node)\n",
        "\n",
        "    camera = pyrender.PerspectiveCamera(yfov=np.pi / 3.0, aspectRatio=1.0)\n",
        "    camera_pose = np.array([\n",
        "        [1, 0, 0, 0],\n",
        "        [0, 1, 0, 0],\n",
        "        [0, 0, 1, 5],\n",
        "        [0, 0, 0, 1]\n",
        "    ])\n",
        "    scene.add(camera, pose=camera_pose)\n",
        "\n",
        "    scene.add(pyrender.DirectionalLight(color=np.ones(3), intensity=3.0), pose=camera_pose)\n",
        "    scene.add(pyrender.PointLight(color=np.ones(3), intensity=100.0), pose=np.array([\n",
        "        [1, 0, 0, 2],\n",
        "        [0, 1, 0, 2],\n",
        "        [0, 0, 1, 5],\n",
        "        [0, 0, 0, 1]\n",
        "    ]))\n",
        "\n",
        "    renderer = pyrender.OffscreenRenderer(viewport_width=640, viewport_height=480)\n",
        "    color, _ = renderer.render(scene)\n",
        "    cv2.imwrite(output_path, cv2.cvtColor(color, cv2.COLOR_RGB2BGR))\n",
        "    return output_path\n",
        "\n",
        "# Ã‰tape 10 : Pipeline principal\n",
        "def main():\n",
        "    print(\"Veuillez uploader une image (.jpg, .png) ou un fichier PLY\")\n",
        "    uploaded = files.upload()\n",
        "    file_path = list(uploaded.keys())[0]\n",
        "\n",
        "    positions, colors, annotations, image_np = None, None, [], None\n",
        "    if file_path.endswith((\".jpg\", \".png\")):\n",
        "        positions, colors, annotations, image_np = create_point_cloud_from_image(file_path)\n",
        "    elif file_path.endswith(\".ply\"):\n",
        "        positions, colors = load_ply(file_path)\n",
        "    else:\n",
        "        raise ValueError(\"Fichier non supportÃ© (doit Ãªtre .jpg, .png ou .ply)\")\n",
        "\n",
        "    print(f\"Nuage de points crÃ©Ã© : {len(positions)} points\")\n",
        "\n",
        "    positions, colors = decimate_point_cloud(positions, colors)\n",
        "\n",
        "    mesh = reconstruct_surface(positions, colors)\n",
        "    print(\"Reconstruction de surface terminÃ©e\")\n",
        "\n",
        "    if image_np is not None:\n",
        "        mesh = apply_texture(open3d_to_trimesh(mesh), image_np)\n",
        "        print(\"Texture appliquÃ©e\")\n",
        "\n",
        "    mesh_path = f\"output_mesh_{uuid.uuid4()}.ply\"\n",
        "    o3d.io.write_triangle_mesh(mesh_path, mesh)\n",
        "\n",
        "    render_path = f\"render_{uuid.uuid4()}.png\"\n",
        "    render_photorealistic(mesh, annotations, render_path)\n",
        "    print(\"Rendu photorÃ©aliste terminÃ©\")\n",
        "\n",
        "    img = cv2.imread(render_path)\n",
        "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    files.download(render_path)\n",
        "    print(f\"TÃ©lÃ©chargement initiÃ© pour {render_path}\")\n",
        "    files.download(mesh_path)\n",
        "    print(f\"TÃ©lÃ©chargement initiÃ© pour {mesh_path}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "N88OgSWoktMJ",
        "outputId": "5a9b07c4-1d12-49af-f875-25afadd33849"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: open3d in /usr/local/lib/python3.11/dist-packages (0.19.0)\n",
            "Requirement already satisfied: pyrender in /usr/local/lib/python3.11/dist-packages (0.1.45)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\n",
            "Requirement already satisfied: trimesh in /usr/local/lib/python3.11/dist-packages (4.7.1)\n",
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.11/dist-packages (8.3.169)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: vtk in /usr/local/lib/python3.11/dist-packages (9.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: dash>=2.6.0 in /usr/local/lib/python3.11/dist-packages (from open3d) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from open3d) (3.1.3)\n",
            "Requirement already satisfied: flask>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from open3d) (3.1.1)\n",
            "Requirement already satisfied: nbformat>=5.7.0 in /usr/local/lib/python3.11/dist-packages (from open3d) (5.10.4)\n",
            "Requirement already satisfied: configargparse in /usr/local/lib/python3.11/dist-packages (from open3d) (1.7.1)\n",
            "Requirement already satisfied: ipywidgets>=8.0.4 in /usr/local/lib/python3.11/dist-packages (from open3d) (8.1.7)\n",
            "Requirement already satisfied: addict in /usr/local/lib/python3.11/dist-packages (from open3d) (2.4.0)\n",
            "Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.11/dist-packages (from open3d) (2.2.2)\n",
            "Requirement already satisfied: pyyaml>=5.4.1 in /usr/local/lib/python3.11/dist-packages (from open3d) (6.0.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21 in /usr/local/lib/python3.11/dist-packages (from open3d) (1.6.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from open3d) (4.67.1)\n",
            "Requirement already satisfied: pyquaternion in /usr/local/lib/python3.11/dist-packages (from open3d) (0.9.9)\n",
            "Requirement already satisfied: freetype-py in /usr/local/lib/python3.11/dist-packages (from pyrender) (2.5.1)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.11/dist-packages (from pyrender) (2.37.0)\n",
            "Requirement already satisfied: pyglet>=1.4.10 in /usr/local/lib/python3.11/dist-packages (from pyrender) (2.1.6)\n",
            "Requirement already satisfied: PyOpenGL==3.1.0 in /usr/local/lib/python3.11/dist-packages (from pyrender) (3.1.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from pyrender) (1.15.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from pyrender) (1.17.0)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.14)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: plotly>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from dash>=2.6.0->open3d) (5.24.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from dash>=2.6.0->open3d) (8.7.0)\n",
            "Requirement already satisfied: retrying in /usr/local/lib/python3.11/dist-packages (from dash>=2.6.0->open3d) (1.4.1)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from dash>=2.6.0->open3d) (1.6.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from dash>=2.6.0->open3d) (75.2.0)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from flask>=3.0.0->open3d) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask>=3.0.0->open3d) (8.2.1)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from flask>=3.0.0->open3d) (2.2.0)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from flask>=3.0.0->open3d) (3.0.2)\n",
            "Requirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.0.4->open3d) (0.2.2)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.0.4->open3d) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.0.4->open3d) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=4.0.14 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.0.4->open3d) (4.0.14)\n",
            "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.0.4->open3d) (3.0.15)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.7.0->open3d) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.7.0->open3d) (4.24.1)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.7.0->open3d) (5.8.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0->open3d) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0->open3d) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.7.14)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21->open3d) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21->open3d) (3.6.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (3.0.51)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (4.9.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (0.26.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core!=5.0.*,>=4.12->nbformat>=5.7.0->open3d) (4.3.8)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly>=5.0.0->dash>=2.6.0->open3d) (8.5.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->dash>=2.6.0->open3d) (3.23.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.13)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/intel-isl_MiDaS_master\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading weights:  None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master\n",
            "Using cache found in /root/.cache/torch/hub/intel-isl_MiDaS_master\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ModÃ¨les MiDaS et YOLOv8 chargÃ©s avec succÃ¨s\n",
            "Veuillez uploader une image (.jpg, .png) ou un fichier PLY\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a9120f8f-f251-494a-8532-5b8baf1d5685\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a9120f8f-f251-494a-8532-5b8baf1d5685\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 20250722_130913.jpg to 20250722_130913 (1).jpg\n",
            "\n",
            "0: 480x640 (no detections), 15.7ms\n",
            "Speed: 2.5ms preprocess, 15.7ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "0 objets dÃ©tectÃ©s par YOLOv8\n",
            "Nuage de points crÃ©Ã© : 4800 points\n",
            "Reconstruction de surface terminÃ©e\n",
            "Texture appliquÃ©e\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "write_triangle_mesh(): incompatible function arguments. The following argument types are supported:\n    1. (filename: os.PathLike, mesh: open3d.cuda.pybind.geometry.TriangleMesh, write_ascii: bool = False, compressed: bool = False, write_vertex_normals: bool = True, write_vertex_colors: bool = True, write_triangle_uvs: bool = True, print_progress: bool = False) -> bool\n\nInvoked with: 'output_mesh_b3a146be-b0dc-4f20-aff5-dc65d3cf3cf5.ply', <trimesh.Trimesh(vertices.shape=(17853, 3), faces.shape=(35462, 3))>",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3-861546820.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-3-861546820.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0mmesh_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"output_mesh_{uuid.uuid4()}.ply\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m     \u001b[0mo3d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_triangle_mesh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmesh_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmesh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[0mrender_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"render_{uuid.uuid4()}.png\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: write_triangle_mesh(): incompatible function arguments. The following argument types are supported:\n    1. (filename: os.PathLike, mesh: open3d.cuda.pybind.geometry.TriangleMesh, write_ascii: bool = False, compressed: bool = False, write_vertex_normals: bool = True, write_vertex_colors: bool = True, write_triangle_uvs: bool = True, print_progress: bool = False) -> bool\n\nInvoked with: 'output_mesh_b3a146be-b0dc-4f20-aff5-dc65d3cf3cf5.ply', <trimesh.Trimesh(vertices.shape=(17853, 3), faces.shape=(35462, 3))>"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4c3da33fd4e74c8582363fba0f5645ea": {
          "model_module": "jupyter-threejs",
          "model_name": "RendererModel",
          "model_module_version": "^2.4.1",
          "state": {
            "_alpha": false,
            "_antialias": false,
            "_dom_classes": [],
            "_height": 600,
            "_model_module": "jupyter-threejs",
            "_model_module_version": "^2.4.1",
            "_model_name": "RendererModel",
            "_pause_autorender": false,
            "_view_count": null,
            "_view_module": "jupyter-threejs",
            "_view_module_version": "^2.4.1",
            "_view_name": "RendererView",
            "_webgl_version": 2,
            "_width": 800,
            "autoClear": true,
            "autoClearColor": true,
            "autoClearDepth": true,
            "autoClearStencil": true,
            "background": "black",
            "background_opacity": 1,
            "camera": "IPY_MODEL_153a949dbee24b3585f6c5a162037a1a",
            "clearColor": "#000000",
            "clearOpacity": 1,
            "clippingPlanes": [],
            "controls": [
              "IPY_MODEL_b5f30a4c765b47e6a1719ccfcd387140"
            ],
            "gammaFactor": 2,
            "gammaInput": false,
            "gammaOutput": false,
            "layout": "IPY_MODEL_bef044e26b3c4d74a82f348a37bcf794",
            "localClippingEnabled": false,
            "maxMorphNormals": 4,
            "maxMorphTargets": 8,
            "physicallyCorrectLights": false,
            "scene": "IPY_MODEL_5cde742aae624c1eac996780b1ed6400",
            "shadowMap": "IPY_MODEL_cad86166e7bf4ddfbdf0dc567a817dfa",
            "sortObject": true,
            "tabbable": null,
            "toneMapping": "LinearToneMapping",
            "toneMappingExposure": 1,
            "toneMappingWhitePoint": 1,
            "tooltip": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}