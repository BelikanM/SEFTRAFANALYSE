{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 908
        },
        "id": "3bhD25UQgUlp",
        "outputId": "9fde9892-f829-4ed6-f507-311024013c1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:6 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 36 not upgraded.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/intel-isl_MiDaS_master\n",
            "/usr/local/lib/python3.11/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LOG] Transformation utilisée : Compose(\n",
            "    <function transforms.<locals>.<lambda> at 0x7af1bcec9d00>\n",
            "    <midas.transforms.Resize object at 0x7af1a0a38150>\n",
            "    <midas.transforms.NormalizeImage object at 0x7af1a0a384d0>\n",
            "    <midas.transforms.PrepareForNet object at 0x7af1a0a3bdd0>\n",
            "    <function transforms.<locals>.<lambda> at 0x7af1bcec9da0>\n",
            ")\n",
            "⬆️ Téléversez votre image (PNG, JPG, etc.)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/intel-isl_MiDaS_master\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e56dc1f7-384a-4e0c-b6c8-38ae2b9da3b1\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e56dc1f7-384a-4e0c-b6c8-38ae2b9da3b1\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving IMG-20250226-WA0015.jpg to IMG-20250226-WA0015.jpg\n",
            "[LOG] Image - Dimensions : (765, 1020, 3), Type : uint8\n",
            "[LOG] Image brute sauvegardée : output_frames/raw_image.png\n",
            "[LOG] Dimensions tenseur : torch.Size([1, 3, 384, 512]), Type : torch.float32, Valeurs min/max : -1.09/1.04\n",
            "[LOG] Forme avant inférence : torch.Size([1, 3, 384, 512])\n",
            "[LOG] Stats profondeur : min=9.87, max=35.34, mean=21.46\n",
            "[LOG] Carte de profondeur sauvegardée : output_frames/depth_image.png\n",
            "[LOG] 12288 points ajoutés\n",
            "[LOG] Forme des points : (12288, 3), Forme des couleurs : (12288, 3)\n",
            "[LOG] Affichage du nuage de points...\n",
            "\u001b[1;33m[Open3D WARNING] GLFW Error: Failed to detect any supported platform\u001b[0;m\n",
            "\u001b[1;33m[Open3D WARNING] GLFW initialized for headless rendering.\u001b[0;m\n",
            "\u001b[1;33m[Open3D WARNING] GLFW Error: OSMesa: Library not found\u001b[0;m\n",
            "\u001b[1;33m[Open3D WARNING] Failed to create window\u001b[0;m\n",
            "\u001b[1;33m[Open3D WARNING] [DrawGeometries] Failed creating OpenGL window.\u001b[0;m\n",
            "[LOG] ✅ Nuage de points exporté vers 'scene3d.ply'\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_fa3acc9c-76e2-41ee-80e5-fca19e902f89\", \"scene3d.ply\", 331984)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LOG] ✅ Processus terminé\n"
          ]
        }
      ],
      "source": [
        "# INSTALLATION\n",
        "!pip install -q opencv-python matplotlib timm torch torchvision open3d\n",
        "!apt-get update && apt-get install -y ffmpeg\n",
        "\n",
        "# IMPORTS\n",
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "import open3d as o3d\n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Fixer les graines pour la reproductibilité\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# CHARGEMENT DU MODÈLE MiDaS\n",
        "model_type = \"DPT_Large\"  # Options : DPT_Large, DPT_Hybrid, MiDaS_small\n",
        "try:\n",
        "    midas = torch.hub.load(\"intel-isl/MiDaS\", model_type, trust_repo=True)\n",
        "    midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\", trust_repo=True)\n",
        "except Exception as e:\n",
        "    raise RuntimeError(f\"Échec du chargement du modèle MiDaS : {e}\")\n",
        "\n",
        "# Configurer le dispositif\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "midas.to(device)\n",
        "midas.eval()\n",
        "\n",
        "# Sélectionner la transformation appropriée\n",
        "transform = midas_transforms.dpt_transform if model_type.startswith(\"DPT\") else midas_transforms.small_transform\n",
        "print(f\"[LOG] Transformation utilisée : {transform}\")\n",
        "\n",
        "# Créer le dossier de sortie\n",
        "os.makedirs(\"output_frames\", exist_ok=True)\n",
        "\n",
        "# Téléverser l'image\n",
        "print(\"⬆️ Téléversez votre image (PNG, JPG, etc.)\")\n",
        "try:\n",
        "    uploaded = files.upload()\n",
        "    image_path = next(iter(uploaded))\n",
        "except Exception as e:\n",
        "    raise RuntimeError(f\"Échec du téléversement de l'image : {e}\")\n",
        "\n",
        "# Charger et convertir l'image en RGB\n",
        "img_rgb = cv2.imread(image_path)\n",
        "if img_rgb is None:\n",
        "    raise RuntimeError(f\"Impossible de charger l'image : {image_path}\")\n",
        "img_rgb = cv2.cvtColor(img_rgb, cv2.COLOR_BGR2RGB)\n",
        "print(f\"[LOG] Image - Dimensions : {img_rgb.shape}, Type : {img_rgb.dtype}\")\n",
        "\n",
        "# Vérifier les canaux\n",
        "if img_rgb.shape[2] != 3:\n",
        "    raise ValueError(f\"L'image doit avoir 3 canaux (RGB), {img_rgb.shape[2]} détectés\")\n",
        "\n",
        "# Sauvegarder l'image brute pour inspection\n",
        "plt.imsave(\"output_frames/raw_image.png\", img_rgb)\n",
        "print(f\"[LOG] Image brute sauvegardée : output_frames/raw_image.png\")\n",
        "\n",
        "# Appliquer la transformation MiDaS\n",
        "try:\n",
        "    input_tensor = transform(img_rgb).to(device)\n",
        "    print(f\"[LOG] Dimensions tenseur : {input_tensor.shape}, Type : {input_tensor.dtype}, Valeurs min/max : {input_tensor.min():.2f}/{input_tensor.max():.2f}\")\n",
        "    if input_tensor.shape[1] != 3:  # Vérifier la dimension des canaux\n",
        "        raise ValueError(f\"Le tenseur d'entrée doit avoir 3 canaux, {input_tensor.shape[1]} détectés\")\n",
        "except Exception as e:\n",
        "    raise RuntimeError(f\"Erreur lors de la transformation : {e}\")\n",
        "\n",
        "# Vérifier la forme avant inférence\n",
        "print(f\"[LOG] Forme avant inférence : {input_tensor.shape}\")\n",
        "\n",
        "# Prédire la profondeur\n",
        "with torch.no_grad():\n",
        "    prediction = midas(input_tensor)\n",
        "    prediction = torch.nn.functional.interpolate(\n",
        "        prediction.unsqueeze(1),\n",
        "        size=img_rgb.shape[:2],\n",
        "        mode=\"bicubic\",\n",
        "        align_corners=False,\n",
        "    ).squeeze()\n",
        "\n",
        "depth = prediction.cpu().numpy()\n",
        "print(f\"[LOG] Stats profondeur : min={depth.min():.2f}, max={depth.max():.2f}, mean={depth.mean():.2f}\")\n",
        "\n",
        "# Sauvegarder la carte de profondeur\n",
        "plt.imsave(\"output_frames/depth_image.png\", depth, cmap='inferno')\n",
        "print(f\"[LOG] Carte de profondeur sauvegardée : output_frames/depth_image.png\")\n",
        "\n",
        "# Paramètres de la caméra\n",
        "fx, fy = 500, 500  # Longueurs focales\n",
        "h, w = depth.shape\n",
        "cx, cy = w / 2, h / 2\n",
        "\n",
        "# Normaliser la profondeur\n",
        "depth = np.clip(depth, 0.1, 100)\n",
        "\n",
        "# Générer le nuage de points\n",
        "all_points = []\n",
        "all_colors = []\n",
        "stride = 8\n",
        "points_count = 0\n",
        "for y in range(0, h, stride):\n",
        "    for x in range(0, w, stride):\n",
        "        z = depth[y, x]\n",
        "        if np.isnan(z) or np.isinf(z):\n",
        "            continue\n",
        "        X = (x - cx) * z / fx\n",
        "        Y = (y - cy) * z / fy\n",
        "        if np.any(np.isnan([X, Y, z])) or np.any(np.isinf([X, Y, z])):\n",
        "            continue\n",
        "        all_points.append([X, -Y, -z])\n",
        "        all_colors.append(img_rgb[y, x] / 255.0)\n",
        "        points_count += 1\n",
        "print(f\"[LOG] {points_count} points ajoutés\")\n",
        "\n",
        "# Vérifier si des points ont été générés\n",
        "if not all_points:\n",
        "    print(\"[LOG] Erreur : Aucun point valide généré. Vérifiez l'image brute et la carte de profondeur dans 'output_frames/'\")\n",
        "    raise RuntimeError(\"Aucun point valide généré pour le nuage de points.\")\n",
        "\n",
        "# Créer le nuage de points Open3D\n",
        "try:\n",
        "    pcd = o3d.geometry.PointCloud()\n",
        "    points_array = np.array(all_points, dtype=np.float64)\n",
        "    colors_array = np.array(all_colors, dtype=np.float64)\n",
        "    print(f\"[LOG] Forme des points : {points_array.shape}, Forme des couleurs : {colors_array.shape}\")\n",
        "    if points_array.shape[1] != 3 or colors_array.shape[1] != 3:\n",
        "        raise ValueError(f\"Forme incorrecte : points {points_array.shape}, couleurs {colors_array.shape}\")\n",
        "    pcd.points = o3d.utility.Vector3dVector(points_array)\n",
        "    pcd.colors = o3d.utility.Vector3dVector(colors_array)\n",
        "except Exception as e:\n",
        "    print(f\"[LOG] Erreur lors de la création du nuage de points : {e}\")\n",
        "    raise RuntimeError(f\"Échec de la création du nuage de points : {e}\")\n",
        "\n",
        "# Visualiser le nuage de points\n",
        "print(\"[LOG] Affichage du nuage de points...\")\n",
        "try:\n",
        "    o3d.visualization.draw_geometries([pcd])\n",
        "except Exception as e:\n",
        "    print(f\"[LOG] Avertissement : Échec de la visualisation : {e}\")\n",
        "\n",
        "# Exporter le nuage de points\n",
        "output_path = \"scene3d.ply\"\n",
        "try:\n",
        "    o3d.io.write_point_cloud(output_path, pcd)\n",
        "    print(f\"[LOG] ✅ Nuage de points exporté vers '{output_path}'\")\n",
        "except Exception as e:\n",
        "    print(f\"[LOG] Erreur lors de l'exportation : {e}\")\n",
        "    raise RuntimeError(f\"Échec de l'exportation du nuage de points : {e}\")\n",
        "\n",
        "# Télécharger le fichier\n",
        "try:\n",
        "    files.download(output_path)\n",
        "except Exception as e:\n",
        "    print(f\"[LOG] Avertissement : Échec du téléchargement : {e}\")\n",
        "\n",
        "# Nettoyage\n",
        "del midas\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "print(\"[LOG] ✅ Processus terminé\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2QyNaxedrGdo"
      },
      "outputs": [],
      "source": [
        "# 📦 INSTALLATION\n",
        "!pip install -q opencv-python matplotlib timm torch torchvision open3d\n",
        "!apt-get update && apt-get install -y ffmpeg\n",
        "\n",
        "# 📚 IMPORTS\n",
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "import open3d as o3d\n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ⚙️ SETUP\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_type = \"DPT_Large\"\n",
        "\n",
        "# 🧠 CHARGEMENT MODÈLE\n",
        "midas = torch.hub.load(\"intel-isl/MiDaS\", model_type, trust_repo=True)\n",
        "midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\", trust_repo=True)\n",
        "midas.to(device).eval()\n",
        "transform = midas_transforms.dpt_transform if model_type.startswith(\"DPT\") else midas_transforms.small_transform\n",
        "\n",
        "# 📁 OUTPUT\n",
        "os.makedirs(\"output_frames\", exist_ok=True)\n",
        "\n",
        "# 📤 CHOIX IMAGE OU VIDÉO\n",
        "print(\"⬆️ Téléversez une image OU une vidéo (.jpg, .png, .mp4)\")\n",
        "uploaded = files.upload()\n",
        "file_path = next(iter(uploaded))\n",
        "is_video = file_path.lower().endswith(\".mp4\")\n",
        "\n",
        "def estimate_depth(img_rgb):\n",
        "    input_tensor = transform(img_rgb).to(device)\n",
        "    with torch.no_grad():\n",
        "        prediction = midas(input_tensor)\n",
        "        prediction = torch.nn.functional.interpolate(\n",
        "            prediction.unsqueeze(1),\n",
        "            size=img_rgb.shape[:2],\n",
        "            mode=\"bicubic\",\n",
        "            align_corners=False,\n",
        "        ).squeeze()\n",
        "    return prediction.cpu().numpy()\n",
        "\n",
        "# 🎯 FONCTION NUAGE DE POINTS\n",
        "def image_to_pointcloud(img_rgb, depth, fx=500, fy=500, stride=8):\n",
        "    h, w = depth.shape\n",
        "    cx, cy = w / 2, h / 2\n",
        "    depth = np.clip(depth, 0.1, 100)\n",
        "    all_points, all_colors = [], []\n",
        "    for y in range(0, h, stride):\n",
        "        for x in range(0, w, stride):\n",
        "            z = depth[y, x]\n",
        "            if np.isnan(z) or np.isinf(z): continue\n",
        "            X = (x - cx) * z / fx\n",
        "            Y = (y - cy) * z / fy\n",
        "            if np.any(np.isnan([X, Y, z])): continue\n",
        "            all_points.append([X, -Y, -z])\n",
        "            all_colors.append(img_rgb[y, x] / 255.0)\n",
        "    return np.array(all_points), np.array(all_colors)\n",
        "\n",
        "# 📸 TRAITEMENT IMAGE UNIQUE\n",
        "if not is_video:\n",
        "    img = cv2.imread(file_path)\n",
        "    if img is None: raise RuntimeError(\"Erreur de chargement de l'image\")\n",
        "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    depth = estimate_depth(img_rgb)\n",
        "    pts, colors = image_to_pointcloud(img_rgb, depth)\n",
        "    print(f\"[LOG] Image : {pts.shape[0]} points générés\")\n",
        "else:\n",
        "    # 🎞️ TRAITEMENT VIDÉO\n",
        "    cap = cv2.VideoCapture(file_path)\n",
        "    stride, skip = 8, 10\n",
        "    fx = fy = 500\n",
        "    all_points, all_colors = [], []\n",
        "    frame_idx, processed = 0, 0\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret: break\n",
        "        if frame_idx % skip != 0:\n",
        "            frame_idx += 1\n",
        "            continue\n",
        "        img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        depth = estimate_depth(img_rgb)\n",
        "        pts, colors = image_to_pointcloud(img_rgb, depth, fx, fy, stride)\n",
        "        all_points.append(pts)\n",
        "        all_colors.append(colors)\n",
        "        print(f\"[LOG] Frame {frame_idx} → {pts.shape[0]} points\")\n",
        "        frame_idx += 1\n",
        "        processed += 1\n",
        "    cap.release()\n",
        "    if not all_points:\n",
        "        raise RuntimeError(\"Aucun point généré à partir de la vidéo.\")\n",
        "    pts = np.concatenate(all_points, axis=0)\n",
        "    colors = np.concatenate(all_colors, axis=0)\n",
        "    print(f\"[LOG] Vidéo : {pts.shape[0]} points cumulés depuis {processed} frames\")\n",
        "\n",
        "# 💾 CRÉATION NUAGE DE POINTS\n",
        "pcd = o3d.geometry.PointCloud()\n",
        "pcd.points = o3d.utility.Vector3dVector(pts)\n",
        "pcd.colors = o3d.utility.Vector3dVector(colors)\n",
        "\n",
        "# 👁️ AFFICHAGE\n",
        "try:\n",
        "    o3d.visualization.draw_geometries([pcd])\n",
        "except Exception as e:\n",
        "    print(f\"[LOG] Avertissement : visualisation non supportée ici : {e}\")\n",
        "\n",
        "# 💽 EXPORT\n",
        "output_path = \"scene3d.ply\"\n",
        "o3d.io.write_point_cloud(output_path, pcd)\n",
        "print(f\"[LOG] ✅ Fichier exporté : {output_path}\")\n",
        "\n",
        "# 📥 TÉLÉCHARGEMENT\n",
        "try:\n",
        "    files.download(output_path)\n",
        "except Exception as e:\n",
        "    print(f\"[LOG] ⚠️ Échec du téléchargement : {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oadgw2zVNp0T",
        "outputId": "ff47fc29-6a82-41ef-9c60-1a674ee48815"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m76.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m858.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.7/447.7 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m78.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m65.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fr-core-news-md==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_md-3.8.0/fr_core_news_md-3.8.0-py3-none-any.whl (45.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fr-core-news-md\n",
            "Successfully installed fr-core-news-md-3.8.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('fr_core_news_md')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:3 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,840 kB]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:10 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,764 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:13 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,124 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,461 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,148 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [5,139 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,572 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [4,932 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,267 kB]\n",
            "Fetched 33.6 MB in 4s (8,263 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "zip is already the newest version (3.0-12build2).\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 36 not upgraded.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/intel-isl/MiDaS/zipball/master\" to /root/.cache/torch/hub/master.zip\n",
            "/usr/local/lib/python3.11/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
            "Downloading: \"https://github.com/isl-org/MiDaS/releases/download/v3/dpt_large_384.pt\" to /root/.cache/torch/hub/checkpoints/dpt_large_384.pt\n",
            "100%|██████████| 1.28G/1.28G [00:20<00:00, 65.6MB/s]\n",
            "Using cache found in /root/.cache/torch/hub/intel-isl_MiDaS_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⬆️ Téléversez une image (.jpg/.png) ou une vidéo (.mp4)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8c0b4eaf-5a7c-4b95-af4d-2f8838229643\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8c0b4eaf-5a7c-4b95-af4d-2f8838229643\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving output_62079.mp4 to output_62079.mp4\n",
            "[LOG] Frame 0 : 5632 points → video_frames_3d/frame_0000.ply\n",
            "[Analyse NLP] → usé\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 128202 (\\N{BAR CHART}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 600x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LOG] Frame 10 : 5632 points → video_frames_3d/frame_0010.ply\n",
            "[Analyse NLP] → usé\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 600x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LOG] Frame 20 : 5632 points → video_frames_3d/frame_0020.ply\n",
            "[Analyse NLP] → usé\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 600x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LOG] Frame 30 : 5632 points → video_frames_3d/frame_0030.ply\n",
            "[Analyse NLP] → usé\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 600x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LOG] Frame 40 : 5632 points → video_frames_3d/frame_0040.ply\n",
            "[Analyse NLP] → usé\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 600x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LOG] Frame 50 : 5632 points → video_frames_3d/frame_0050.ply\n",
            "[Analyse NLP] → usé\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 600x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LOG] ✅ 6 frames traitées et analysées\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_ff4b9986-51be-46c4-be1e-46b3b63670d2\", \"video_frames_3d.zip\", 914464)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 📦 INSTALLATION\n",
        "!pip install -q opencv-python matplotlib timm torch torchvision open3d spacy\n",
        "!python -m spacy download fr_core_news_md\n",
        "!apt-get update && apt-get install -y ffmpeg zip\n",
        "\n",
        "# 📚 IMPORTS\n",
        "import os\n",
        "import cv2\n",
        "import zipfile\n",
        "import torch\n",
        "import numpy as np\n",
        "import open3d as o3d\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "import spacy\n",
        "import random\n",
        "\n",
        "# ⚙️ SETUP\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_type = \"DPT_Large\"\n",
        "\n",
        "# 🧠 CHARGEMENT MODÈLE DE PROFONDEUR\n",
        "midas = torch.hub.load(\"intel-isl/MiDaS\", model_type, trust_repo=True)\n",
        "midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\", trust_repo=True)\n",
        "midas.to(device).eval()\n",
        "transform = midas_transforms.dpt_transform if model_type.startswith(\"DPT\") else midas_transforms.small_transform\n",
        "\n",
        "# 🧠 CHARGEMENT SPAcY POUR ANALYSE\n",
        "nlp = spacy.load(\"fr_core_news_md\")\n",
        "\n",
        "# 📤 TÉLÉVERSEMENT\n",
        "print(\"⬆️ Téléversez une image (.jpg/.png) ou une vidéo (.mp4)\")\n",
        "uploaded = files.upload()\n",
        "file_path = next(iter(uploaded))\n",
        "is_video = file_path.lower().endswith(\".mp4\")\n",
        "\n",
        "# 📁 DOSSIERS OUTPUT\n",
        "os.makedirs(\"output_frames\", exist_ok=True)\n",
        "os.makedirs(\"video_frames_3d\", exist_ok=True)\n",
        "os.makedirs(\"depth_maps\", exist_ok=True)\n",
        "\n",
        "# 🧠 ESTIMATION DE PROFONDEUR\n",
        "def estimate_depth(img_rgb):\n",
        "    input_tensor = transform(img_rgb).to(device)\n",
        "    with torch.no_grad():\n",
        "        prediction = midas(input_tensor)\n",
        "        prediction = torch.nn.functional.interpolate(\n",
        "            prediction.unsqueeze(1),\n",
        "            size=img_rgb.shape[:2],\n",
        "            mode=\"bicubic\",\n",
        "            align_corners=False,\n",
        "        ).squeeze()\n",
        "    return prediction.cpu().numpy()\n",
        "\n",
        "# 🎯 CONVERSION EN NUAGE DE POINTS\n",
        "def image_to_pointcloud(img_rgb, depth, fx=500, fy=500, stride=8):\n",
        "    h, w = depth.shape\n",
        "    cx, cy = w / 2, h / 2\n",
        "    depth = np.clip(depth, 0.1, 100)\n",
        "    all_points, all_colors = [], []\n",
        "    for y in range(0, h, stride):\n",
        "        for x in range(0, w, stride):\n",
        "            z = depth[y, x]\n",
        "            if np.isnan(z) or np.isinf(z): continue\n",
        "            X = (x - cx) * z / fx\n",
        "            Y = (y - cy) * z / fy\n",
        "            if np.any(np.isnan([X, Y, z])): continue\n",
        "            all_points.append([X, -Y, -z])\n",
        "            all_colors.append(img_rgb[y, x] / 255.0)\n",
        "    return np.array(all_points), np.array(all_colors)\n",
        "\n",
        "# 🧠 ANALYSE PAR spaCy + Modèle ML fictif\n",
        "def analyze_pointcloud_stats(pts):\n",
        "    mean_height = np.mean(pts[:, 1])\n",
        "    max_depth = np.max(pts[:, 2])\n",
        "    spread = np.std(pts[:, 0])\n",
        "    keywords = []\n",
        "\n",
        "    # Prédictions simulées (à remplacer par vrai modèle ML si dispo)\n",
        "    if max_depth > 10: keywords.append(\"dangereux\")\n",
        "    if mean_height < -1: keywords.append(\"abîmé\")\n",
        "    if spread > 5: keywords.append(\"usé\")\n",
        "    if len(keywords) == 0: keywords.append(\"neuf\")\n",
        "\n",
        "    # NLP spaCy enrichi\n",
        "    doc = nlp(\" \".join(keywords))\n",
        "    print(f\"[Analyse NLP] → {' | '.join([ent.text for ent in doc])}\")\n",
        "\n",
        "    # Visualisation simple\n",
        "    plt.figure(figsize=(6, 3))\n",
        "    plt.bar([\"Hauteur\", \"Profondeur\", \"Dispersion\"], [abs(mean_height), abs(max_depth), spread], color='skyblue')\n",
        "    plt.title(\"📊 Analyse structurelle\")\n",
        "    plt.show()\n",
        "\n",
        "    return keywords\n",
        "\n",
        "# 🎞️ TRAITEMENT VIDÉO OU IMAGE\n",
        "if is_video:\n",
        "    cap = cv2.VideoCapture(file_path)\n",
        "    stride, skip = 8, 10\n",
        "    fx = fy = 500\n",
        "    frame_idx, processed = 0, 0\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        if frame_idx % skip != 0:\n",
        "            frame_idx += 1\n",
        "            continue\n",
        "\n",
        "        img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        depth = estimate_depth(img_rgb)\n",
        "\n",
        "        # Sauvegarde de la carte de profondeur\n",
        "        plt.imsave(f\"depth_maps/depth_{frame_idx:04d}.png\", depth, cmap=\"inferno\")\n",
        "\n",
        "        pts, colors = image_to_pointcloud(img_rgb, depth, fx, fy, stride)\n",
        "        if pts.shape[0] == 0:\n",
        "            frame_idx += 1\n",
        "            continue\n",
        "\n",
        "        pcd = o3d.geometry.PointCloud()\n",
        "        pcd.points = o3d.utility.Vector3dVector(pts)\n",
        "        pcd.colors = o3d.utility.Vector3dVector(colors)\n",
        "\n",
        "        path = f\"video_frames_3d/frame_{frame_idx:04d}.ply\"\n",
        "        o3d.io.write_point_cloud(path, pcd)\n",
        "        print(f\"[LOG] Frame {frame_idx} : {pts.shape[0]} points → {path}\")\n",
        "\n",
        "        analyze_pointcloud_stats(pts)\n",
        "        frame_idx += 1\n",
        "        processed += 1\n",
        "\n",
        "    cap.release()\n",
        "    print(f\"[LOG] ✅ {processed} frames traitées et analysées\")\n",
        "\n",
        "    # Création d’un ZIP\n",
        "    zip_name = \"video_frames_3d.zip\"\n",
        "    with zipfile.ZipFile(zip_name, 'w') as zipf:\n",
        "        for root, _, files_ in os.walk(\"video_frames_3d\"):\n",
        "            for file in files_:\n",
        "                zipf.write(os.path.join(root, file))\n",
        "    files.download(zip_name)\n",
        "\n",
        "else:\n",
        "    # 📸 TRAITEMENT IMAGE UNIQUE\n",
        "    img = cv2.imread(file_path)\n",
        "    if img is None:\n",
        "        raise RuntimeError(\"Erreur de chargement de l'image\")\n",
        "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    depth = estimate_depth(img_rgb)\n",
        "    plt.imsave(\"depth_maps/depth_image.png\", depth, cmap=\"inferno\")\n",
        "\n",
        "    pts, colors = image_to_pointcloud(img_rgb, depth)\n",
        "    pcd = o3d.geometry.PointCloud()\n",
        "    pcd.points = o3d.utility.Vector3dVector(pts)\n",
        "    pcd.colors = o3d.utility.Vector3dVector(colors)\n",
        "\n",
        "    output_path = \"output_frames/scene3d.ply\"\n",
        "    o3d.io.write_point_cloud(output_path, pcd)\n",
        "    print(f\"[LOG] ✅ Image → {pts.shape[0]} points exportés\")\n",
        "\n",
        "    analyze_pointcloud_stats(pts)\n",
        "    files.download(output_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Wylvp5S3qm45",
        "outputId": "9c7a8049-9b8e-4a83-d7ac-d1f063c62991"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting open3d\n",
            "  Downloading open3d-0.19.0-cp311-cp311-manylinux_2_31_x86_64.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.31.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.11/dist-packages (from open3d) (2.0.2)\n",
            "Collecting dash>=2.6.0 (from open3d)\n",
            "  Downloading dash-3.1.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: werkzeug>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from open3d) (3.1.3)\n",
            "Requirement already satisfied: flask>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from open3d) (3.1.1)\n",
            "Requirement already satisfied: nbformat>=5.7.0 in /usr/local/lib/python3.11/dist-packages (from open3d) (5.10.4)\n",
            "Collecting configargparse (from open3d)\n",
            "  Downloading configargparse-1.7.1-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting ipywidgets>=8.0.4 (from open3d)\n",
            "  Downloading ipywidgets-8.1.7-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting addict (from open3d)\n",
            "  Downloading addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: pillow>=9.3.0 in /usr/local/lib/python3.11/dist-packages (from open3d) (11.2.1)\n",
            "Requirement already satisfied: matplotlib>=3 in /usr/local/lib/python3.11/dist-packages (from open3d) (3.10.0)\n",
            "Requirement already satisfied: pyyaml>=5.4.1 in /usr/local/lib/python3.11/dist-packages (from open3d) (6.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from open3d) (4.67.1)\n",
            "Collecting pyquaternion (from open3d)\n",
            "  Downloading pyquaternion-0.9.9-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.116.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.6.0)\n",
            "Requirement already satisfied: gradio-client==1.10.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.10.1)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.33.4)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.11.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.7)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.12.3)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.47.1)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.14.1)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.35.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (15.0.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.73.1)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: plotly>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from dash>=2.6.0->open3d) (5.24.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from dash>=2.6.0->open3d) (8.7.0)\n",
            "Collecting retrying (from dash>=2.6.0->open3d)\n",
            "  Downloading retrying-1.4.1-py3-none-any.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from dash>=2.6.0->open3d) (1.6.0)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from flask>=3.0.0->open3d) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask>=3.0.0->open3d) (8.2.1)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from flask>=3.0.0->open3d) (2.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (1.1.5)\n",
            "Collecting comm>=0.1.3 (from ipywidgets>=8.0.4->open3d)\n",
            "  Downloading comm-0.2.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.0.4->open3d) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.0.4->open3d) (5.7.1)\n",
            "Collecting widgetsnbextension~=4.0.14 (from ipywidgets>=8.0.4->open3d)\n",
            "  Downloading widgetsnbextension-4.0.14-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.0.4->open3d) (3.0.15)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3->open3d) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3->open3d) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3->open3d) (4.58.5)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3->open3d) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3->open3d) (3.2.3)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.7.0->open3d) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.7.0->open3d) (4.24.0)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.7.0->open3d) (5.8.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Collecting jedi>=0.16 (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (3.0.51)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (4.9.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (0.26.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core!=5.0.*,>=4.12->nbformat>=5.7.0->open3d) (4.3.8)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly>=5.0.0->dash>=2.6.0->open3d) (8.5.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->dash>=2.6.0->open3d) (3.23.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.8.4)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.13)\n",
            "Downloading open3d-0.19.0-cp311-cp311-manylinux_2_31_x86_64.whl (447.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.7/447.7 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dash-3.1.1-py3-none-any.whl (7.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ipywidgets-8.1.7-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Downloading configargparse-1.7.1-py3-none-any.whl (25 kB)\n",
            "Downloading pyquaternion-0.9.9-py3-none-any.whl (14 kB)\n",
            "Downloading comm-0.2.2-py3-none-any.whl (7.2 kB)\n",
            "Downloading widgetsnbextension-4.0.14-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading retrying-1.4.1-py3-none-any.whl (12 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: addict, widgetsnbextension, retrying, pyquaternion, jedi, configargparse, comm, ipywidgets, dash, open3d\n",
            "  Attempting uninstall: widgetsnbextension\n",
            "    Found existing installation: widgetsnbextension 3.6.10\n",
            "    Uninstalling widgetsnbextension-3.6.10:\n",
            "      Successfully uninstalled widgetsnbextension-3.6.10\n",
            "  Attempting uninstall: ipywidgets\n",
            "    Found existing installation: ipywidgets 7.7.1\n",
            "    Uninstalling ipywidgets-7.7.1:\n",
            "      Successfully uninstalled ipywidgets-7.7.1\n",
            "Successfully installed addict-2.4.0 comm-0.2.2 configargparse-1.7.1 dash-3.1.1 ipywidgets-8.1.7 jedi-0.19.2 open3d-0.19.0 pyquaternion-0.9.9 retrying-1.4.1 widgetsnbextension-4.0.14\n",
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://3a0394de9eaa733e19.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://3a0394de9eaa733e19.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 📌 NOM : topo_ai_trainer.ipynb\n",
        "# Utilise TensorFlow + open3d + Gradio pour IA topographique\n",
        "\n",
        "!pip install open3d gradio tensorflow scikit-learn pandas\n",
        "\n",
        "import open3d as o3d\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import gradio as gr\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# 📥 Chargement d'un nuage de points\n",
        "def load_point_cloud(file):\n",
        "    pcd = o3d.io.read_point_cloud(file.name)\n",
        "    return np.asarray(pcd.points)\n",
        "\n",
        "# 🧠 Création d'un modèle simple pour classifier le terrain\n",
        "def create_model(input_dim):\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(64, activation='relu', input_shape=(input_dim,)),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(4, activation='softmax')  # 4 classes: plat, pente, sommet, cuvette\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# 📊 Exemple de génération de données topographiques fictives\n",
        "def generate_fake_data(points):\n",
        "    X = points[:, :3]  # x, y, z\n",
        "    y = []\n",
        "    for pt in X:\n",
        "        if pt[2] < 0.2:\n",
        "            y.append([1,0,0,0])  # plat\n",
        "        elif pt[2] < 0.5:\n",
        "            y.append([0,1,0,0])  # pente\n",
        "        elif pt[2] < 0.8:\n",
        "            y.append([0,0,1,0])  # sommet\n",
        "        else:\n",
        "            y.append([0,0,0,1])  # cuvette\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# 🔁 Entraînement\n",
        "def train_model(file):\n",
        "    points = load_point_cloud(file)\n",
        "    X, y = generate_fake_data(points)\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2)\n",
        "    model = create_model(X_train.shape[1])\n",
        "    model.fit(X_train, y_train, epochs=10, batch_size=16)\n",
        "    acc = model.evaluate(X_test, y_test)[1]\n",
        "    return f\"Modèle entraîné avec {acc*100:.2f}% de précision.\"\n",
        "\n",
        "# 🧪 Interface Gradio\n",
        "iface = gr.Interface(\n",
        "    fn=train_model,\n",
        "    inputs=gr.File(label=\"Charger un fichier .ply\"),\n",
        "    outputs=\"text\",\n",
        "    title=\"Entraînement IA Topographique\"\n",
        ")\n",
        "\n",
        "iface.launch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nPVfYE2QO7Te",
        "outputId": "1ad88aff-db83-44de-ca86-e3a9eb0f76fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m75.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.7/447.7 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,840 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:12 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,128 kB]\n",
            "Get:13 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,267 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,572 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [4,932 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,461 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,148 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [5,139 kB]\n",
            "Get:19 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,764 kB]\n",
            "Fetched 33.6 MB in 4s (9,554 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 36 not upgraded.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/intel-isl/MiDaS/zipball/master\" to /root/.cache/torch/hub/master.zip\n",
            "/usr/local/lib/python3.11/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
            "Downloading: \"https://github.com/isl-org/MiDaS/releases/download/v3/dpt_large_384.pt\" to /root/.cache/torch/hub/checkpoints/dpt_large_384.pt\n",
            "100%|██████████| 1.28G/1.28G [00:25<00:00, 53.5MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⬆️ Téléversez une image...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/intel-isl_MiDaS_master\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-542b6ca8-3915-4196-ad21-b629b11090c9\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-542b6ca8-3915-4196-ad21-b629b11090c9\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving IMG-20250226-WA0017.jpg to IMG-20250226-WA0017.jpg\n",
            "[LOG] Netteté OK (Laplacian: 8412.02)\n",
            "\u001b[1;33m[Open3D WARNING] GLFW Error: Failed to detect any supported platform\u001b[0;m\n",
            "\u001b[1;33m[Open3D WARNING] GLFW initialized for headless rendering.\u001b[0;m\n",
            "\u001b[1;33m[Open3D WARNING] GLFW Error: OSMesa: Library not found\u001b[0;m\n",
            "\u001b[1;33m[Open3D WARNING] Failed to create window\u001b[0;m\n",
            "\u001b[1;33m[Open3D WARNING] [DrawGeometries] Failed creating OpenGL window.\u001b[0;m\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_901da362-0e5d-4259-b83e-40f2d1008aa4\", \"scene3d_corrected.ply\", 83151)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[✅ FIN] Rendu 3D avec améliorations complètes et export réussi.\n"
          ]
        }
      ],
      "source": [
        "# 📦 INSTALLATION (exécuter une seule fois)\n",
        "!pip install -q opencv-python-headless pillow imageio matplotlib timm torch torchvision open3d\n",
        "!apt-get update && apt-get install -y ffmpeg\n",
        "\n",
        "# 📚 IMPORTS\n",
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "import open3d as o3d\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ExifTags, ImageEnhance, ImageFilter\n",
        "from google.colab import files\n",
        "import torchvision.transforms as T\n",
        "\n",
        "# 🔄 SETUP\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "os.makedirs(\"output_frames\", exist_ok=True)\n",
        "\n",
        "# 🔍 CHARGEMENT MiDaS\n",
        "model_type = \"DPT_Large\"\n",
        "midas = torch.hub.load(\"intel-isl/MiDaS\", model_type, trust_repo=True).to(device).eval()\n",
        "midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\", trust_repo=True)\n",
        "transform = midas_transforms.dpt_transform if model_type.startswith(\"DPT\") else midas_transforms.small_transform\n",
        "\n",
        "# 🧼 PRÉTRAITEMENT AVANCÉ\n",
        "def enhance_image(image: Image.Image) -> Image.Image:\n",
        "    enhancer = ImageEnhance.Contrast(image)\n",
        "    image = enhancer.enhance(1.8)\n",
        "\n",
        "    enhancer = ImageEnhance.Sharpness(image)\n",
        "    image = enhancer.enhance(2.0)\n",
        "\n",
        "    image = image.filter(ImageFilter.EDGE_ENHANCE_MORE)\n",
        "    return image\n",
        "\n",
        "def correct_orientation(image: Image.Image) -> Image.Image:\n",
        "    try:\n",
        "        for orientation in ExifTags.TAGS.keys():\n",
        "            if ExifTags.TAGS[orientation] == 'Orientation':\n",
        "                break\n",
        "        exif = dict(image._getexif().items())\n",
        "        if exif.get(orientation) == 3:\n",
        "            image = image.rotate(180, expand=True)\n",
        "        elif exif.get(orientation) == 6:\n",
        "            image = image.rotate(270, expand=True)\n",
        "        elif exif.get(orientation) == 8:\n",
        "            image = image.rotate(90, expand=True)\n",
        "    except:\n",
        "        pass\n",
        "    return image\n",
        "\n",
        "def load_and_prepare_image(image_path, target_max_size=512):\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    image = correct_orientation(image)\n",
        "\n",
        "    max_dim = max(image.size)\n",
        "    if max_dim > target_max_size:\n",
        "        scale = target_max_size / max_dim\n",
        "        image = image.resize((int(image.size[0]*scale), int(image.size[1]*scale)), Image.LANCZOS)\n",
        "\n",
        "    image = enhance_image(image)\n",
        "    return np.array(image)\n",
        "\n",
        "# 🔎 DÉTECTION D’ANOMALIES\n",
        "def check_image_quality(img):\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "    lap_var = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
        "    if lap_var < 50:\n",
        "        print(f\"[ALERTE] Image floue (Laplacian: {lap_var:.2f})\")\n",
        "    else:\n",
        "        print(f\"[LOG] Netteté OK (Laplacian: {lap_var:.2f})\")\n",
        "\n",
        "    if img.std() < 10:\n",
        "        raise ValueError(\"Image trop plate (faible contraste)\")\n",
        "    if img.mean() < 10:\n",
        "        raise ValueError(\"Image trop sombre\")\n",
        "\n",
        "# 🧠 INPAINTING POUR COMPLÉTION AUTOMATIQUE (zones noires ou plates)\n",
        "def auto_inpaint(img):\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "    _, mask = cv2.threshold(gray, 5, 255, cv2.THRESH_BINARY_INV)\n",
        "    inpainted = cv2.inpaint(img, mask, 3, cv2.INPAINT_TELEA)\n",
        "    return inpainted\n",
        "\n",
        "# 📤 UPLOAD IMAGE\n",
        "print(\"⬆️ Téléversez une image...\")\n",
        "uploaded = files.upload()\n",
        "image_path = next(iter(uploaded))\n",
        "\n",
        "# 🧽 TRAITEMENT\n",
        "img_rgb = load_and_prepare_image(image_path)\n",
        "check_image_quality(img_rgb)\n",
        "\n",
        "# Sauvegarde prévisualisation\n",
        "plt.imsave(\"output_frames/corrected_input.png\", img_rgb)\n",
        "\n",
        "# Inpainting zones sombres\n",
        "img_rgb = auto_inpaint(img_rgb)\n",
        "\n",
        "# 🔁 MIDAS - PRÉDICTION\n",
        "input_tensor = transform(img_rgb).to(device)\n",
        "with torch.no_grad():\n",
        "    prediction = midas(input_tensor)\n",
        "    prediction = torch.nn.functional.interpolate(\n",
        "        prediction.unsqueeze(1),\n",
        "        size=img_rgb.shape[:2],\n",
        "        mode=\"bicubic\",\n",
        "        align_corners=False,\n",
        "    ).squeeze()\n",
        "\n",
        "depth = prediction.cpu().numpy()\n",
        "plt.imsave(\"output_frames/depth_map.png\", depth, cmap=\"inferno\")\n",
        "\n",
        "# 📌 PARAMÈTRES 3D\n",
        "fx, fy = 500, 500\n",
        "h, w = depth.shape\n",
        "cx, cy = w / 2, h / 2\n",
        "depth = np.clip(depth, 0.1, 100)\n",
        "\n",
        "# 📍 GÉNÉRATION DU NUAGE DE POINTS\n",
        "all_points, all_colors = [], []\n",
        "for y in range(0, h, 8):\n",
        "    for x in range(0, w, 8):\n",
        "        z = depth[y, x]\n",
        "        if np.isnan(z) or np.isinf(z): continue\n",
        "        X = (x - cx) * z / fx\n",
        "        Y = (y - cy) * z / fy\n",
        "        all_points.append([X, -Y, -z])\n",
        "        all_colors.append(img_rgb[y, x] / 255.0)\n",
        "\n",
        "if not all_points:\n",
        "    raise RuntimeError(\"❌ Aucun point 3D détecté !\")\n",
        "\n",
        "pcd = o3d.geometry.PointCloud()\n",
        "pcd.points = o3d.utility.Vector3dVector(np.array(all_points))\n",
        "pcd.colors = o3d.utility.Vector3dVector(np.array(all_colors))\n",
        "\n",
        "# 🌐 VISUALISATION ET EXPORT\n",
        "try:\n",
        "    o3d.visualization.draw_geometries([pcd])\n",
        "except:\n",
        "    print(\"[LOG] Visualisation désactivée (Colab)\")\n",
        "\n",
        "output_file = \"scene3d_corrected.ply\"\n",
        "o3d.io.write_point_cloud(output_file, pcd)\n",
        "files.download(output_file)\n",
        "\n",
        "print(\"[✅ FIN] Rendu 3D avec améliorations complètes et export réussi.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 856
        },
        "id": "430hi9yQS6Sp",
        "outputId": "90baef8a-5074-4247-a066-b24b661cd321"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "Hit:1 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 36 not upgraded.\n",
            "Chargement du modèle MiDaS...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/intel-isl_MiDaS_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⬆️ Téléversez votre image...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/intel-isl_MiDaS_master\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1751c5f2-bb0a-4b55-91b7-aae3f964c7e2\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1751c5f2-bb0a-4b55-91b7-aae3f964c7e2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving 20250719_202118.jpg to 20250719_202118 (2).jpg\n",
            "[1/6] Chargement et prétraitement de l'image...\n",
            "[LOG] Netteté OK (Laplacian: 47787.33)\n",
            "[2/6] Inpainting automatique des zones sombres...\n",
            "[3/6] Segmentation sémantique en cours...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DeepLabV3_ResNet50_Weights.COCO_WITH_VOC_LABELS_V1`. You can also use `weights=DeepLabV3_ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/deeplabv3_resnet50_coco-cd0a2569.pth\" to /root/.cache/torch/hub/checkpoints/deeplabv3_resnet50_coco-cd0a2569.pth\n",
            "100%|██████████| 161M/161M [00:02<00:00, 63.0MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LOG] Carte de segmentation sauvegardée.\n",
            "[4/6] Amélioration super-résolution (bicubique)...\n",
            "[5/6] Estimation profondeur MiDaS sur l'image SR...\n",
            "[LOG] Carte de profondeur sauvegardée.\n",
            "[6/6] Génération du nuage de points 3D...\n",
            "\u001b[1;33m[Open3D WARNING] GLFW initialized for headless rendering.\u001b[0;m\n",
            "\u001b[1;33m[Open3D WARNING] GLFW Error: OSMesa: Library not found\u001b[0;m\n",
            "\u001b[1;33m[Open3D WARNING] Failed to create window\u001b[0;m\n",
            "\u001b[1;33m[Open3D WARNING] [DrawGeometries] Failed creating OpenGL window.\u001b[0;m\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_9854b787-25be-4a64-9039-1b39a8bcbff9\", \"scene3d_full_pipeline.ply\", 331984)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[✅ FIN] Pipeline complet exécuté et fichier 3D exporté.\n"
          ]
        }
      ],
      "source": [
        "# --- INSTALLATION ---\n",
        "!pip install -q opencv-python-headless pillow imageio matplotlib timm torch torchvision open3d segmentation-models-pytorch\n",
        "!apt-get update && apt-get install -y ffmpeg\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "import open3d as o3d\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ExifTags, ImageEnhance, ImageFilter\n",
        "from google.colab import files\n",
        "import torchvision.transforms as T\n",
        "from torchvision.models.segmentation import deeplabv3_resnet50\n",
        "\n",
        "# --- SETUP ---\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "os.makedirs(\"output_frames\", exist_ok=True)\n",
        "\n",
        "# --- Fonctions Utilitaires ---\n",
        "\n",
        "def correct_orientation(image: Image.Image) -> Image.Image:\n",
        "    try:\n",
        "        for orientation in ExifTags.TAGS.keys():\n",
        "            if ExifTags.TAGS[orientation] == 'Orientation':\n",
        "                break\n",
        "        exif = dict(image._getexif().items())\n",
        "        orientation_value = exif.get(orientation, None)\n",
        "        if orientation_value == 3:\n",
        "            image = image.rotate(180, expand=True)\n",
        "        elif orientation_value == 6:\n",
        "            image = image.rotate(270, expand=True)\n",
        "        elif orientation_value == 8:\n",
        "            image = image.rotate(90, expand=True)\n",
        "    except:\n",
        "        pass\n",
        "    return image\n",
        "\n",
        "def enhance_image(image: Image.Image) -> Image.Image:\n",
        "    enhancer = ImageEnhance.Contrast(image)\n",
        "    image = enhancer.enhance(1.8)\n",
        "    enhancer = ImageEnhance.Sharpness(image)\n",
        "    image = enhancer.enhance(2.0)\n",
        "    image = image.filter(ImageFilter.EDGE_ENHANCE_MORE)\n",
        "    return image\n",
        "\n",
        "def load_and_prepare_image(image_path, target_max_size=512):\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    image = correct_orientation(image)\n",
        "    max_dim = max(image.size)\n",
        "    if max_dim > target_max_size:\n",
        "        scale = target_max_size / max_dim\n",
        "        image = image.resize((int(image.size[0]*scale), int(image.size[1]*scale)), Image.LANCZOS)\n",
        "    image = enhance_image(image)\n",
        "    return np.array(image)\n",
        "\n",
        "def check_image_quality(img):\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "    lap_var = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
        "    if lap_var < 50:\n",
        "        print(f\"[ALERTE] Image floue (Laplacian: {lap_var:.2f})\")\n",
        "    else:\n",
        "        print(f\"[LOG] Netteté OK (Laplacian: {lap_var:.2f})\")\n",
        "    if img.std() < 10:\n",
        "        raise ValueError(\"Image trop plate (faible contraste)\")\n",
        "    if img.mean() < 10:\n",
        "        raise ValueError(\"Image trop sombre\")\n",
        "\n",
        "def auto_inpaint(img):\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "    _, mask = cv2.threshold(gray, 5, 255, cv2.THRESH_BINARY_INV)\n",
        "    inpainted = cv2.inpaint(img, mask, 3, cv2.INPAINT_TELEA)\n",
        "    return inpainted\n",
        "\n",
        "# --- Segmentation sémantique ---\n",
        "\n",
        "def run_segmentation(img_rgb):\n",
        "    model = deeplabv3_resnet50(pretrained=True).to(device)\n",
        "    model.eval()\n",
        "    preprocess = T.Compose([\n",
        "        T.ToTensor(),\n",
        "        T.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                    std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "    input_tensor = preprocess(Image.fromarray(img_rgb)).unsqueeze(0).to(device)\n",
        "    with torch.no_grad():\n",
        "        output = model(input_tensor)['out'][0]\n",
        "    output_predictions = output.argmax(0).byte().cpu().numpy()\n",
        "    return output_predictions\n",
        "\n",
        "def colorize_segmentation(segmentation):\n",
        "    # Couleurs simples pour les classes (21 classes)\n",
        "    palette = np.array([\n",
        "        [0, 0, 0],        # fond\n",
        "        [128, 0, 0],      # aeroplane\n",
        "        [0, 128, 0],      # bicycle\n",
        "        [128, 128, 0],    # bird\n",
        "        [0, 0, 128],      # boat\n",
        "        [128, 0, 128],    # bottle\n",
        "        [0, 128, 128],    # bus\n",
        "        [128, 128, 128],  # car\n",
        "        [64, 0, 0],       # cat\n",
        "        [192, 0, 0],      # chair\n",
        "        [64, 128, 0],     # cow\n",
        "        [192, 128, 0],    # diningtable\n",
        "        [64, 0, 128],     # dog\n",
        "        [192, 0, 128],    # horse\n",
        "        [64, 128, 128],   # motorbike\n",
        "        [192, 128, 128],  # person\n",
        "        [0, 64, 0],       # potted plant\n",
        "        [128, 64, 0],     # sheep\n",
        "        [0, 192, 0],      # sofa\n",
        "        [128, 192, 0],    # train\n",
        "        [0, 64, 128],     # tv/monitor\n",
        "    ])\n",
        "    color_seg = palette[segmentation % 21]\n",
        "    return color_seg.astype(np.uint8)\n",
        "\n",
        "# --- Super-résolution simplifiée (interpolation bicubique ici, tu peux remplacer par ESRGAN) ---\n",
        "\n",
        "def super_resolution(img_rgb, scale=2):\n",
        "    h, w = img_rgb.shape[:2]\n",
        "    new_h, new_w = h*scale, w*scale\n",
        "    img_sr = cv2.resize(img_rgb, (new_w, new_h), interpolation=cv2.INTER_CUBIC)\n",
        "    return img_sr\n",
        "\n",
        "# --- Chargement MiDaS ---\n",
        "\n",
        "print(\"Chargement du modèle MiDaS...\")\n",
        "model_type = \"DPT_Large\"\n",
        "midas = torch.hub.load(\"intel-isl/MiDaS\", model_type, trust_repo=True).to(device).eval()\n",
        "midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\", trust_repo=True)\n",
        "transform = midas_transforms.dpt_transform if model_type.startswith(\"DPT\") else midas_transforms.small_transform\n",
        "\n",
        "# --- Upload image ---\n",
        "print(\"⬆️ Téléversez votre image...\")\n",
        "uploaded = files.upload()\n",
        "image_path = next(iter(uploaded))\n",
        "\n",
        "# --- Pipeline complet ---\n",
        "print(\"[1/6] Chargement et prétraitement de l'image...\")\n",
        "img_rgb = load_and_prepare_image(image_path)\n",
        "check_image_quality(img_rgb)\n",
        "\n",
        "print(\"[2/6] Inpainting automatique des zones sombres...\")\n",
        "img_rgb = auto_inpaint(img_rgb)\n",
        "\n",
        "print(\"[3/6] Segmentation sémantique en cours...\")\n",
        "segmentation = run_segmentation(img_rgb)\n",
        "color_seg = colorize_segmentation(segmentation)\n",
        "plt.imsave(\"output_frames/segmentation.png\", color_seg)\n",
        "print(\"[LOG] Carte de segmentation sauvegardée.\")\n",
        "\n",
        "print(\"[4/6] Amélioration super-résolution (bicubique)...\")\n",
        "img_sr = super_resolution(img_rgb, scale=2)\n",
        "plt.imsave(\"output_frames/super_resolution.png\", img_sr)\n",
        "\n",
        "print(\"[5/6] Estimation profondeur MiDaS sur l'image SR...\")\n",
        "input_tensor = transform(img_sr).to(device)\n",
        "with torch.no_grad():\n",
        "    prediction = midas(input_tensor)\n",
        "    prediction = torch.nn.functional.interpolate(\n",
        "        prediction.unsqueeze(1),\n",
        "        size=img_sr.shape[:2],\n",
        "        mode=\"bicubic\",\n",
        "        align_corners=False,\n",
        "    ).squeeze()\n",
        "depth = prediction.cpu().numpy()\n",
        "plt.imsave(\"output_frames/depth_map.png\", depth, cmap=\"inferno\")\n",
        "print(\"[LOG] Carte de profondeur sauvegardée.\")\n",
        "\n",
        "print(\"[6/6] Génération du nuage de points 3D...\")\n",
        "fx, fy = 500, 500\n",
        "h, w = depth.shape\n",
        "cx, cy = w / 2, h / 2\n",
        "depth = np.clip(depth, 0.1, 100)\n",
        "\n",
        "all_points, all_colors = [], []\n",
        "stride = 8\n",
        "for y in range(0, h, stride):\n",
        "    for x in range(0, w, stride):\n",
        "        z = depth[y, x]\n",
        "        if np.isnan(z) or np.isinf(z):\n",
        "            continue\n",
        "        X = (x - cx) * z / fx\n",
        "        Y = (y - cy) * z / fy\n",
        "        all_points.append([X, -Y, -z])\n",
        "        # Couleur depuis l'image super-résolution (index possible hors limite, on clamp)\n",
        "        c_x, c_y = min(x, img_sr.shape[1]-1), min(y, img_sr.shape[0]-1)\n",
        "        all_colors.append(img_sr[c_y, c_x] / 255.0)\n",
        "\n",
        "if not all_points:\n",
        "    raise RuntimeError(\"❌ Aucun point valide généré !\")\n",
        "\n",
        "pcd = o3d.geometry.PointCloud()\n",
        "pcd.points = o3d.utility.Vector3dVector(np.array(all_points))\n",
        "pcd.colors = o3d.utility.Vector3dVector(np.array(all_colors))\n",
        "\n",
        "try:\n",
        "    o3d.visualization.draw_geometries([pcd])\n",
        "except:\n",
        "    print(\"[LOG] Visualisation désactivée (environnement non supporté)\")\n",
        "\n",
        "output_file = \"scene3d_full_pipeline.ply\"\n",
        "o3d.io.write_point_cloud(output_file, pcd)\n",
        "files.download(output_file)\n",
        "\n",
        "print(\"[✅ FIN] Pipeline complet exécuté et fichier 3D exporté.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4qTEPUbBYGUa",
        "outputId": "f73fd21a-8708-4bef-a249-3f369c25c42c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,840 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:8 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,764 kB]\n",
            "Get:9 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,267 kB]\n",
            "Hit:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:12 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,148 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:14 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,128 kB]\n",
            "Hit:15 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [4,932 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [5,139 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,461 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,572 kB]\n",
            "Fetched 33.6 MB in 3s (11.6 MB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 36 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!pip install -q opencv-python-headless pillow imageio matplotlib timm torch torchvision open3d segmentation-models-pytorch\n",
        "!apt-get update && apt-get install -y ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 526
        },
        "id": "_sXjWqDTYKw4",
        "outputId": "7c430e3c-a653-4659-95e8-90ef18dedbbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chargement MiDaS...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/intel-isl_MiDaS_master\n",
            "/usr/local/lib/python3.11/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⬆️ Upload image pour reconstruction...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/intel-isl_MiDaS_master\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-33378c0d-4939-4871-9afb-3abac5044469\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-33378c0d-4939-4871-9afb-3abac5044469\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 20250719_220835.jpg to 20250719_220835 (1).jpg\n",
            "[1/6] Prétraitement image...\n",
            "[LOG] Netteté (Laplacian): 31067.61\n",
            "[2/6] Inpainting zones sombres...\n",
            "[3/6] Segmentation sémantique...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DeepLabV3_ResNet50_Weights.COCO_WITH_VOC_LABELS_V1`. You can also use `weights=DeepLabV3_ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4/6] Super-résolution...\n",
            "[5/6] Profondeur avec MiDaS...\n",
            "[6/6] Nuage de points 3D texturé...\n",
            "\u001b[1;33m[Open3D WARNING] GLFW Error: Failed to detect any supported platform\u001b[0;m\n",
            "\u001b[1;33m[Open3D WARNING] GLFW initialized for headless rendering.\u001b[0;m\n",
            "\u001b[1;33m[Open3D WARNING] GLFW Error: OSMesa: Library not found\u001b[0;m\n",
            "\u001b[1;33m[Open3D WARNING] Failed to create window\u001b[0;m\n",
            "\u001b[1;33m[Open3D WARNING] [DrawGeometries] Failed creating OpenGL window.\u001b[0;m\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_edfa48eb-3274-4eae-abc1-ad30fae3af2d\", \"scene3d_splatting.ply\", 1327312)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Terminé. Nuage de points 3D exporté.\n"
          ]
        }
      ],
      "source": [
        "# coloré nuage et amélioration\n",
        "# ✅ IMPORTS\n",
        "import os, cv2, torch\n",
        "import numpy as np\n",
        "import open3d as o3d\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ExifTags, ImageEnhance, ImageFilter\n",
        "from google.colab import files\n",
        "import torchvision.transforms as T\n",
        "from torchvision.models.segmentation import deeplabv3_resnet50\n",
        "\n",
        "# ✅ SETUP\n",
        "torch.manual_seed(42)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "os.makedirs(\"output_frames\", exist_ok=True)\n",
        "\n",
        "# ✅ UTILS\n",
        "def correct_orientation(image: Image.Image) -> Image.Image:\n",
        "    try:\n",
        "        for orientation in ExifTags.TAGS.keys():\n",
        "            if ExifTags.TAGS[orientation] == 'Orientation':\n",
        "                break\n",
        "        exif = dict(image._getexif().items())\n",
        "        orientation_value = exif.get(orientation, None)\n",
        "        if orientation_value == 3:\n",
        "            image = image.rotate(180, expand=True)\n",
        "        elif orientation_value == 6:\n",
        "            image = image.rotate(270, expand=True)\n",
        "        elif orientation_value == 8:\n",
        "            image = image.rotate(90, expand=True)\n",
        "    except: pass\n",
        "    return image\n",
        "\n",
        "def enhance_image(image: Image.Image) -> Image.Image:\n",
        "    image = ImageEnhance.Contrast(image).enhance(1.8)\n",
        "    image = ImageEnhance.Sharpness(image).enhance(2.0)\n",
        "    image = image.filter(ImageFilter.EDGE_ENHANCE_MORE)\n",
        "    return image\n",
        "\n",
        "def load_and_prepare_image(image_path, target_max_size=512):\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    image = correct_orientation(image)\n",
        "    max_dim = max(image.size)\n",
        "    if max_dim > target_max_size:\n",
        "        scale = target_max_size / max_dim\n",
        "        image = image.resize((int(image.size[0]*scale), int(image.size[1]*scale)), Image.LANCZOS)\n",
        "    image = enhance_image(image)\n",
        "    return np.array(image)  # ✅ Fix ici : on retourne un tableau NumPy\n",
        "\n",
        "def check_image_quality(img):\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "    lap_var = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
        "    print(f\"[LOG] Netteté (Laplacian): {lap_var:.2f}\")\n",
        "    if img.std() < 10: raise ValueError(\"Image trop plate (contraste)\")\n",
        "    if img.mean() < 10: raise ValueError(\"Image trop sombre\")\n",
        "\n",
        "def auto_inpaint(img):\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "    _, mask = cv2.threshold(gray, 5, 255, cv2.THRESH_BINARY_INV)\n",
        "    return cv2.inpaint(img, mask, 3, cv2.INPAINT_TELEA)\n",
        "\n",
        "# ✅ SEGMENTATION DEEPLAB\n",
        "def run_segmentation(img_rgb):\n",
        "    model = deeplabv3_resnet50(pretrained=True).to(device)\n",
        "    model.eval()\n",
        "    preprocess = T.Compose([\n",
        "        T.ToTensor(),\n",
        "        T.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                    std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "    input_tensor = preprocess(Image.fromarray(img_rgb)).unsqueeze(0).to(device)\n",
        "    with torch.no_grad():\n",
        "        output = model(input_tensor)['out'][0]\n",
        "    return output.argmax(0).byte().cpu().numpy()\n",
        "\n",
        "def colorize_segmentation(seg):\n",
        "    palette = np.array([\n",
        "        [0,0,0],[128,0,0],[0,128,0],[128,128,0],[0,0,128],\n",
        "        [128,0,128],[0,128,128],[128,128,128],[64,0,0],[192,0,0],\n",
        "        [64,128,0],[192,128,0],[64,0,128],[192,0,128],[64,128,128],\n",
        "        [192,128,128],[0,64,0],[128,64,0],[0,192,0],[128,192,0],\n",
        "        [0,64,128]\n",
        "    ])\n",
        "    return palette[seg % 21].astype(np.uint8)\n",
        "\n",
        "def super_resolution(img, scale=2):\n",
        "    return cv2.resize(img, (img.shape[1]*scale, img.shape[0]*scale), interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "# ✅ MIDAS SETUP\n",
        "print(\"Chargement MiDaS...\")\n",
        "model_type = \"DPT_Large\"\n",
        "midas = torch.hub.load(\"intel-isl/MiDaS\", model_type, trust_repo=True).to(device).eval()\n",
        "midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\", trust_repo=True)\n",
        "transform = midas_transforms.dpt_transform\n",
        "\n",
        "# ✅ UPLOAD IMAGE\n",
        "print(\"⬆️ Upload image pour reconstruction...\")\n",
        "uploaded = files.upload()\n",
        "image_path = next(iter(uploaded))\n",
        "\n",
        "# ✅ PIPELINE\n",
        "print(\"[1/6] Prétraitement image...\")\n",
        "img_rgb = load_and_prepare_image(image_path)\n",
        "check_image_quality(img_rgb)\n",
        "\n",
        "print(\"[2/6] Inpainting zones sombres...\")\n",
        "img_rgb = auto_inpaint(img_rgb)\n",
        "\n",
        "print(\"[3/6] Segmentation sémantique...\")\n",
        "seg = run_segmentation(img_rgb)\n",
        "color_seg = colorize_segmentation(seg)\n",
        "plt.imsave(\"output_frames/segmentation.png\", color_seg)\n",
        "\n",
        "print(\"[4/6] Super-résolution...\")\n",
        "img_sr = super_resolution(img_rgb, scale=2)\n",
        "plt.imsave(\"output_frames/super_resolution.png\", img_sr)\n",
        "\n",
        "print(\"[5/6] Profondeur avec MiDaS...\")\n",
        "input_tensor = transform(img_sr).to(device)\n",
        "with torch.no_grad():\n",
        "    prediction = midas(input_tensor)\n",
        "    prediction = torch.nn.functional.interpolate(\n",
        "        prediction.unsqueeze(1),\n",
        "        size=img_sr.shape[:2],\n",
        "        mode=\"bicubic\",\n",
        "        align_corners=False,\n",
        "    ).squeeze()\n",
        "depth = prediction.cpu().numpy()\n",
        "plt.imsave(\"output_frames/depth_map.png\", depth, cmap=\"inferno\")\n",
        "\n",
        "print(\"[6/6] Nuage de points 3D texturé...\")\n",
        "fx, fy = 500, 500\n",
        "h, w = depth.shape\n",
        "cx, cy = w/2, h/2\n",
        "depth = np.clip(depth, 0.1, 100)\n",
        "\n",
        "points, colors = [], []\n",
        "stride = 4\n",
        "for y in range(0, h, stride):\n",
        "    for x in range(0, w, stride):\n",
        "        z = depth[y, x]\n",
        "        if np.isnan(z) or np.isinf(z): continue\n",
        "        X = (x - cx) * z / fx\n",
        "        Y = (y - cy) * z / fy\n",
        "        points.append([X, -Y, -z])\n",
        "        cx2, cy2 = min(x, img_sr.shape[1]-1), min(y, img_sr.shape[0]-1)\n",
        "        colors.append(img_sr[cy2, cx2] / 255.0)\n",
        "\n",
        "points = np.array(points)\n",
        "colors = np.array(colors)\n",
        "\n",
        "pcd = o3d.geometry.PointCloud()\n",
        "pcd.points = o3d.utility.Vector3dVector(points)\n",
        "pcd.colors = o3d.utility.Vector3dVector(colors)\n",
        "\n",
        "try:\n",
        "    o3d.visualization.draw_geometries([pcd])\n",
        "except:\n",
        "    print(\"[INFO] Visualisation désactivée sur ce device\")\n",
        "\n",
        "output_file = \"scene3d_splatting.ply\"\n",
        "o3d.io.write_point_cloud(output_file, pcd)\n",
        "files.download(output_file)\n",
        "print(\"✅ Terminé. Nuage de points 3D exporté.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 855
        },
        "id": "_FgVowC-b9yX",
        "outputId": "17bdc66a-d65f-4696-8709-bf68c0d35abe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Chargement nuage de points scene3d_splatting (1).ply...\n",
            "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to open file: scene3d_splatting (1).ply\u001b[0;m\n",
            "PointCloud with 0 points.\n",
            "[INFO] Calcul des normales...\n",
            "\u001b[1;33m[Open3D WARNING] [KDTreeFlann::SetRawData] Failed due to no data.\u001b[0;m\n",
            "[INFO] Reconstruction poisson en cours...\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "\u001b[1;31m[Open3D Error] (static std::tuple<std::shared_ptr<open3d::geometry::TriangleMesh>, std::vector<double, std::allocator<double> > > open3d::geometry::TriangleMesh::CreateFromPointCloudPoisson(const open3d::geometry::PointCloud&, size_t, float, float, bool, int)) /root/Open3D/cpp/open3d/geometry/SurfaceReconstructionPoisson.cpp:731: Point cloud has no normals\n\u001b[0;m",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1-1103138883.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# Exemple d'appel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mprocess_ply_to_textured_mesh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"scene3d_splatting (1).ply\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"scene3d_final.obj\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-1-1103138883.py\u001b[0m in \u001b[0;36mprocess_ply_to_textured_mesh\u001b[0;34m(ply_path, output_path, depth)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[INFO] Reconstruction poisson en cours...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mmesh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdensities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo3d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeometry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTriangleMesh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_from_point_cloud_poisson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpcd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# Filtrage pour supprimer les parties faibles densités\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: \u001b[1;31m[Open3D Error] (static std::tuple<std::shared_ptr<open3d::geometry::TriangleMesh>, std::vector<double, std::allocator<double> > > open3d::geometry::TriangleMesh::CreateFromPointCloudPoisson(const open3d::geometry::PointCloud&, size_t, float, float, bool, int)) /root/Open3D/cpp/open3d/geometry/SurfaceReconstructionPoisson.cpp:731: Point cloud has no normals\n\u001b[0;m"
          ]
        }
      ],
      "source": [
        "import open3d as o3d\n",
        "import numpy as np\n",
        "\n",
        "def process_ply_to_textured_mesh(ply_path, output_path=\"output_mesh.obj\", depth=9):\n",
        "    print(f\"[INFO] Chargement nuage de points {ply_path}...\")\n",
        "    pcd = o3d.io.read_point_cloud(ply_path)\n",
        "    print(pcd)\n",
        "\n",
        "    if not pcd.has_normals():\n",
        "        print(\"[INFO] Calcul des normales...\")\n",
        "        pcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.1, max_nn=30))\n",
        "        pcd.normalize_normals()\n",
        "\n",
        "    print(\"[INFO] Reconstruction poisson en cours...\")\n",
        "    mesh, densities = o3d.geometry.TriangleMesh.create_from_point_cloud_poisson(pcd, depth=depth)\n",
        "\n",
        "    # Filtrage pour supprimer les parties faibles densités\n",
        "    print(\"[INFO] Filtrage des faibles densités...\")\n",
        "    densities = np.asarray(densities)\n",
        "    density_threshold = np.quantile(densities, 0.01)\n",
        "    vertices_to_keep = densities > density_threshold\n",
        "    mesh.remove_vertices_by_mask(~vertices_to_keep)\n",
        "\n",
        "    # Si le nuage a des couleurs, on les transfère\n",
        "    if pcd.has_colors():\n",
        "        print(\"[INFO] Transfert couleurs vers le mesh...\")\n",
        "        mesh.vertex_colors = o3d.utility.Vector3dVector(\n",
        "            np.asarray(pcd.colors)[np.asarray(mesh.vertices)[:, 0].astype(int) % len(pcd.colors)]\n",
        "        )\n",
        "\n",
        "    # Sauvegarde du mesh en .obj\n",
        "    print(f\"[INFO] Export mesh final vers {output_path}\")\n",
        "    o3d.io.write_triangle_mesh(output_path, mesh)\n",
        "    print(\"[✅] Terminé ! Vous pouvez maintenant charger le mesh dans Blender, Unreal Engine, etc.\")\n",
        "\n",
        "# Exemple d'appel\n",
        "process_ply_to_textured_mesh(\"scene3d_splatting (1).ply\", \"scene3d_final.obj\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 509
        },
        "id": "_LcAnRmOl_5P",
        "outputId": "6d23b815-7f2d-4d7c-f9a2-7dfc17f46ba3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chargement MiDaS...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/intel-isl_MiDaS_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⬆️ Upload image pour reconstruction...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/intel-isl_MiDaS_master\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-28f2605a-ca96-471f-8e39-ae210d925899\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-28f2605a-ca96-471f-8e39-ae210d925899\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving 20250719_220848.jpg to 20250719_220848 (1).jpg\n",
            "[1/6] Prétraitement image...\n",
            "[LOG] Netteté (Laplacian): 34042.68\n",
            "[2/6] Inpainting zones sombres...\n",
            "[3/6] Segmentation sémantique...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DeepLabV3_ResNet50_Weights.COCO_WITH_VOC_LABELS_V1`. You can also use `weights=DeepLabV3_ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[4/6] Super-résolution...\n",
            "[5/6] Profondeur avec MiDaS...\n",
            "[Analyse] Statistiques et anomalies...\n",
            "📊 Moyenne: 20.21, Écart-type: 12.40, Min: -0.27, Max: 49.78\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_fe6ce113-280d-4dc6-9b42-fd2457237802\", \"rapport.txt\", 155)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[6/6] Reconstruction 3D...\n",
            "\u001b[1;33m[Open3D WARNING] GLFW initialized for headless rendering.\u001b[0;m\n",
            "\u001b[1;33m[Open3D WARNING] GLFW Error: OSMesa: Library not found\u001b[0;m\n",
            "\u001b[1;33m[Open3D WARNING] Failed to create window\u001b[0;m\n",
            "\u001b[1;33m[Open3D WARNING] [DrawGeometries] Failed creating OpenGL window.\u001b[0;m\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_98d3441d-9985-4da0-bfd6-1ffe9301cfed\", \"scene3d_splatting.ply\", 1327312)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Terminé. Tous les fichiers exportés dans 'output_frames'.\n"
          ]
        }
      ],
      "source": [
        "# ✅ IMPORTS\n",
        "import os, cv2, torch\n",
        "import numpy as np\n",
        "import open3d as o3d\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image, ExifTags, ImageEnhance, ImageFilter\n",
        "from google.colab import files\n",
        "import torchvision.transforms as T\n",
        "from torchvision.models.segmentation import deeplabv3_resnet50\n",
        "\n",
        "from scipy import ndimage\n",
        "\n",
        "# ✅ SETUP\n",
        "torch.manual_seed(42)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "os.makedirs(\"output_frames\", exist_ok=True)\n",
        "\n",
        "# ✅ UTILS\n",
        "def correct_orientation(image: Image.Image) -> Image.Image:\n",
        "    try:\n",
        "        for orientation in ExifTags.TAGS.keys():\n",
        "            if ExifTags.TAGS[orientation] == 'Orientation':\n",
        "                break\n",
        "        exif = dict(image._getexif().items())\n",
        "        orientation_value = exif.get(orientation, None)\n",
        "        if orientation_value == 3:\n",
        "            image = image.rotate(180, expand=True)\n",
        "        elif orientation_value == 6:\n",
        "            image = image.rotate(270, expand=True)\n",
        "        elif orientation_value == 8:\n",
        "            image = image.rotate(90, expand=True)\n",
        "    except: pass\n",
        "    return image\n",
        "\n",
        "def enhance_image(image: Image.Image) -> Image.Image:\n",
        "    image = ImageEnhance.Contrast(image).enhance(1.8)\n",
        "    image = ImageEnhance.Sharpness(image).enhance(2.0)\n",
        "    image = image.filter(ImageFilter.EDGE_ENHANCE_MORE)\n",
        "    return image\n",
        "\n",
        "def load_and_prepare_image(image_path, target_max_size=512):\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    image = correct_orientation(image)\n",
        "    max_dim = max(image.size)\n",
        "    if max_dim > target_max_size:\n",
        "        scale = target_max_size / max_dim\n",
        "        image = image.resize((int(image.size[0]*scale), int(image.size[1]*scale)), Image.LANCZOS)\n",
        "    image = enhance_image(image)\n",
        "    return np.array(image)\n",
        "\n",
        "def check_image_quality(img):\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "    lap_var = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
        "    print(f\"[LOG] Netteté (Laplacian): {lap_var:.2f}\")\n",
        "    if img.std() < 10: raise ValueError(\"Image trop plate (contraste)\")\n",
        "    if img.mean() < 10: raise ValueError(\"Image trop sombre\")\n",
        "\n",
        "def auto_inpaint(img):\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "    _, mask = cv2.threshold(gray, 5, 255, cv2.THRESH_BINARY_INV)\n",
        "    return cv2.inpaint(img, mask, 3, cv2.INPAINT_TELEA)\n",
        "\n",
        "# ✅ SEGMENTATION DEEPLAB\n",
        "def run_segmentation(img_rgb):\n",
        "    model = deeplabv3_resnet50(pretrained=True).to(device)\n",
        "    model.eval()\n",
        "    preprocess = T.Compose([\n",
        "        T.ToTensor(),\n",
        "        T.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                    std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "    input_tensor = preprocess(Image.fromarray(img_rgb)).unsqueeze(0).to(device)\n",
        "    with torch.no_grad():\n",
        "        output = model(input_tensor)['out'][0]\n",
        "    return output.argmax(0).byte().cpu().numpy()\n",
        "\n",
        "def colorize_segmentation(seg):\n",
        "    palette = np.array([\n",
        "        [0,0,0],[128,0,0],[0,128,0],[128,128,0],[0,0,128],\n",
        "        [128,0,128],[0,128,128],[128,128,128],[64,0,0],[192,0,0],\n",
        "        [64,128,0],[192,128,0],[64,0,128],[192,0,128],[64,128,128],\n",
        "        [192,128,128],[0,64,0],[128,64,0],[0,192,0],[128,192,0],\n",
        "        [0,64,128]\n",
        "    ])\n",
        "    return palette[seg % 21].astype(np.uint8)\n",
        "\n",
        "def super_resolution(img, scale=2):\n",
        "    return cv2.resize(img, (img.shape[1]*scale, img.shape[0]*scale), interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "# ✅ MIDAS SETUP\n",
        "print(\"Chargement MiDaS...\")\n",
        "model_type = \"DPT_Large\"\n",
        "midas = torch.hub.load(\"intel-isl/MiDaS\", model_type, trust_repo=True).to(device).eval()\n",
        "midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\", trust_repo=True)\n",
        "transform = midas_transforms.dpt_transform\n",
        "\n",
        "# ✅ UPLOAD IMAGE\n",
        "print(\"⬆️ Upload image pour reconstruction...\")\n",
        "uploaded = files.upload()\n",
        "image_path = next(iter(uploaded))\n",
        "\n",
        "# ✅ PIPELINE\n",
        "print(\"[1/6] Prétraitement image...\")\n",
        "img_rgb = load_and_prepare_image(image_path)\n",
        "check_image_quality(img_rgb)\n",
        "\n",
        "print(\"[2/6] Inpainting zones sombres...\")\n",
        "img_rgb = auto_inpaint(img_rgb)\n",
        "\n",
        "print(\"[3/6] Segmentation sémantique...\")\n",
        "seg = run_segmentation(img_rgb)\n",
        "color_seg = colorize_segmentation(seg)\n",
        "plt.imsave(\"output_frames/segmentation.png\", color_seg)\n",
        "\n",
        "print(\"[4/6] Super-résolution...\")\n",
        "img_sr = super_resolution(img_rgb, scale=2)\n",
        "plt.imsave(\"output_frames/super_resolution.png\", img_sr)\n",
        "\n",
        "print(\"[5/6] Profondeur avec MiDaS...\")\n",
        "input_tensor = transform(img_sr).to(device)\n",
        "with torch.no_grad():\n",
        "    prediction = midas(input_tensor)\n",
        "    prediction = torch.nn.functional.interpolate(\n",
        "        prediction.unsqueeze(1),\n",
        "        size=img_sr.shape[:2],\n",
        "        mode=\"bicubic\",\n",
        "        align_corners=False,\n",
        "    ).squeeze()\n",
        "depth = prediction.cpu().numpy()\n",
        "plt.imsave(\"output_frames/depth_map.png\", depth, cmap=\"inferno\")\n",
        "\n",
        "# ✅ ANALYSE DE PROFONDEUR\n",
        "print(\"[Analyse] Statistiques et anomalies...\")\n",
        "depth_flat = depth.flatten()\n",
        "depth_flat = depth_flat[~np.isnan(depth_flat)]\n",
        "\n",
        "mean_depth = np.mean(depth_flat)\n",
        "std_depth = np.std(depth_flat)\n",
        "max_depth = np.max(depth_flat)\n",
        "min_depth = np.min(depth_flat)\n",
        "\n",
        "print(f\"📊 Moyenne: {mean_depth:.2f}, Écart-type: {std_depth:.2f}, Min: {min_depth:.2f}, Max: {max_depth:.2f}\")\n",
        "\n",
        "anomalies = (depth < (mean_depth - 2*std_depth)) | (depth > (mean_depth + 2*std_depth))\n",
        "anomaly_map = anomalies.astype(np.uint8) * 255\n",
        "plt.imsave(\"output_frames/anomaly_map.png\", anomaly_map, cmap=\"gray\")\n",
        "\n",
        "# ✅ Histogramme profondeur\n",
        "plt.figure(figsize=(10,4))\n",
        "sns.histplot(depth_flat, bins=100, kde=True, color=\"blue\")\n",
        "plt.title(\"Distribution des valeurs de profondeur\")\n",
        "plt.xlabel(\"Profondeur\")\n",
        "plt.ylabel(\"Fréquence\")\n",
        "plt.savefig(\"output_frames/depth_distribution.png\")\n",
        "plt.close()\n",
        "\n",
        "# ✅ Contours sur l’image\n",
        "contours, _ = cv2.findContours(anomaly_map, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "img_contours = img_rgb.copy()\n",
        "cv2.drawContours(img_contours, contours, -1, (255, 0, 0), 2)\n",
        "plt.imsave(\"output_frames/zones_anomalies.png\", img_contours)\n",
        "\n",
        "# ✅ Rapport automatique\n",
        "rapport = []\n",
        "rapport.append(\"📄 Rapport d'analyse de scène 3D :\\n\")\n",
        "rapport.append(f\"- Moyenne de profondeur : {mean_depth:.2f}\")\n",
        "rapport.append(f\"- Écart-type : {std_depth:.2f}\")\n",
        "rapport.append(f\"- Min : {min_depth:.2f}, Max : {max_depth:.2f}\")\n",
        "rapport.append(f\"- Zones anormales détectées : {'Oui' if anomalies.any() else 'Non'}\")\n",
        "\n",
        "with open(\"output_frames/rapport.txt\", \"w\") as f:\n",
        "    f.write(\"\\n\".join(rapport))\n",
        "\n",
        "files.download(\"output_frames/rapport.txt\")\n",
        "\n",
        "# ✅ Nuage de points 3D\n",
        "print(\"[6/6] Reconstruction 3D...\")\n",
        "fx, fy = 500, 500\n",
        "h, w = depth.shape\n",
        "cx, cy = w/2, h/2\n",
        "depth = np.clip(depth, 0.1, 100)\n",
        "\n",
        "points, colors = [], []\n",
        "stride = 4\n",
        "for y in range(0, h, stride):\n",
        "    for x in range(0, w, stride):\n",
        "        z = depth[y, x]\n",
        "        if np.isnan(z) or np.isinf(z): continue\n",
        "        X = (x - cx) * z / fx\n",
        "        Y = (y - cy) * z / fy\n",
        "        points.append([X, -Y, -z])\n",
        "        cx2, cy2 = min(x, img_sr.shape[1]-1), min(y, img_sr.shape[0]-1)\n",
        "        colors.append(img_sr[cy2, cx2] / 255.0)\n",
        "\n",
        "points = np.array(points)\n",
        "colors = np.array(colors)\n",
        "\n",
        "pcd = o3d.geometry.PointCloud()\n",
        "pcd.points = o3d.utility.Vector3dVector(points)\n",
        "pcd.colors = o3d.utility.Vector3dVector(colors)\n",
        "\n",
        "try:\n",
        "    o3d.visualization.draw_geometries([pcd])\n",
        "except:\n",
        "    print(\"[INFO] Visualisation désactivée sur ce device\")\n",
        "\n",
        "output_file = \"scene3d_splatting.ply\"\n",
        "o3d.io.write_point_cloud(output_file, pcd)\n",
        "files.download(output_file)\n",
        "print(\"✅ Terminé. Tous les fichiers exportés dans 'output_frames'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "bONvuz1bqKw9",
        "outputId": "c207ae1f-2072-4aff-c108-784b7a71c5db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.7)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Collecting open3d\n",
            "  Downloading open3d-0.19.0-cp311-cp311-manylinux_2_31_x86_64.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.16.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.11.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (25.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.11/dist-packages (from seaborn) (2.2.2)\n",
            "Collecting dash>=2.6.0 (from open3d)\n",
            "  Downloading dash-3.1.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: werkzeug>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from open3d) (3.1.3)\n",
            "Requirement already satisfied: flask>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from open3d) (3.1.1)\n",
            "Requirement already satisfied: nbformat>=5.7.0 in /usr/local/lib/python3.11/dist-packages (from open3d) (5.10.4)\n",
            "Collecting configargparse (from open3d)\n",
            "  Downloading configargparse-1.7.1-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting ipywidgets>=8.0.4 (from open3d)\n",
            "  Downloading ipywidgets-8.1.7-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting addict (from open3d)\n",
            "  Downloading addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: pyyaml>=5.4.1 in /usr/local/lib/python3.11/dist-packages (from open3d) (6.0.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21 in /usr/local/lib/python3.11/dist-packages (from open3d) (1.6.1)\n",
            "Collecting pyquaternion (from open3d)\n",
            "  Downloading pyquaternion-0.9.9-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.5)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: plotly>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from dash>=2.6.0->open3d) (5.24.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from dash>=2.6.0->open3d) (8.7.0)\n",
            "Collecting retrying (from dash>=2.6.0->open3d)\n",
            "  Downloading retrying-1.4.1-py3-none-any.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from dash>=2.6.0->open3d) (1.6.0)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from flask>=3.0.0->open3d) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask>=3.0.0->open3d) (8.2.1)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from flask>=3.0.0->open3d) (2.2.0)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from flask>=3.0.0->open3d) (3.0.2)\n",
            "Collecting comm>=0.1.3 (from ipywidgets>=8.0.4->open3d)\n",
            "  Downloading comm-0.2.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.0.4->open3d) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.0.4->open3d) (5.7.1)\n",
            "Collecting widgetsnbextension~=4.0.14 (from ipywidgets>=8.0.4->open3d)\n",
            "  Downloading widgetsnbextension-4.0.14-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.0.4->open3d) (3.0.15)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.7.0->open3d) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.7.0->open3d) (4.24.0)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.7.0->open3d) (5.8.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.7.14)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21->open3d) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21->open3d) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21->open3d) (3.6.0)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.3.0.post1)\n",
            "Collecting jedi>=0.16 (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (3.0.51)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (4.9.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (0.26.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core!=5.0.*,>=4.12->nbformat>=5.7.0->open3d) (4.3.8)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly>=5.0.0->dash>=2.6.0->open3d) (8.5.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->dash>=2.6.0->open3d) (3.23.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.8.4)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.13)\n",
            "Downloading open3d-0.19.0-cp311-cp311-manylinux_2_31_x86_64.whl (447.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.7/447.7 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m74.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m79.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dash-3.1.1-py3-none-any.whl (7.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m105.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ipywidgets-8.1.7-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Downloading configargparse-1.7.1-py3-none-any.whl (25 kB)\n",
            "Downloading pyquaternion-0.9.9-py3-none-any.whl (14 kB)\n",
            "Downloading comm-0.2.2-py3-none-any.whl (7.2 kB)\n",
            "Downloading widgetsnbextension-4.0.14-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m79.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading retrying-1.4.1-py3-none-any.whl (12 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: addict, widgetsnbextension, retrying, pyquaternion, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, jedi, configargparse, comm, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ipywidgets, dash, open3d\n",
            "  Attempting uninstall: widgetsnbextension\n",
            "    Found existing installation: widgetsnbextension 3.6.10\n",
            "    Uninstalling widgetsnbextension-3.6.10:\n",
            "      Successfully uninstalled widgetsnbextension-3.6.10\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: ipywidgets\n",
            "    Found existing installation: ipywidgets 7.7.1\n",
            "    Uninstalling ipywidgets-7.7.1:\n",
            "      Successfully uninstalled ipywidgets-7.7.1\n",
            "Successfully installed addict-2.4.0 comm-0.2.2 configargparse-1.7.1 dash-3.1.1 ipywidgets-8.1.7 jedi-0.19.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 open3d-0.19.0 pyquaternion-0.9.9 retrying-1.4.1 widgetsnbextension-4.0.14\n",
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m102.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "!pip install spacy seaborn open3d torch torchvision matplotlib pillow\n",
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3lJ06KeoXv6c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 509
        },
        "id": "V0gIUnesvcbt",
        "outputId": "340bddb9-ba6f-41a5-cceb-bffd75569328"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chargement MiDaS...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/intel-isl_MiDaS_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⬆️ Upload image pour reconstruction...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/intel-isl_MiDaS_master\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-fdafbeec-5bc4-4835-aa4f-3b52266aca56\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-fdafbeec-5bc4-4835-aa4f-3b52266aca56\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving 20250719_220848.jpg to 20250719_220848 (2).jpg\n",
            "[1/6] Prétraitement image...\n",
            "[LOG] Netteté (Laplacian): 34042.68\n",
            "[2/6] Inpainting zones sombres...\n",
            "[3/6] Segmentation sémantique...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DeepLabV3_ResNet50_Weights.COCO_WITH_VOC_LABELS_V1`. You can also use `weights=DeepLabV3_ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[4/6] Super-résolution...\n",
            "[5/6] Profondeur avec MiDaS...\n",
            "[Analyse] Statistiques et anomalies...\n",
            "📊 Moyenne: 20.21, Écart-type: 12.40, Min: -0.27, Max: 49.78\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_62ceef99-f710-4812-bd12-09b0b02d32e1\", \"rapport.txt\", 155)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[6/6] Reconstruction 3D avec analyse...\n",
            "\u001b[1;33m[Open3D WARNING] GLFW initialized for headless rendering.\u001b[0;m\n",
            "\u001b[1;33m[Open3D WARNING] GLFW Error: OSMesa: Library not found\u001b[0;m\n",
            "\u001b[1;33m[Open3D WARNING] Failed to create window\u001b[0;m\n",
            "\u001b[1;33m[Open3D WARNING] [DrawGeometries] Failed creating OpenGL window.\u001b[0;m\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_ad22240d-77e9-4075-8264-b7cf1baf4b79\", \"scene3d_splatting_with_analysis.ply\", 3020793)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Terminé. Nuage de points 3D avec analyse exporté dans 'scene3d_splatting_with_analysis.ply'.\n"
          ]
        }
      ],
      "source": [
        "# ✅ IMPORTS\n",
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "import open3d as o3d\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image, ExifTags, ImageEnhance, ImageFilter\n",
        "from google.colab import files\n",
        "import torchvision.transforms as T\n",
        "from torchvision.models.segmentation import deeplabv3_resnet50\n",
        "from scipy import ndimage\n",
        "\n",
        "# ✅ SETUP\n",
        "torch.manual_seed(42)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "os.makedirs(\"output_frames\", exist_ok=True)\n",
        "\n",
        "# ✅ UTILS\n",
        "def correct_orientation(image: Image.Image) -> Image.Image:\n",
        "    try:\n",
        "        for orientation in ExifTags.TAGS.keys():\n",
        "            if ExifTags.TAGS[orientation] == 'Orientation':\n",
        "                break\n",
        "        exif = dict(image._getexif().items())\n",
        "        orientation_value = exif.get(orientation, None)\n",
        "        if orientation_value == 3:\n",
        "            image = image.rotate(180, expand=True)\n",
        "        elif orientation_value == 6:\n",
        "            image = image.rotate(270, expand=True)\n",
        "        elif orientation_value == 8:\n",
        "            image = image.rotate(90, expand=True)\n",
        "    except:\n",
        "        pass\n",
        "    return image\n",
        "\n",
        "def enhance_image(image: Image.Image) -> Image.Image:\n",
        "    image = ImageEnhance.Contrast(image).enhance(1.8)\n",
        "    image = ImageEnhance.Sharpness(image).enhance(2.0)\n",
        "    image = image.filter(ImageFilter.EDGE_ENHANCE_MORE)\n",
        "    return image\n",
        "\n",
        "def load_and_prepare_image(image_path, target_max_size=512):\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    image = correct_orientation(image)\n",
        "    max_dim = max(image.size)\n",
        "    if max_dim > target_max_size:\n",
        "        scale = target_max_size / max_dim\n",
        "        image = image.resize((int(image.size[0]*scale), int(image.size[1]*scale)), Image.LANCZOS)\n",
        "    image = enhance_image(image)\n",
        "    return np.array(image)\n",
        "\n",
        "def check_image_quality(img):\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "    lap_var = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
        "    print(f\"[LOG] Netteté (Laplacian): {lap_var:.2f}\")\n",
        "    if img.std() < 10: raise ValueError(\"Image trop plate (contraste)\")\n",
        "    if img.mean() < 10: raise ValueError(\"Image trop sombre\")\n",
        "\n",
        "def auto_inpaint(img):\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "    _, mask = cv2.threshold(gray, 5, 255, cv2.THRESH_BINARY_INV)\n",
        "    return cv2.inpaint(img, mask, 3, cv2.INPAINT_TELEA)\n",
        "\n",
        "# ✅ SEGMENTATION DEEPLAB\n",
        "def run_segmentation(img_rgb):\n",
        "    model = deeplabv3_resnet50(pretrained=True).to(device)\n",
        "    model.eval()\n",
        "    preprocess = T.Compose([\n",
        "        T.ToTensor(),\n",
        "        T.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                    std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "    input_tensor = preprocess(Image.fromarray(img_rgb)).unsqueeze(0).to(device)\n",
        "    with torch.no_grad():\n",
        "        output = model(input_tensor)['out'][0]\n",
        "    return output.argmax(0).byte().cpu().numpy()\n",
        "\n",
        "def colorize_segmentation(seg):\n",
        "    palette = np.array([\n",
        "        [0,0,0],[128,0,0],[0,128,0],[128,128,0],[0,0,128],\n",
        "        [128,0,128],[0,128,128],[128,128,128],[64,0,0],[192,0,0],\n",
        "        [64,128,0],[192,128,0],[64,0,128],[192,0,128],[64,128,128],\n",
        "        [192,128,128],[0,64,0],[128,64,0],[0,192,0],[128,192,0],\n",
        "        [0,64,128]\n",
        "    ])\n",
        "    return palette[seg % 21].astype(np.uint8)\n",
        "\n",
        "def super_resolution(img, scale=2):\n",
        "    return cv2.resize(img, (img.shape[1]*scale, img.shape[0]*scale), interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "# ✅ MIDAS SETUP\n",
        "print(\"Chargement MiDaS...\")\n",
        "model_type = \"DPT_Large\"\n",
        "midas = torch.hub.load(\"intel-isl/MiDaS\", model_type, trust_repo=True).to(device).eval()\n",
        "midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\", trust_repo=True)\n",
        "transform = midas_transforms.dpt_transform\n",
        "\n",
        "# ✅ UPLOAD IMAGE\n",
        "print(\"⬆️ Upload image pour reconstruction...\")\n",
        "uploaded = files.upload()\n",
        "image_path = next(iter(uploaded))\n",
        "\n",
        "# ✅ PIPELINE\n",
        "print(\"[1/6] Prétraitement image...\")\n",
        "img_rgb = load_and_prepare_image(image_path)\n",
        "check_image_quality(img_rgb)\n",
        "\n",
        "print(\"[2/6] Inpainting zones sombres...\")\n",
        "img_rgb = auto_inpaint(img_rgb)\n",
        "\n",
        "print(\"[3/6] Segmentation sémantique...\")\n",
        "seg = run_segmentation(img_rgb)\n",
        "color_seg = colorize_segmentation(seg)\n",
        "plt.imsave(\"output_frames/segmentation.png\", color_seg)\n",
        "\n",
        "print(\"[4/6] Super-résolution...\")\n",
        "img_sr = super_resolution(img_rgb, scale=2)\n",
        "plt.imsave(\"output_frames/super_resolution.png\", img_sr)\n",
        "\n",
        "print(\"[5/6] Profondeur avec MiDaS...\")\n",
        "input_tensor = transform(img_sr).to(device)\n",
        "with torch.no_grad():\n",
        "    prediction = midas(input_tensor)\n",
        "    prediction = torch.nn.functional.interpolate(\n",
        "        prediction.unsqueeze(1),\n",
        "        size=img_sr.shape[:2],\n",
        "        mode=\"bicubic\",\n",
        "        align_corners=False,\n",
        "    ).squeeze()\n",
        "depth = prediction.cpu().numpy()\n",
        "plt.imsave(\"output_frames/depth_map.png\", depth, cmap=\"inferno\")\n",
        "\n",
        "# ✅ ANALYSE DE PROFONDEUR\n",
        "print(\"[Analyse] Statistiques et anomalies...\")\n",
        "depth_flat = depth.flatten()\n",
        "depth_flat = depth_flat[~np.isnan(depth_flat)]\n",
        "\n",
        "mean_depth = np.mean(depth_flat)\n",
        "std_depth = np.std(depth_flat)\n",
        "max_depth = np.max(depth_flat)\n",
        "min_depth = np.min(depth_flat)\n",
        "\n",
        "print(f\"📊 Moyenne: {mean_depth:.2f}, Écart-type: {std_depth:.2f}, Min: {min_depth:.2f}, Max: {max_depth:.2f}\")\n",
        "\n",
        "anomalies = (depth < (mean_depth - 2*std_depth)) | (depth > (mean_depth + 2*std_depth))\n",
        "anomaly_map = anomalies.astype(np.uint8) * 255\n",
        "plt.imsave(\"output_frames/anomaly_map.png\", anomaly_map, cmap=\"gray\")\n",
        "\n",
        "# ✅ Histogramme profondeur\n",
        "plt.figure(figsize=(10,4))\n",
        "sns.histplot(depth_flat, bins=100, kde=True, color=\"blue\")\n",
        "plt.title(\"Distribution des valeurs de profondeur\")\n",
        "plt.xlabel(\"Profondeur\")\n",
        "plt.ylabel(\"Fréquence\")\n",
        "plt.savefig(\"output_frames/depth_distribution.png\")\n",
        "plt.close()\n",
        "\n",
        "# ✅ Contours sur l’image\n",
        "contours, _ = cv2.findContours(anomaly_map, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "img_contours = img_rgb.copy()\n",
        "cv2.drawContours(img_contours, contours, -1, (255, 0, 0), 2)\n",
        "plt.imsave(\"output_frames/zones_anomalies.png\", img_contours)\n",
        "\n",
        "# ✅ Rapport automatique\n",
        "rapport = []\n",
        "rapport.append(\"📄 Rapport d'analyse de scène 3D :\\n\")\n",
        "rapport.append(f\"- Moyenne de profondeur : {mean_depth:.2f}\")\n",
        "rapport.append(f\"- Écart-type : {std_depth:.2f}\")\n",
        "rapport.append(f\"- Min : {min_depth:.2f}, Max : {max_depth:.2f}\")\n",
        "rapport.append(f\"- Zones anormales détectées : {'Oui' if anomalies.any() else 'Non'}\")\n",
        "\n",
        "with open(\"output_frames/rapport.txt\", \"w\") as f:\n",
        "    f.write(\"\\n\".join(rapport))\n",
        "\n",
        "files.download(\"output_frames/rapport.txt\")\n",
        "\n",
        "# ✅ Nuage de points 3D avec analyse intégrée\n",
        "print(\"[6/6] Reconstruction 3D avec analyse...\")\n",
        "fx, fy = 500, 500\n",
        "h, w = depth.shape\n",
        "cx, cy = w/2, h/2\n",
        "depth = np.clip(depth, 0.1, 100)\n",
        "\n",
        "points, colors, anomaly_flags = [], [], []\n",
        "stride = 4\n",
        "for y in range(0, h, stride):\n",
        "    for x in range(0, w, stride):\n",
        "        z = depth[y, x]\n",
        "        if np.isnan(z) or np.isinf(z): continue\n",
        "        X = (x - cx) * z / fx\n",
        "        Y = (y - cy) * z / fy\n",
        "        points.append([X, -Y, -z])\n",
        "        cx2, cy2 = min(x, img_sr.shape[1]-1), min(y, img_sr.shape[0]-1)\n",
        "        colors.append(img_sr[cy2, cx2] / 255.0)\n",
        "        anomaly_flags.append(1.0 if anomalies[y, x] else 0.0)  # 1 pour anomalie, 0 sinon\n",
        "\n",
        "points = np.array(points)\n",
        "colors = np.array(colors)\n",
        "anomaly_flags = np.array(anomaly_flags)\n",
        "\n",
        "# Créer le nuage de points\n",
        "pcd = o3d.geometry.PointCloud()\n",
        "pcd.points = o3d.utility.Vector3dVector(points)\n",
        "pcd.colors = o3d.utility.Vector3dVector(colors)\n",
        "\n",
        "# Ajouter la propriété d'anomalie comme propriété personnalisée\n",
        "# Note : Open3D ne supporte pas nativement les propriétés personnalisées, donc on utilise un fichier PLY personnalisé\n",
        "output_file = \"scene3d_splatting_with_analysis.ply\"\n",
        "\n",
        "# Écrire le fichier PLY manuellement avec les métadonnées et propriétés\n",
        "with open(output_file, \"w\") as f:\n",
        "    # En-tête PLY\n",
        "    f.write(\"ply\\n\")\n",
        "    f.write(\"format ascii 1.0\\n\")\n",
        "    f.write(f\"comment Mean Depth: {mean_depth:.2f}\\n\")\n",
        "    f.write(f\"comment Std Depth: {std_depth:.2f}\\n\")\n",
        "    f.write(f\"comment Min Depth: {min_depth:.2f}\\n\")\n",
        "    f.write(f\"comment Max Depth: {max_depth:.2f}\\n\")\n",
        "    f.write(f\"comment Anomalies Detected: {'Yes' if anomalies.any() else 'No'}\\n\")\n",
        "    f.write(f\"element vertex {len(points)}\\n\")\n",
        "    f.write(\"property float x\\n\")\n",
        "    f.write(\"property float y\\n\")\n",
        "    f.write(\"property float z\\n\")\n",
        "    f.write(\"property float red\\n\")\n",
        "    f.write(\"property float green\\n\")\n",
        "    f.write(\"property float blue\\n\")\n",
        "    f.write(\"property float anomaly\\n\")  # Propriété personnalisée pour les anomalies\n",
        "    f.write(\"end_header\\n\")\n",
        "\n",
        "    # Écrire les données des points\n",
        "    for i in range(len(points)):\n",
        "        x, y, z = points[i]\n",
        "        r, g, b = colors[i]\n",
        "        anomaly = anomaly_flags[i]\n",
        "        f.write(f\"{x:.6f} {y:.6f} {z:.6f} {r:.6f} {g:.6f} {b:.6f} {anomaly:.1f}\\n\")\n",
        "\n",
        "# Visualisation\n",
        "try:\n",
        "    o3d.visualization.draw_geometries([pcd])\n",
        "except:\n",
        "    print(\"[INFO] Visualisation désactivée sur ce device\")\n",
        "\n",
        "# Téléchargement du fichier PLY\n",
        "files.download(output_file)\n",
        "print(\"✅ Terminé. Nuage de points 3D avec analyse exporté dans 'scene3d_splatting_with_analysis.ply'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Tcmx3Cy2Xy1J",
        "outputId": "715e1a98-4e36-4616-9724-9b045cec345f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.11/dist-packages (0.116.1)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.11/dist-packages (0.35.0)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.11/dist-packages (0.0.20)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (1.0.17)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: open3d in /usr/local/lib/python3.11/dist-packages (0.19.0)\n",
            "Requirement already satisfied: starlette<0.48.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (0.47.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from fastapi) (2.11.7)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (4.14.1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (8.2.1)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (0.16.0)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (2.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.5)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from timm) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from timm) (0.33.4)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: dash>=2.6.0 in /usr/local/lib/python3.11/dist-packages (from open3d) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from open3d) (3.1.3)\n",
            "Requirement already satisfied: flask>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from open3d) (3.1.1)\n",
            "Requirement already satisfied: nbformat>=5.7.0 in /usr/local/lib/python3.11/dist-packages (from open3d) (5.10.4)\n",
            "Requirement already satisfied: configargparse in /usr/local/lib/python3.11/dist-packages (from open3d) (1.7.1)\n",
            "Requirement already satisfied: ipywidgets>=8.0.4 in /usr/local/lib/python3.11/dist-packages (from open3d) (8.1.7)\n",
            "Requirement already satisfied: addict in /usr/local/lib/python3.11/dist-packages (from open3d) (2.4.0)\n",
            "Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.11/dist-packages (from open3d) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21 in /usr/local/lib/python3.11/dist-packages (from open3d) (1.6.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from open3d) (4.67.1)\n",
            "Requirement already satisfied: pyquaternion in /usr/local/lib/python3.11/dist-packages (from open3d) (0.9.9)\n",
            "Requirement already satisfied: plotly>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from dash>=2.6.0->open3d) (5.24.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from dash>=2.6.0->open3d) (8.7.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from dash>=2.6.0->open3d) (2.32.3)\n",
            "Requirement already satisfied: retrying in /usr/local/lib/python3.11/dist-packages (from dash>=2.6.0->open3d) (1.4.1)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from dash>=2.6.0->open3d) (1.6.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from dash>=2.6.0->open3d) (75.2.0)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from flask>=3.0.0->open3d) (1.9.0)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from flask>=3.0.0->open3d) (2.2.0)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from flask>=3.0.0->open3d) (3.0.2)\n",
            "Requirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.0.4->open3d) (0.2.2)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.0.4->open3d) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.0.4->open3d) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=4.0.14 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.0.4->open3d) (4.0.14)\n",
            "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.0.4->open3d) (3.0.15)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.7.0->open3d) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.7.0->open3d) (4.24.0)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.7.0->open3d) (5.8.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0->open3d) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0->open3d) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21->open3d) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21->open3d) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21->open3d) (3.6.0)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.48.0,>=0.40.0->fastapi) (4.9.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (1.1.5)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.48.0,>=0.40.0->fastapi) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.48.0,>=0.40.0->fastapi) (1.3.1)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (3.0.51)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (4.9.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (0.26.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core!=5.0.*,>=4.12->nbformat>=5.7.0->open3d) (4.3.8)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly>=5.0.0->dash>=2.6.0->open3d) (8.5.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->dash>=2.6.0->open3d) (3.23.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->dash>=2.6.0->open3d) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->dash>=2.6.0->open3d) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->dash>=2.6.0->open3d) (2025.7.14)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.13)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:asyncio:Task exception was never retrieved\n",
            "future: <Task finished name='Task-1' coro=<Server.serve() done, defined at /usr/local/lib/python3.11/dist-packages/uvicorn/server.py:69> exception=KeyboardInterrupt()>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/main.py\", line 580, in run\n",
            "    server.run()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/server.py\", line 67, in run\n",
            "    return asyncio.run(self.serve(sockets=sockets))\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/nest_asyncio.py\", line 30, in run\n",
            "    return loop.run_until_complete(task)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/nest_asyncio.py\", line 92, in run_until_complete\n",
            "    self._run_once()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/nest_asyncio.py\", line 133, in _run_once\n",
            "    handle._run()\n",
            "  File \"/usr/lib/python3.11/asyncio/events.py\", line 84, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/usr/lib/python3.11/asyncio/tasks.py\", line 360, in __wakeup\n",
            "    self.__step()\n",
            "  File \"/usr/lib/python3.11/asyncio/tasks.py\", line 277, in __step\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/server.py\", line 70, in serve\n",
            "    with self.capture_signals():\n",
            "  File \"/usr/lib/python3.11/contextlib.py\", line 144, in __exit__\n",
            "    next(self.gen)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/server.py\", line 331, in capture_signals\n",
            "    signal.raise_signal(captured_signal)\n",
            "KeyboardInterrupt\n",
            "Using cache found in /root/.cache/torch/hub/intel-isl_MiDaS_master\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-19-379460978.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Charger modèle MiDaS une fois au démarrage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mmodel_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"DPT_Large\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mmidas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"intel-isl/MiDaS\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrust_repo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mmidas_transforms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"intel-isl/MiDaS\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transforms\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrust_repo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/hub.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(repo_or_dir, model, source, trust_repo, force_reload, verbose, skip_validation, *args, **kwargs)\u001b[0m\n\u001b[1;32m    645\u001b[0m         )\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 647\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_local\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepo_or_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    648\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/hub.py\u001b[0m in \u001b[0;36m_load_local\u001b[0;34m(hubconf_dir, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m         \u001b[0mentry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_entry_from_hubconf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhub_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.cache/torch/hub/intel-isl_MiDaS_master/hubconf.py\u001b[0m in \u001b[0;36mDPT_Large\u001b[0;34m(pretrained, **kwargs)\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0;34m\"https://github.com/isl-org/MiDaS/releases/download/v3/dpt_large_384.pt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         )\n\u001b[0;32m--> 234\u001b[0;31m         state_dict = torch.hub.load_state_dict_from_url(\n\u001b[0m\u001b[1;32m    235\u001b[0m             \u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_hash\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/hub.py\u001b[0m in \u001b[0;36mload_state_dict_from_url\u001b[0;34m(url, model_dir, map_location, progress, check_hash, file_name, weights_only)\u001b[0m\n\u001b[1;32m    869\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_legacy_zip_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcached_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_zip_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcached_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_only\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcached_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights_only\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1469\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1470\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_wo_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1471\u001b[0;31m                 return _load(\n\u001b[0m\u001b[1;32m   1472\u001b[0m                     \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1473\u001b[0m                     \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1962\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0m_serialization_tls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m     \u001b[0m_serialization_tls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_location\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1964\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1965\u001b[0m     \u001b[0m_serialization_tls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_location\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1926\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1927\u001b[0m             \u001b[0mnbytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumel\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1928\u001b[0;31m             typed_storage = load_tensor(\n\u001b[0m\u001b[1;32m   1929\u001b[0m                 \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_maybe_decode_ascii\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1930\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1886\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1887\u001b[0m             storage = (\n\u001b[0;32m-> 1888\u001b[0;31m                 \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_storage_from_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUntypedStorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1889\u001b[0m                 \u001b[0;34m.\u001b[0m\u001b[0m_typed_storage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m                 \u001b[0;34m.\u001b[0m\u001b[0m_untyped_storage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# INSTALLATION\n",
        "!pip install fastapi uvicorn python-multipart opencv-python matplotlib timm torch torchvision open3d\n",
        "\n",
        "# Imports\n",
        "import os\n",
        "import io\n",
        "import base64\n",
        "import numpy as np\n",
        "import torch\n",
        "import cv2\n",
        "import open3d as o3d\n",
        "import matplotlib.pyplot as plt\n",
        "from fastapi import FastAPI, UploadFile, File\n",
        "from fastapi.responses import JSONResponse\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "\n",
        "# Charger modèle MiDaS une fois au démarrage\n",
        "model_type = \"DPT_Large\"\n",
        "midas = torch.hub.load(\"intel-isl/MiDaS\", model_type, trust_repo=True)\n",
        "midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\", trust_repo=True)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "midas.to(device)\n",
        "midas.eval()\n",
        "\n",
        "transform = midas_transforms.dpt_transform if model_type.startswith(\"DPT\") else midas_transforms.small_transform\n",
        "\n",
        "# Création FastAPI app\n",
        "app = FastAPI()\n",
        "\n",
        "# CORS pour React frontend distant (adapter l'origin)\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=[\"*\"],  # mettre URL frontend en prod\n",
        "    allow_credentials=True,\n",
        "    allow_methods=[\"*\"],\n",
        "    allow_headers=[\"*\"],\n",
        ")\n",
        "\n",
        "def create_pointcloud_and_depth(image_np):\n",
        "    # image_np : numpy RGB uint8\n",
        "\n",
        "    input_tensor = transform(image_np).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        prediction = midas(input_tensor)\n",
        "        prediction = torch.nn.functional.interpolate(\n",
        "            prediction.unsqueeze(1),\n",
        "            size=image_np.shape[:2],\n",
        "            mode=\"bicubic\",\n",
        "            align_corners=False,\n",
        "        ).squeeze()\n",
        "\n",
        "    depth = prediction.cpu().numpy()\n",
        "    depth_norm = np.clip(depth, 0.1, 100)\n",
        "\n",
        "    # Paramètres caméra\n",
        "    fx, fy = 500, 500\n",
        "    h, w = depth.shape\n",
        "    cx, cy = w / 2, h / 2\n",
        "\n",
        "    all_points = []\n",
        "    all_colors = []\n",
        "    stride = 8\n",
        "    for y in range(0, h, stride):\n",
        "        for x in range(0, w, stride):\n",
        "            z = depth_norm[y, x]\n",
        "            if np.isnan(z) or np.isinf(z):\n",
        "                continue\n",
        "            X = (x - cx) * z / fx\n",
        "            Y = (y - cy) * z / fy\n",
        "            if np.any(np.isnan([X, Y, z])) or np.any(np.isinf([X, Y, z])):\n",
        "                continue\n",
        "            all_points.append([X, -Y, -z])\n",
        "            all_colors.append(image_np[y, x] / 255.0)\n",
        "\n",
        "    if not all_points:\n",
        "        raise RuntimeError(\"Aucun point valide généré.\")\n",
        "\n",
        "    pcd = o3d.geometry.PointCloud()\n",
        "    pcd.points = o3d.utility.Vector3dVector(np.array(all_points))\n",
        "    pcd.colors = o3d.utility.Vector3dVector(np.array(all_colors))\n",
        "\n",
        "    # Sauvegarder depth en PNG en mémoire\n",
        "    depth_img_path = \"depth_image.png\"\n",
        "    plt.imsave(depth_img_path, depth, cmap='inferno')\n",
        "\n",
        "    # Sauvegarder nuage points en PLY en mémoire\n",
        "    ply_path = \"scene3d.ply\"\n",
        "    o3d.io.write_point_cloud(ply_path, pcd)\n",
        "\n",
        "    # Lire fichiers en base64 pour réponse\n",
        "    with open(depth_img_path, \"rb\") as f:\n",
        "        depth_b64 = base64.b64encode(f.read()).decode(\"utf-8\")\n",
        "    with open(ply_path, \"rb\") as f:\n",
        "        ply_b64 = base64.b64encode(f.read()).decode(\"utf-8\")\n",
        "\n",
        "    # Supprimer fichiers temporaires\n",
        "    os.remove(depth_img_path)\n",
        "    os.remove(ply_path)\n",
        "\n",
        "    return depth_b64, ply_b64\n",
        "\n",
        "@app.post(\"/predict\")\n",
        "async def predict(image: UploadFile = File(...)):\n",
        "    try:\n",
        "        contents = await image.read()\n",
        "        np_arr = np.frombuffer(contents, np.uint8)\n",
        "        img_bgr = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)\n",
        "        if img_bgr is None:\n",
        "            return JSONResponse(status_code=400, content={\"error\": \"Image invalide\"})\n",
        "        img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        depth_b64, ply_b64 = create_pointcloud_and_depth(img_rgb)\n",
        "\n",
        "        return {\n",
        "            \"depth_image_base64\": depth_b64,\n",
        "            \"pointcloud_ply_base64\": ply_b64,\n",
        "            \"message\": \"Succès de la prédiction MiDaS\",\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return JSONResponse(status_code=500, content={\"error\": str(e)})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 526
        },
        "id": "nYgnPLiG1vM2",
        "outputId": "897731a5-d1ca-4d3d-b062-f02e00c6efab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chargement MiDaS...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/intel-isl/MiDaS/zipball/master\" to /root/.cache/torch/hub/master.zip\n",
            "/usr/local/lib/python3.11/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
            "Downloading: \"https://github.com/isl-org/MiDaS/releases/download/v3/dpt_large_384.pt\" to /root/.cache/torch/hub/checkpoints/dpt_large_384.pt\n",
            "100%|██████████| 1.28G/1.28G [00:05<00:00, 260MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⬆️ Upload image pour reconstruction...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/intel-isl_MiDaS_master\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-12a0fce3-3245-45fc-8212-0a632ac313ca\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-12a0fce3-3245-45fc-8212-0a632ac313ca\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 20250719_220835.jpg to 20250719_220835.jpg\n",
            "[1/7] Prétraitement image...\n",
            "[LOG] Netteté (Laplacian): 31067.61\n",
            "[2/7] Inpainting zones sombres...\n",
            "[3/7] Segmentation sémantique...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DeepLabV3_ResNet50_Weights.COCO_WITH_VOC_LABELS_V1`. You can also use `weights=DeepLabV3_ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/deeplabv3_resnet50_coco-cd0a2569.pth\" to /root/.cache/torch/hub/checkpoints/deeplabv3_resnet50_coco-cd0a2569.pth\n",
            "100%|██████████| 161M/161M [00:01<00:00, 146MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4/7] Super-résolution...\n",
            "[5/7] Profondeur avec MiDaS...\n",
            "[6/7] Reconstruction 3D avec maillage...\n",
            "[INFO] Reconstruction de maillage avec Poisson...\n",
            "[7/7] Exportation en OBJ et PNG...\n"
          ]
        }
      ],
      "source": [
        "# ✅ IMPORTS\n",
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "import open3d as o3d\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ExifTags, ImageEnhance, ImageFilter\n",
        "from google.colab import files\n",
        "import torchvision.transforms as T\n",
        "from torchvision.models.segmentation import deeplabv3_resnet50\n",
        "import time  # Ajouté pour gérer les délais\n",
        "\n",
        "# ✅ SETUP\n",
        "torch.manual_seed(42)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "os.makedirs(\"output_frames\", exist_ok=True)\n",
        "\n",
        "# ✅ UTILS\n",
        "def correct_orientation(image: Image.Image) -> Image.Image:\n",
        "    try:\n",
        "        for orientation in ExifTags.TAGS.keys():\n",
        "            if ExifTags.TAGS[orientation] == 'Orientation':\n",
        "                break\n",
        "        exif = dict(image._getexif().items())\n",
        "        orientation_value = exif.get(orientation, None)\n",
        "        if orientation_value == 3:\n",
        "            image = image.rotate(180, expand=True)\n",
        "        elif orientation_value == 6:\n",
        "            image = image.rotate(270, expand=True)\n",
        "        elif orientation_value == 8:\n",
        "            image = image.rotate(90, expand=True)\n",
        "    except:\n",
        "        pass\n",
        "    return image\n",
        "\n",
        "def enhance_image(image: Image.Image) -> Image.Image:\n",
        "    image = ImageEnhance.Contrast(image).enhance(1.8)\n",
        "    image = ImageEnhance.Sharpness(image).enhance(2.0)\n",
        "    image = image.filter(ImageFilter.EDGE_ENHANCE_MORE)\n",
        "    return image\n",
        "\n",
        "def load_and_prepare_image(image_path, target_max_size=512):\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    image = correct_orientation(image)\n",
        "    max_dim = max(image.size)\n",
        "    if max_dim > target_max_size:\n",
        "        scale = target_max_size / max_dim\n",
        "        image = image.resize((int(image.size[0]*scale), int(image.size[1]*scale)), Image.LANCZOS)\n",
        "    image = enhance_image(image)\n",
        "    return np.array(image)\n",
        "\n",
        "def check_image_quality(img):\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "    lap_var = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
        "    print(f\"[LOG] Netteté (Laplacian): {lap_var:.2f}\")\n",
        "    if img.std() < 10:\n",
        "        raise ValueError(\"Image trop plate (contraste)\")\n",
        "    if img.mean() < 10:\n",
        "        raise ValueError(\"Image trop sombre\")\n",
        "\n",
        "def auto_inpaint(img):\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "    _, mask = cv2.threshold(gray, 5, 255, cv2.THRESH_BINARY_INV)\n",
        "    return cv2.inpaint(img, mask, 3, cv2.INPAINT_TELEA)\n",
        "\n",
        "# ✅ SEGMENTATION DEEPLAB\n",
        "def run_segmentation(img_rgb):\n",
        "    model = deeplabv3_resnet50(pretrained=True).to(device)\n",
        "    model.eval()\n",
        "    preprocess = T.Compose([\n",
        "        T.ToTensor(),\n",
        "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "    input_tensor = preprocess(Image.fromarray(img_rgb)).unsqueeze(0).to(device)\n",
        "    with torch.no_grad():\n",
        "        output = model(input_tensor)['out'][0]\n",
        "    return output.argmax(0).byte().cpu().numpy()\n",
        "\n",
        "def colorize_segmentation(seg):\n",
        "    palette = np.array([\n",
        "        [0,0,0],[128,0,0],[0,128,0],[128,128,0],[0,0,128],\n",
        "        [128,0,128],[0,128,128],[128,128,128],[64,0,0],[192,0,0],\n",
        "        [64,128,0],[192,128,0],[64,0,128],[192,0,128],[64,128,128],\n",
        "        [192,128,128],[0,64,0],[128,64,0],[0,192,0],[128,192,0],\n",
        "        [0,64,128]\n",
        "    ])\n",
        "    return palette[seg % 21].astype(np.uint8)\n",
        "\n",
        "def super_resolution(img, scale=2):\n",
        "    return cv2.resize(img, (img.shape[1]*scale, img.shape[0]*scale), interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "# ✅ MIDAS SETUP\n",
        "print(\"Chargement MiDaS...\")\n",
        "model_type = \"DPT_Large\"\n",
        "midas = torch.hub.load(\"intel-isl/MiDaS\", model_type, trust_repo=True).to(device).eval()\n",
        "midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\", trust_repo=True)\n",
        "transform = midas_transforms.dpt_transform\n",
        "\n",
        "# ✅ UPLOAD IMAGE\n",
        "print(\"⬆️ Upload image pour reconstruction...\")\n",
        "uploaded = files.upload()\n",
        "image_path = next(iter(uploaded))\n",
        "\n",
        "# ✅ PIPELINE\n",
        "print(\"[1/7] Prétraitement image...\")\n",
        "img_rgb = load_and_prepare_image(image_path)\n",
        "check_image_quality(img_rgb)\n",
        "\n",
        "print(\"[2/7] Inpainting zones sombres...\")\n",
        "img_rgb = auto_inpaint(img_rgb)\n",
        "\n",
        "print(\"[3/7] Segmentation sémantique...\")\n",
        "seg = run_segmentation(img_rgb)\n",
        "color_seg = colorize_segmentation(seg)\n",
        "plt.imsave(\"output_frames/segmentation.png\", color_seg)\n",
        "\n",
        "print(\"[4/7] Super-résolution...\")\n",
        "img_sr = super_resolution(img_rgb, scale=2)\n",
        "plt.imsave(\"output_frames/super_resolution.png\", img_sr)\n",
        "\n",
        "print(\"[5/7] Profondeur avec MiDaS...\")\n",
        "input_tensor = transform(img_sr).to(device)\n",
        "with torch.no_grad():\n",
        "    prediction = midas(input_tensor)\n",
        "    prediction = torch.nn.functional.interpolate(\n",
        "        prediction.unsqueeze(1),\n",
        "        size=img_sr.shape[:2],\n",
        "        mode=\"bicubic\",\n",
        "        align_corners=False,\n",
        "    ).squeeze()\n",
        "depth = prediction.cpu().numpy()\n",
        "plt.imsave(\"output_frames/depth_map.png\", depth, cmap=\"inferno\")\n",
        "\n",
        "print(\"[6/7] Reconstruction 3D avec maillage...\")\n",
        "fx, fy = 500, 500\n",
        "h, w = depth.shape\n",
        "cx, cy = w/2, h/2\n",
        "depth = np.clip(depth, 0.1, 100)\n",
        "\n",
        "# Générer nuage de points\n",
        "points, colors, texcoords = [], [], []\n",
        "stride = 4\n",
        "for y in range(0, h, stride):\n",
        "    for x in range(0, w, stride):\n",
        "        z = depth[y, x]\n",
        "        if np.isnan(z) or np.isinf(z):\n",
        "            continue\n",
        "        X = (x - cx) * z / fx\n",
        "        Y = (y - cy) * z / fy\n",
        "        points.append([X, -Y, -z])\n",
        "        cx2, cy2 = min(x, img_sr.shape[1]-1), min(y, img_sr.shape[0]-1)\n",
        "        colors.append(img_sr[cy2, cx2] / 255.0)\n",
        "        texcoords.append([x / w, 1.0 - y / h])\n",
        "\n",
        "points = np.array(points)\n",
        "colors = np.array(colors)\n",
        "texcoords = np.array(texcoords)\n",
        "\n",
        "# Créer nuage de points\n",
        "pcd = o3d.geometry.PointCloud()\n",
        "pcd.points = o3d.utility.Vector3dVector(points)\n",
        "pcd.colors = o3d.utility.Vector3dVector(colors)\n",
        "\n",
        "# Estimation des normales\n",
        "pcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.1, max_nn=30))\n",
        "\n",
        "# Reconstruction de maillage avec Poisson\n",
        "print(\"[INFO] Reconstruction de maillage avec Poisson...\")\n",
        "mesh, densities = o3d.geometry.TriangleMesh.create_from_point_cloud_poisson(\n",
        "    pcd, depth=8, scale=1.1, linear_fit=True\n",
        ")\n",
        "mesh.compute_vertex_normals()\n",
        "\n",
        "# Sauvegarde de la carte de texture\n",
        "texture_path = \"output_frames/texture.png\"\n",
        "plt.imsave(texture_path, img_sr)\n",
        "\n",
        "# Exportation en OBJ avec MTL\n",
        "print(\"[7/7] Exportation en OBJ et PNG...\")\n",
        "def save_obj_with_mtl(mesh, texture_path, output_obj_path=\"scene3d.obj\"):\n",
        "    vertices = np.asarray(mesh.vertices)\n",
        "    normals = np.asarray(mesh.vertex_normals)\n",
        "    triangles = np.asarray(mesh.triangles)\n",
        "    texcoords = np.random.rand(len(vertices), 2)  # Placeholder pour UV\n",
        "\n",
        "    mtl_path = output_obj_path.replace(\".obj\", \".mtl\")\n",
        "    with open(mtl_path, \"w\") as mtl_file:\n",
        "        mtl_file.write(f\"newmtl material_0\\n\")\n",
        "        mtl_file.write(f\"map_Kd {os.path.basename(texture_path)}\\n\")\n",
        "\n",
        "    with open(output_obj_path, \"w\") as obj_file:\n",
        "        obj_file.write(f\"mtllib {os.path.basename(mtl_path)}\\n\")\n",
        "        for v in vertices:\n",
        "            obj_file.write(f\"v {v[0]} {v[1]} {v[2]}\\n\")\n",
        "        for n in normals:\n",
        "            obj_file.write(f\"vn {n[0]} {n[1]} {n[2]}\\n\")\n",
        "        for uv in texcoords:\n",
        "            obj_file.write(f\"vt {uv[0]} {uv[1]}\\n\")\n",
        "        obj_file.write(\"usemtl material_0\\n\")\n",
        "        for t in triangles:\n",
        "            obj_file.write(f\"f {t[0]+1}/{t[0]+1}/{t[0]+1} {t[1]+1}/{t[1]+1}/{t[1]+1} {t[2]+1}/{t[2]+1}/{t[2]+1}\\n\")\n",
        "\n",
        "save_obj_with_mtl(mesh, texture_path, \"scene3d.obj\")\n",
        "\n",
        "# Rendu PNG de la scène 3D\n",
        "vis = o3d.visualization.Visualizer()\n",
        "vis.create_window(visible=False)\n",
        "vis.add_geometry(mesh)\n",
        "vis.capture_screen_image(\"output_frames/rendered_scene.png\")\n",
        "vis.destroy_window()\n",
        "\n",
        "# Téléchargements séquentiels avec délais\n",
        "print(\"[INFO] Téléchargement des fichiers...\")\n",
        "file_list = [\"scene3d.obj\", \"scene3d.mtl\", \"output_frames/texture.png\", \"output_frames/rendered_scene.png\"]\n",
        "for file_path in file_list:\n",
        "    if os.path.exists(file_path):\n",
        "        print(f\"[INFO] Téléchargement de {file_path}...\")\n",
        "        files.download(file_path)\n",
        "        time.sleep(2)  # Délai de 2 secondes entre chaque téléchargement\n",
        "    else:\n",
        "        print(f\"[ERREUR] Le fichier {file_path} n'existe pas.\")\n",
        "\n",
        "print(\"✅ Terminé. Maillage 3D avec texture exporté (OBJ, MTL, PNG) et rendu PNG généré.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r3UbRD5Bg0gu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ IMPORTS\n",
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "import open3d as o3d\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ExifTags, ImageEnhance, ImageFilter\n",
        "from google.colab import files\n",
        "import torchvision.transforms as T\n",
        "from torchvision.models.segmentation import deeplabv3_resnet50\n",
        "import time\n",
        "\n",
        "# ✅ SETUP\n",
        "torch.manual_seed(42)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "os.makedirs(\"output_frames\", exist_ok=True)\n",
        "\n",
        "# ✅ UTILS\n",
        "def correct_orientation(image: Image.Image) -> Image.Image:\n",
        "    try:\n",
        "        for orientation in ExifTags.TAGS.keys():\n",
        "            if ExifTags.TAGS[orientation] == 'Orientation':\n",
        "                break\n",
        "        exif = dict(image._getexif().items())\n",
        "        orientation_value = exif.get(orientation, None)\n",
        "        if orientation_value == 3:\n",
        "            image = image.rotate(180, expand=True)\n",
        "        elif orientation_value == 6:\n",
        "            image = image.rotate(270, expand=True)\n",
        "        elif orientation_value == 8:\n",
        "            image = image.rotate(90, expand=True)\n",
        "    except:\n",
        "        pass\n",
        "    return image\n",
        "\n",
        "def enhance_image(image: Image.Image) -> Image.Image:\n",
        "    image = ImageEnhance.Contrast(image).enhance(1.8)\n",
        "    image = ImageEnhance.Sharpness(image).enhance(2.0)\n",
        "    image = image.filter(ImageFilter.EDGE_ENHANCE_MORE)\n",
        "    return image\n",
        "\n",
        "def load_and_prepare_image(image_path, target_max_size=512):\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    image = correct_orientation(image)\n",
        "    max_dim = max(image.size)\n",
        "    if max_dim > target_max_size:\n",
        "        scale = target_max_size / max_dim\n",
        "        image = image.resize((int(image.size[0]*scale), int(image.size[1]*scale)), Image.LANCZOS)\n",
        "    image = enhance_image(image)\n",
        "    return np.array(image)\n",
        "\n",
        "def check_image_quality(img):\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "    lap_var = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
        "    print(f\"[LOG] Netteté (Laplacian): {lap_var:.2f}\")\n",
        "    if img.std() < 10:\n",
        "        raise ValueError(\"Image trop plate (contraste)\")\n",
        "    if img.mean() < 10:\n",
        "        raise ValueError(\"Image trop sombre\")\n",
        "\n",
        "def auto_inpaint(img):\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "    _, mask = cv2.threshold(gray, 5, 255, cv2.THRESH_BINARY_INV)\n",
        "    return cv2.inpaint(img, mask, 3, cv2.INPAINT_TELEA)\n",
        "\n",
        "# ✅ SEGMENTATION DEEPLAB\n",
        "def run_segmentation(img_rgb):\n",
        "    model = deeplabv3_resnet50(pretrained=True).to(device)\n",
        "    model.eval()\n",
        "    preprocess = T.Compose([\n",
        "        T.ToTensor(),\n",
        "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "    input_tensor = preprocess(Image.fromarray(img_rgb)).unsqueeze(0).to(device)\n",
        "    with torch.no_grad():\n",
        "        output = model(input_tensor)['out'][0]\n",
        "    return output.argmax(0).byte().cpu().numpy()\n",
        "\n",
        "def colorize_segmentation(seg):\n",
        "    palette = np.array([\n",
        "        [0,0,0],[128,0,0],[0,128,0],[128,128,0],[0,0,128],\n",
        "        [128,0,128],[0,128,128],[128,128,128],[64,0,0],[192,0,0],\n",
        "        [64,128,0],[192,128,0],[64,0,128],[192,0,128],[64,128,128],\n",
        "        [192,128,128],[0,64,0],[128,64,0],[0,192,0],[128,192,0],\n",
        "        [0,64,128]\n",
        "    ])\n",
        "    return palette[seg % 21].astype(np.uint8)\n",
        "\n",
        "def super_resolution(img, scale=2):\n",
        "    return cv2.resize(img, (img.shape[1]*scale, img.shape[0]*scale), interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "# ✅ MIDAS SETUP\n",
        "print(\"Chargement MiDaS...\")\n",
        "model_type = \"DPT_Large\"\n",
        "midas = torch.hub.load(\"intel-isl/MiDaS\", model_type, trust_repo=True).to(device).eval()\n",
        "midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\", trust_repo=True)\n",
        "transform = midas_transforms.dpt_transform\n",
        "\n",
        "# ✅ UPLOAD IMAGE\n",
        "print(\"⬆️ Upload image pour reconstruction...\")\n",
        "uploaded = files.upload()\n",
        "image_path = next(iter(uploaded))\n",
        "\n",
        "# ✅ PIPELINE\n",
        "print(\"[1/6] Prétraitement image...\")\n",
        "img_rgb = load_and_prepare_image(image_path)\n",
        "check_image_quality(img_rgb)\n",
        "\n",
        "print(\"[2/6] Inpainting zones sombres...\")\n",
        "img_rgb = auto_inpaint(img_rgb)\n",
        "\n",
        "print(\"[3/6] Segmentation sémantique...\")\n",
        "seg = run_segmentation(img_rgb)\n",
        "color_seg = colorize_segmentation(seg)\n",
        "plt.imsave(\"output_frames/segmentation.png\", color_seg)\n",
        "\n",
        "print(\"[4/6] Super-résolution...\")\n",
        "img_sr = super_resolution(img_rgb, scale=2)\n",
        "plt.imsave(\"output_frames/super_resolution.png\", img_sr)\n",
        "\n",
        "print(\"[5/6] Profondeur avec MiDaS...\")\n",
        "input_tensor = transform(img_sr).to(device)\n",
        "with torch.no_grad():\n",
        "    prediction = midas(input_tensor)\n",
        "    prediction = torch.nn.functional.interpolate(\n",
        "        prediction.unsqueeze(1),\n",
        "        size=img_sr.shape[:2],\n",
        "        mode=\"bicubic\",\n",
        "        align_corners=False,\n",
        "    ).squeeze()\n",
        "depth = prediction.cpu().numpy()\n",
        "plt.imsave(\"output_frames/depth_map.png\", depth, cmap=\"inferno\")\n",
        "\n",
        "print(\"[6/6] Reconstruction 3D et rendu PNG...\")\n",
        "fx, fy = 500, 500\n",
        "h, w = depth.shape\n",
        "cx, cy = w/2, h/2\n",
        "depth = np.clip(depth, 0.1, 100)\n",
        "\n",
        "# Générer nuage de points\n",
        "points, colors = [], []\n",
        "stride = 4\n",
        "for y in range(0, h, stride):\n",
        "    for x in range(0, w, stride):\n",
        "        z = depth[y, x]\n",
        "        if np.isnan(z) or np.isinf(z):\n",
        "            continue\n",
        "        X = (x - cx) * z / fx\n",
        "        Y = (y - cy) * z / fy\n",
        "        points.append([X, -Y, -z])\n",
        "        cx2, cy2 = min(x, img_sr.shape[1]-1), min(y, img_sr.shape[0]-1)\n",
        "        colors.append(img_sr[cy2, cx2] / 255.0)\n",
        "\n",
        "points = np.array(points)\n",
        "colors = np.array(colors)\n",
        "\n",
        "# Créer nuage de points\n",
        "pcd = o3d.geometry.PointCloud()\n",
        "pcd.points = o3d.utility.Vector3dVector(points)\n",
        "pcd.colors = o3d.utility.Vector3dVector(colors)\n",
        "\n",
        "# Estimation des normales\n",
        "pcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.1, max_nn=30))\n",
        "\n",
        "# Reconstruction de maillage avec Poisson\n",
        "print(\"[INFO] Reconstruction de maillage avec Poisson...\")\n",
        "mesh, _ = o3d.geometry.TriangleMesh.create_from_point_cloud_poisson(\n",
        "    pcd, depth=8, scale=1.1, linear_fit=True\n",
        ")\n",
        "mesh.compute_vertex_normals()\n",
        "\n",
        "# Rendu PNG de la scène 3D\n",
        "rendered_png_path = \"output_frames/rendered_scene.png\"\n",
        "vis = o3d.visualization.Visualizer()\n",
        "vis.create_window(visible=False)\n",
        "vis.add_geometry(mesh)\n",
        "vis.capture_screen_image(rendered_png_path)\n",
        "vis.destroy_window()\n",
        "\n",
        "# Téléchargement du fichier PNG\n",
        "print(\"[INFO] Téléchargement du rendu PNG...\")\n",
        "if os.path.exists(rendered_png_path):\n",
        "    files.download(rendered_png_path)\n",
        "    print(f\"[INFO] Fichier {rendered_png_path} téléchargé avec succès.\")\n",
        "else:\n",
        "    print(f\"[ERREUR] Le fichier {rendered_png_path} n'a pas été généré.\")\n",
        "\n",
        "print(\"✅ Terminé. Rendu PNG généré et téléchargé.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "AV4wepEp70tH",
        "outputId": "eb97e4dd-b212-4f2c-eed8-71335f900a8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chargement MiDaS...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/intel-isl_MiDaS_master\n",
            "/usr/local/lib/python3.11/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⬆️ Upload image pour reconstruction...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/intel-isl_MiDaS_master\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-59ac6fa7-277a-4586-a862-b89f27767cfc\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-59ac6fa7-277a-4586-a862-b89f27767cfc\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving IMG-20250719-WA0036.jpg to IMG-20250719-WA0036.jpg\n",
            "[1/6] Prétraitement image...\n",
            "[LOG] Netteté (Laplacian): 114142.72\n",
            "[2/6] Inpainting zones sombres...\n",
            "[3/6] Segmentation sémantique...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DeepLabV3_ResNet50_Weights.COCO_WITH_VOC_LABELS_V1`. You can also use `weights=DeepLabV3_ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4/6] Super-résolution...\n",
            "[5/6] Profondeur avec MiDaS...\n",
            "[6/6] Reconstruction 3D et rendu PNG...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Installer les dépendances nécessaires\n",
        "!pip install open3d pythreejs trimesh --quiet\n",
        "\n",
        "import open3d as o3d\n",
        "import numpy as np\n",
        "import trimesh\n",
        "from google.colab import files\n",
        "from IPython.display import display\n",
        "from pythreejs import *\n",
        "import ipywidgets\n",
        "\n",
        "# Upload fichier nuage de points\n",
        "uploaded = files.upload()\n",
        "filename = list(uploaded.keys())[0]\n",
        "\n",
        "# Lecture du nuage\n",
        "pcd = o3d.io.read_point_cloud(filename)\n",
        "print(f\"Nuage chargé : {len(pcd.points)} points\")\n",
        "\n",
        "# Nettoyage statistique\n",
        "pcd, ind = pcd.remove_statistical_outlier(nb_neighbors=20, std_ratio=2.0)\n",
        "print(f\"Points après nettoyage : {len(pcd.points)}\")\n",
        "\n",
        "# Normales\n",
        "pcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=1.0, max_nn=30))\n",
        "\n",
        "# Reconstruction Poisson\n",
        "mesh, densities = o3d.geometry.TriangleMesh.create_from_point_cloud_poisson(pcd, depth=9)\n",
        "threshold = np.quantile(densities, 0.01)\n",
        "mesh.remove_vertices_by_mask(densities < threshold)\n",
        "mesh.compute_vertex_normals()\n",
        "\n",
        "# Transfert couleurs si présentes\n",
        "if pcd.has_colors():\n",
        "    mesh.vertex_colors = pcd.colors\n",
        "\n",
        "# Export mesh en .glb pour visualisation web\n",
        "mesh_trimesh = trimesh.Trimesh(\n",
        "    vertices=np.asarray(mesh.vertices),\n",
        "    faces=np.asarray(mesh.triangles),\n",
        "    vertex_colors=np.asarray(mesh.vertex_colors) if mesh.has_vertex_colors() else None\n",
        ")\n",
        "mesh_trimesh.export('mesh.glb')\n",
        "\n",
        "print(\"Mesh exporté sous mesh.glb\")\n",
        "\n",
        "# Visualisation interactive avec pythreejs\n",
        "\n",
        "def trimesh_to_geometry(mesh):\n",
        "    positions = np.array(mesh.vertices).astype(np.float32)\n",
        "    faces = np.array(mesh.faces).astype(np.uint32)\n",
        "    colors = None\n",
        "    if mesh.visual.vertex_colors is not None:\n",
        "        colors = np.array(mesh.visual.vertex_colors)[:, :3] / 255.0\n",
        "    geometry = BufferGeometry(\n",
        "        attributes={\n",
        "            'position': BufferAttribute(positions, normalized=False),\n",
        "            'index': BufferAttribute(faces.flatten(), normalized=False),\n",
        "        }\n",
        "    )\n",
        "    if colors is not None:\n",
        "        geometry.attributes['color'] = BufferAttribute(colors, normalized=False)\n",
        "    return geometry\n",
        "\n",
        "geometry = trimesh_to_geometry(mesh_trimesh)\n",
        "material = MeshLambertMaterial(vertexColors='VertexColors') if mesh_trimesh.visual.vertex_colors.any() else MeshLambertMaterial(color='gray')\n",
        "mesh3js = Mesh(geometry=geometry, material=material)\n",
        "\n",
        "scene = Scene(children=[\n",
        "    mesh3js,\n",
        "    AmbientLight(intensity=0.5),\n",
        "    DirectionalLight(position=[3, 5, 1], intensity=0.6)\n",
        "])\n",
        "\n",
        "camera = PerspectiveCamera(position=[0, 0, 3], fov=60,\n",
        "                           children=[DirectionalLight(color='white', position=[0, 0, 1], intensity=0.5)])\n",
        "\n",
        "controller = OrbitControls(controlling=camera)\n",
        "\n",
        "renderer = Renderer(camera=camera, scene=scene, controls=[controller], width=800, height=600)\n",
        "\n",
        "display(renderer)\n",
        "\n",
        "# Lien téléchargement\n",
        "files.download('mesh.glb')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249,
          "referenced_widgets": [
            "4c3da33fd4e74c8582363fba0f5645ea"
          ]
        },
        "id": "eH2VONMXg3pc",
        "outputId": "2324e68e-58ce-4777-fb36-8b6a2cef3649"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m271.7/271.7 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-cd37d3ba-085e-4e9a-8113-e1c88cbd7a10\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-cd37d3ba-085e-4e9a-8113-e1c88cbd7a10\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving gh.ply to gh.ply\n",
            "Nuage chargé : 49152 points\n",
            "Points après nettoyage : 48129\n",
            "Mesh exporté sous mesh.glb\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pythreejs/traits.py:257: UserWarning: 64-bit data types not supported for WebGL data, casting to 32-bit.\n",
            "  warnings.warn('64-bit data types not supported for WebGL '\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Renderer(camera=PerspectiveCamera(children=(DirectionalLight(color='white', intensity=0.5, position=(0.0, 0.0,…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4c3da33fd4e74c8582363fba0f5645ea"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_097bfa97-0f32-470c-ae91-45b108ca573c\", \"mesh.glb\", 4114440)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install open3d trimesh gradio --quiet"
      ],
      "metadata": {
        "id": "gD19UjVcjoam"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Étape 1 : Installer les dépendances\n",
        "!pip install torch torchvision open3d pyrender numpy opencv-python pillow trimesh ultralytics matplotlib vtk\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import open3d as o3d\n",
        "import pyrender\n",
        "import trimesh\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "import os\n",
        "import uuid\n",
        "from ultralytics import YOLO\n",
        "import vtk\n",
        "\n",
        "# Étape 2 : Charger les modèles MiDaS et YOLOv8\n",
        "def load_models():\n",
        "    model_type = \"MiDaS_small\"\n",
        "    midas = torch.hub.load(\"intel-isl/MiDaS\", model_type, pretrained=True, trust_repo=True)\n",
        "    midas.eval()\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    midas.to(device)\n",
        "    midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\", trust_repo=True)\n",
        "    transform = midas_transforms.small_transform\n",
        "\n",
        "    yolo = YOLO(\"yolov8n.pt\")\n",
        "    yolo.to(device)\n",
        "\n",
        "    return midas, transform, yolo, device\n",
        "\n",
        "midas, midas_transform, yolo, device = load_models()\n",
        "print(\"Modèles MiDaS et YOLOv8 chargés avec succès\")\n",
        "\n",
        "# Étape 3 : Créer un nuage de points à partir d’une image\n",
        "def create_point_cloud_from_image(image_path):\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    image = image.resize((160, 120), Image.LANCZOS)\n",
        "    image_np = np.array(image)\n",
        "\n",
        "    img = cv2.cvtColor(image_np, cv2.COLOR_RGB2BGR)\n",
        "    input_batch = midas_transform(img).to(device)\n",
        "    with torch.no_grad():\n",
        "        prediction = midas(input_batch)\n",
        "        prediction = torch.nn.functional.interpolate(\n",
        "            prediction.unsqueeze(1),\n",
        "            size=(120, 160),\n",
        "            mode=\"bicubic\",\n",
        "            align_corners=False,\n",
        "        ).squeeze().cpu().numpy()\n",
        "    depth = prediction\n",
        "\n",
        "    results = yolo(image_np, conf=0.5)\n",
        "    annotations = []\n",
        "    for result in results:\n",
        "        for box in result.boxes:\n",
        "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "            cls = int(box.cls[0])\n",
        "            label = yolo.names[cls]\n",
        "            if label in [\"person\", \"car\", \"truck\", \"animal\", \"bed\", \"tv\"]:\n",
        "                x_center = (x1 + x2) // 2\n",
        "                y_center = (y1 + y2) // 2\n",
        "                z = float(depth[y_center, x_center] / np.max(depth))\n",
        "                x_norm = float((x_center - 160 / 2) / max(160, 120))\n",
        "                y_norm = float((y_center - 120 / 2) / max(160, 120))\n",
        "                annotations.append({\n",
        "                    \"type\": \"sphere\",\n",
        "                    \"position\": [x_norm, -y_norm, z],\n",
        "                    \"radius\": 0.02,\n",
        "                    \"color\": [1.0, 0.0, 0.0],\n",
        "                    \"label\": label\n",
        "                })\n",
        "    print(f\"{len(annotations)} objets détectés par YOLOv8\")\n",
        "\n",
        "    positions = []\n",
        "    colors = []\n",
        "    h, w = depth.shape\n",
        "    for y in range(0, h, 2):\n",
        "        for x in range(0, w, 2):\n",
        "            z = depth[y, x]\n",
        "            x_norm = float((x - w / 2) / max(w, h))\n",
        "            y_norm = float((y - h / 2) / max(w, h))\n",
        "            z_norm = float(z / np.max(depth))\n",
        "            positions.append([x_norm, -y_norm, z_norm])\n",
        "            colors.append(image_np[y, x] / 255.0)\n",
        "\n",
        "    return np.array(positions), np.array(colors), annotations, image_np\n",
        "\n",
        "# Étape 4 : Charger un nuage de points à partir d’un fichier PLY\n",
        "def load_ply(file_path):\n",
        "    mesh = trimesh.load(file_path, file_type=\"ply\")\n",
        "    if not isinstance(mesh, trimesh.PointCloud):\n",
        "        raise ValueError(\"Le fichier n'est pas un nuage de points valide\")\n",
        "    positions = mesh.vertices.astype(np.float32)\n",
        "    colors = mesh.colors[:, :3].astype(float) / 255.0 if hasattr(mesh, \"colors\") and mesh.colors is not None else None\n",
        "    return positions, colors\n",
        "\n",
        "# Étape 5 : Décimation du nuage de points\n",
        "def decimate_point_cloud(positions, colors=None, max_points=50000):\n",
        "    if len(positions) > max_points:\n",
        "        points = vtk.vtkPoints()\n",
        "        for pos in positions:\n",
        "            points.InsertNextPoint(pos)\n",
        "        polydata = vtk.vtkPolyData()\n",
        "        polydata.SetPoints(points)\n",
        "\n",
        "        if colors is not None:\n",
        "            color_array = vtk.vtkUnsignedCharArray()\n",
        "            color_array.SetNumberOfComponents(3)\n",
        "            color_array.SetName(\"Colors\")\n",
        "            for color in colors:\n",
        "                color_array.InsertNextTuple3(int(color[0] * 255), int(color[1] * 255), int(color[2] * 255))\n",
        "            polydata.GetPointData().SetScalars(color_array)\n",
        "\n",
        "        decimate = vtk.vtkDecimatePro()\n",
        "        decimate.SetInputData(polydata)\n",
        "        decimate.SetTargetReduction(0.7)\n",
        "        decimate.Update()\n",
        "        reduced_polydata = decimate.GetOutput()\n",
        "        positions = np.array(reduced_polydata.GetPoints().GetData())\n",
        "        if colors is not None:\n",
        "            colors = colors[:len(positions)]\n",
        "        print(f\"Nuage de points réduit à {len(positions)} points\")\n",
        "    return positions, colors\n",
        "\n",
        "# Étape 6 : Reconstruction de surface\n",
        "def reconstruct_surface(positions, colors=None):\n",
        "    pcd = o3d.geometry.PointCloud()\n",
        "    pcd.points = o3d.utility.Vector3dVector(positions)\n",
        "    if colors is not None:\n",
        "        pcd.colors = o3d.utility.Vector3dVector(colors)\n",
        "\n",
        "    pcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.1, max_nn=30))\n",
        "    mesh, _ = o3d.geometry.TriangleMesh.create_from_point_cloud_poisson(pcd, depth=8)\n",
        "    mesh.compute_vertex_normals()\n",
        "    return mesh\n",
        "\n",
        "# Étape 7 : Convertir le maillage open3d en trimesh\n",
        "def open3d_to_trimesh(open3d_mesh):\n",
        "    vertices = np.asarray(open3d_mesh.vertices)\n",
        "    faces = np.asarray(open3d_mesh.triangles)\n",
        "    vertex_colors = np.asarray(open3d_mesh.vertex_colors) if open3d_mesh.has_vertex_colors() else None\n",
        "    trimesh_mesh = trimesh.Trimesh(vertices=vertices, faces=faces, vertex_colors=vertex_colors)\n",
        "    return trimesh_mesh\n",
        "\n",
        "# Étape 8 : Appliquer une texture\n",
        "def apply_texture(mesh, image_np):\n",
        "    material = trimesh.visual.material.SimpleMaterial(image=Image.fromarray(image_np))\n",
        "    mesh.visual.material = material\n",
        "    return mesh\n",
        "\n",
        "# Étape 9 : Rendu photoréaliste avec annotations\n",
        "def render_photorealistic(mesh, annotations, output_path=\"render.png\"):\n",
        "    scene = pyrender.Scene(ambient_light=[0.3, 0.3, 0.3])\n",
        "\n",
        "    # Convertir le maillage open3d en trimesh si nécessaire\n",
        "    if isinstance(mesh, o3d.geometry.TriangleMesh):\n",
        "        mesh = open3d_to_trimesh(mesh)\n",
        "\n",
        "    mesh_node = pyrender.Mesh.from_trimesh(mesh)\n",
        "    scene.add(mesh_node)\n",
        "\n",
        "    for anno in annotations:\n",
        "        if anno[\"type\"] == \"sphere\":\n",
        "            sphere = trimesh.creation.icosphere(radius=anno[\"radius\"])\n",
        "            sphere.visual.vertex_colors = anno[\"color\"]\n",
        "            sphere_node = pyrender.Mesh.from_trimesh(sphere, poses=np.array([\n",
        "                [1, 0, 0, anno[\"position\"][0]],\n",
        "                [0, 1, 0, anno[\"position\"][1]],\n",
        "                [0, 0, 1, anno[\"position\"][2]],\n",
        "                [0, 0, 0, 1]\n",
        "            ]))\n",
        "            scene.add(sphere_node)\n",
        "\n",
        "    camera = pyrender.PerspectiveCamera(yfov=np.pi / 3.0, aspectRatio=1.0)\n",
        "    camera_pose = np.array([\n",
        "        [1, 0, 0, 0],\n",
        "        [0, 1, 0, 0],\n",
        "        [0, 0, 1, 5],\n",
        "        [0, 0, 0, 1]\n",
        "    ])\n",
        "    scene.add(camera, pose=camera_pose)\n",
        "\n",
        "    scene.add(pyrender.DirectionalLight(color=np.ones(3), intensity=3.0), pose=camera_pose)\n",
        "    scene.add(pyrender.PointLight(color=np.ones(3), intensity=100.0), pose=np.array([\n",
        "        [1, 0, 0, 2],\n",
        "        [0, 1, 0, 2],\n",
        "        [0, 0, 1, 5],\n",
        "        [0, 0, 0, 1]\n",
        "    ]))\n",
        "\n",
        "    renderer = pyrender.OffscreenRenderer(viewport_width=640, viewport_height=480)\n",
        "    color, _ = renderer.render(scene)\n",
        "    cv2.imwrite(output_path, cv2.cvtColor(color, cv2.COLOR_RGB2BGR))\n",
        "    return output_path\n",
        "\n",
        "# Étape 10 : Pipeline principal\n",
        "def main():\n",
        "    print(\"Veuillez uploader une image (.jpg, .png) ou un fichier PLY\")\n",
        "    uploaded = files.upload()\n",
        "    file_path = list(uploaded.keys())[0]\n",
        "\n",
        "    positions, colors, annotations, image_np = None, None, [], None\n",
        "    if file_path.endswith((\".jpg\", \".png\")):\n",
        "        positions, colors, annotations, image_np = create_point_cloud_from_image(file_path)\n",
        "    elif file_path.endswith(\".ply\"):\n",
        "        positions, colors = load_ply(file_path)\n",
        "    else:\n",
        "        raise ValueError(\"Fichier non supporté (doit être .jpg, .png ou .ply)\")\n",
        "\n",
        "    print(f\"Nuage de points créé : {len(positions)} points\")\n",
        "\n",
        "    positions, colors = decimate_point_cloud(positions, colors)\n",
        "\n",
        "    mesh = reconstruct_surface(positions, colors)\n",
        "    print(\"Reconstruction de surface terminée\")\n",
        "\n",
        "    if image_np is not None:\n",
        "        mesh = apply_texture(open3d_to_trimesh(mesh), image_np)\n",
        "        print(\"Texture appliquée\")\n",
        "\n",
        "    mesh_path = f\"output_mesh_{uuid.uuid4()}.ply\"\n",
        "    o3d.io.write_triangle_mesh(mesh_path, mesh)\n",
        "\n",
        "    render_path = f\"render_{uuid.uuid4()}.png\"\n",
        "    render_photorealistic(mesh, annotations, render_path)\n",
        "    print(\"Rendu photoréaliste terminé\")\n",
        "\n",
        "    img = cv2.imread(render_path)\n",
        "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    files.download(render_path)\n",
        "    print(f\"Téléchargement initié pour {render_path}\")\n",
        "    files.download(mesh_path)\n",
        "    print(f\"Téléchargement initié pour {mesh_path}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "N88OgSWoktMJ",
        "outputId": "5a9b07c4-1d12-49af-f875-25afadd33849"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: open3d in /usr/local/lib/python3.11/dist-packages (0.19.0)\n",
            "Requirement already satisfied: pyrender in /usr/local/lib/python3.11/dist-packages (0.1.45)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\n",
            "Requirement already satisfied: trimesh in /usr/local/lib/python3.11/dist-packages (4.7.1)\n",
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.11/dist-packages (8.3.169)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: vtk in /usr/local/lib/python3.11/dist-packages (9.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: dash>=2.6.0 in /usr/local/lib/python3.11/dist-packages (from open3d) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from open3d) (3.1.3)\n",
            "Requirement already satisfied: flask>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from open3d) (3.1.1)\n",
            "Requirement already satisfied: nbformat>=5.7.0 in /usr/local/lib/python3.11/dist-packages (from open3d) (5.10.4)\n",
            "Requirement already satisfied: configargparse in /usr/local/lib/python3.11/dist-packages (from open3d) (1.7.1)\n",
            "Requirement already satisfied: ipywidgets>=8.0.4 in /usr/local/lib/python3.11/dist-packages (from open3d) (8.1.7)\n",
            "Requirement already satisfied: addict in /usr/local/lib/python3.11/dist-packages (from open3d) (2.4.0)\n",
            "Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.11/dist-packages (from open3d) (2.2.2)\n",
            "Requirement already satisfied: pyyaml>=5.4.1 in /usr/local/lib/python3.11/dist-packages (from open3d) (6.0.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21 in /usr/local/lib/python3.11/dist-packages (from open3d) (1.6.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from open3d) (4.67.1)\n",
            "Requirement already satisfied: pyquaternion in /usr/local/lib/python3.11/dist-packages (from open3d) (0.9.9)\n",
            "Requirement already satisfied: freetype-py in /usr/local/lib/python3.11/dist-packages (from pyrender) (2.5.1)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.11/dist-packages (from pyrender) (2.37.0)\n",
            "Requirement already satisfied: pyglet>=1.4.10 in /usr/local/lib/python3.11/dist-packages (from pyrender) (2.1.6)\n",
            "Requirement already satisfied: PyOpenGL==3.1.0 in /usr/local/lib/python3.11/dist-packages (from pyrender) (3.1.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from pyrender) (1.15.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from pyrender) (1.17.0)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.14)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: plotly>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from dash>=2.6.0->open3d) (5.24.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from dash>=2.6.0->open3d) (8.7.0)\n",
            "Requirement already satisfied: retrying in /usr/local/lib/python3.11/dist-packages (from dash>=2.6.0->open3d) (1.4.1)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from dash>=2.6.0->open3d) (1.6.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from dash>=2.6.0->open3d) (75.2.0)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from flask>=3.0.0->open3d) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask>=3.0.0->open3d) (8.2.1)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from flask>=3.0.0->open3d) (2.2.0)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from flask>=3.0.0->open3d) (3.0.2)\n",
            "Requirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.0.4->open3d) (0.2.2)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.0.4->open3d) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.0.4->open3d) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=4.0.14 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.0.4->open3d) (4.0.14)\n",
            "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.0.4->open3d) (3.0.15)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.7.0->open3d) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.7.0->open3d) (4.24.1)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.7.0->open3d) (5.8.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0->open3d) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0->open3d) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.7.14)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21->open3d) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21->open3d) (3.6.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (3.0.51)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (4.9.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (0.26.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core!=5.0.*,>=4.12->nbformat>=5.7.0->open3d) (4.3.8)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly>=5.0.0->dash>=2.6.0->open3d) (8.5.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->dash>=2.6.0->open3d) (3.23.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.13)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/intel-isl_MiDaS_master\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading weights:  None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master\n",
            "Using cache found in /root/.cache/torch/hub/intel-isl_MiDaS_master\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modèles MiDaS et YOLOv8 chargés avec succès\n",
            "Veuillez uploader une image (.jpg, .png) ou un fichier PLY\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a9120f8f-f251-494a-8532-5b8baf1d5685\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a9120f8f-f251-494a-8532-5b8baf1d5685\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 20250722_130913.jpg to 20250722_130913 (1).jpg\n",
            "\n",
            "0: 480x640 (no detections), 15.7ms\n",
            "Speed: 2.5ms preprocess, 15.7ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "0 objets détectés par YOLOv8\n",
            "Nuage de points créé : 4800 points\n",
            "Reconstruction de surface terminée\n",
            "Texture appliquée\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "write_triangle_mesh(): incompatible function arguments. The following argument types are supported:\n    1. (filename: os.PathLike, mesh: open3d.cuda.pybind.geometry.TriangleMesh, write_ascii: bool = False, compressed: bool = False, write_vertex_normals: bool = True, write_vertex_colors: bool = True, write_triangle_uvs: bool = True, print_progress: bool = False) -> bool\n\nInvoked with: 'output_mesh_b3a146be-b0dc-4f20-aff5-dc65d3cf3cf5.ply', <trimesh.Trimesh(vertices.shape=(17853, 3), faces.shape=(35462, 3))>",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3-861546820.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-3-861546820.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0mmesh_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"output_mesh_{uuid.uuid4()}.ply\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m     \u001b[0mo3d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_triangle_mesh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmesh_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmesh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[0mrender_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"render_{uuid.uuid4()}.png\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: write_triangle_mesh(): incompatible function arguments. The following argument types are supported:\n    1. (filename: os.PathLike, mesh: open3d.cuda.pybind.geometry.TriangleMesh, write_ascii: bool = False, compressed: bool = False, write_vertex_normals: bool = True, write_vertex_colors: bool = True, write_triangle_uvs: bool = True, print_progress: bool = False) -> bool\n\nInvoked with: 'output_mesh_b3a146be-b0dc-4f20-aff5-dc65d3cf3cf5.ply', <trimesh.Trimesh(vertices.shape=(17853, 3), faces.shape=(35462, 3))>"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4c3da33fd4e74c8582363fba0f5645ea": {
          "model_module": "jupyter-threejs",
          "model_name": "RendererModel",
          "model_module_version": "^2.4.1",
          "state": {
            "_alpha": false,
            "_antialias": false,
            "_dom_classes": [],
            "_height": 600,
            "_model_module": "jupyter-threejs",
            "_model_module_version": "^2.4.1",
            "_model_name": "RendererModel",
            "_pause_autorender": false,
            "_view_count": null,
            "_view_module": "jupyter-threejs",
            "_view_module_version": "^2.4.1",
            "_view_name": "RendererView",
            "_webgl_version": 2,
            "_width": 800,
            "autoClear": true,
            "autoClearColor": true,
            "autoClearDepth": true,
            "autoClearStencil": true,
            "background": "black",
            "background_opacity": 1,
            "camera": "IPY_MODEL_153a949dbee24b3585f6c5a162037a1a",
            "clearColor": "#000000",
            "clearOpacity": 1,
            "clippingPlanes": [],
            "controls": [
              "IPY_MODEL_b5f30a4c765b47e6a1719ccfcd387140"
            ],
            "gammaFactor": 2,
            "gammaInput": false,
            "gammaOutput": false,
            "layout": "IPY_MODEL_bef044e26b3c4d74a82f348a37bcf794",
            "localClippingEnabled": false,
            "maxMorphNormals": 4,
            "maxMorphTargets": 8,
            "physicallyCorrectLights": false,
            "scene": "IPY_MODEL_5cde742aae624c1eac996780b1ed6400",
            "shadowMap": "IPY_MODEL_cad86166e7bf4ddfbdf0dc567a817dfa",
            "sortObject": true,
            "tabbable": null,
            "toneMapping": "LinearToneMapping",
            "toneMappingExposure": 1,
            "toneMappingWhitePoint": 1,
            "tooltip": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}